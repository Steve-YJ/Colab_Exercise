{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exp01.VAE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNX+dtAp3berER68ydTtmiO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Steve-YJ/Colab_Exercise/blob/master/Exp01_VAE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os9GS8R_KCWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "b0af0b1b-379c-4cf6-be1c-b0bdf174b71d"
      },
      "source": [
        "# drive mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "%cd drive/My\\ Drive/InformationSecurity_Summer\n",
        "! pwd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/InformationSecurity_Summer\n",
            "/content/drive/My Drive/InformationSecurity_Summer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XeJBewoLDOr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1a2206dd-6269-4a32-83c6-636cde35c10c"
      },
      "source": [
        "! pwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/InformationSecurity_Summer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dmz78nUKxGx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05u2akkWKR4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms = transforms.Compose([\n",
        "                                transforms.Resize((224, 224)),                # Change size of Image to (224, 224)\n",
        "                                transforms.Grayscale(num_output_channels=1),  # Makes it 1-dimension channel\n",
        "                                transforms.ToTensor(),                        # Convert a PIL Image or numpy.ndarray to tensor.\n",
        "                                                                              # Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8\n",
        "                                                                              # In the other cases, tensors are returned without scaling.\n",
        "                                # transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "                                \n",
        "                                ])\n",
        "# trainset = torchvision.datasets.ImageFolder(root=\"/content/drive/My Drive/Malimg_Exp_200611/malimg\",\n",
        "#                                             transforms = transform)\n",
        "trainset = torchvision.datasets.ImageFolder(root='./malimg',\n",
        "                                            transform=transforms)  # make custom dataset"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx1-yQH1KutR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "08391bb5-31f0-423c-a51a-be9b2f4bd497"
      },
      "source": [
        "# classes = trainset.classes\n",
        "classes = trainset.classes\n",
        "classes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Adialer.C',\n",
              " 'Agent.FYI',\n",
              " 'Allaple.A',\n",
              " 'Allaple.L',\n",
              " 'Alueron.gen!J',\n",
              " 'Autorun.K',\n",
              " 'C2LOP.P',\n",
              " 'C2LOP.gen!g',\n",
              " 'Dialplatform.B',\n",
              " 'Dontovo.A',\n",
              " 'Fakerean',\n",
              " 'Instantaccess',\n",
              " 'Lolyda.AA1',\n",
              " 'Lolyda.AA2',\n",
              " 'Lolyda.AA3',\n",
              " 'Lolyda.AT',\n",
              " 'Malex.gen!J',\n",
              " 'Obfuscator.AD',\n",
              " 'Rbot!gen',\n",
              " 'Skintrim.N',\n",
              " 'Swizzor.gen!E',\n",
              " 'Swizzor.gen!I',\n",
              " 'VB.AT',\n",
              " 'Wintrim.BX',\n",
              " 'Yuner.A']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB6yE7h9Lu9A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "full_dataset = trainset\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvaDlRrGLm5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_dataset,\n",
        "                         batch_size=16,\n",
        "                         shuffle=True,\n",
        "                         pin_memory=True) \n",
        "test_loader = DataLoader(test_dataset,\n",
        "                        batch_size=16,\n",
        "                        shuffle=True,\n",
        "                        pin_memory=True)  # Instead, we recommend using automatic memory pinning (i.e., setting pin_memory=True)\n",
        "                                          #  which enables fast data transfer to CUDA-enabled GPUs"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUoYh3G5LooR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a2a1166-3b71-49f2-d52d-ff7b2afba8a0"
      },
      "source": [
        "for idx, (data, _) in enumerate(train_loader):\n",
        "    print(data[3], data[4], data.type(), data.shape)\n",
        "    print(_, _.type())\n",
        "    print(\"==\" * 20 )"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0.2706, 0.3961, 0.2902,  ..., 0.0235, 0.0000, 0.0000],\n",
            "         [0.0588, 0.2510, 0.0039,  ..., 0.1098, 0.0000, 0.0000],\n",
            "         [0.0118, 0.0431, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.8392, 0.3686, 0.3294,  ..., 0.4824, 0.3725, 0.4431],\n",
            "         [0.8627, 0.3255, 0.3922,  ..., 0.4078, 0.4549, 0.4863],\n",
            "         [0.3647, 0.4353, 0.5098,  ..., 0.4000, 0.5490, 0.6118]]]) tensor([[[0.0980, 0.0667, 0.0275,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.1529, 0.1569, 0.1333,  ..., 0.1020, 0.1294, 0.1608],\n",
            "         ...,\n",
            "         [0.2118, 0.1608, 0.1216,  ..., 0.2157, 0.1843, 0.1373],\n",
            "         [0.1490, 0.1176, 0.0784,  ..., 0.1059, 0.0667, 0.0549],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([10, 22, 24,  2,  6,  2, 24,  2,  2,  3,  3,  8,  3,  0, 19,  3]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.1569, 0.2275, 0.3412,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.1333, 0.1373, 0.1451,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.3412, 0.3020, 0.2431,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.2549, 0.3922, 0.6157,  ..., 0.2235, 0.4196, 0.5412],\n",
            "         [0.8235, 0.6510, 0.3765,  ..., 0.1882, 0.5176, 0.7255],\n",
            "         [0.6549, 0.5294, 0.3255,  ..., 0.4471, 0.5804, 0.6627]]]) tensor([[[0.2941, 0.3216, 0.3647,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.1725, 0.1647, 0.1529,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.3412, 0.3020, 0.2431,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.4510, 0.5686, 0.7608,  ..., 0.5373, 0.4196, 0.3490],\n",
            "         [0.3686, 0.3725, 0.3765,  ..., 0.3922, 0.4157, 0.4314],\n",
            "         [0.4627, 0.5176, 0.6000,  ..., 0.2667, 0.5137, 0.6627]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([11,  2,  7,  3,  3,  3,  2, 12, 10,  2,  3,  3,  3,  2, 24,  3]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.2588, 0.1490, 0.1882,  ..., 0.1176, 0.1490, 0.0980],\n",
            "         [0.3922, 0.3725, 0.2431,  ..., 0.3569, 0.3333, 0.3725],\n",
            "         [0.5255, 0.5059, 0.4980,  ..., 0.5490, 0.5098, 0.4784],\n",
            "         ...,\n",
            "         [0.4706, 0.5490, 0.5843,  ..., 0.5922, 0.4863, 0.6314],\n",
            "         [0.5373, 0.6235, 0.6275,  ..., 0.6510, 0.4980, 0.7098],\n",
            "         [0.3843, 0.4706, 0.4588,  ..., 0.1922, 0.1451, 0.2078]]]) tensor([[[0.2784, 0.3922, 0.2980,  ..., 0.0196, 0.0000, 0.0000],\n",
            "         [0.0510, 0.2196, 0.0039,  ..., 0.1176, 0.0000, 0.0000],\n",
            "         [0.0039, 0.0157, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.8235, 0.8863, 0.8431,  ..., 0.7451, 0.7294, 0.5647],\n",
            "         [0.5412, 0.8314, 0.8000,  ..., 0.2667, 0.5098, 0.3882],\n",
            "         [0.4196, 0.5373, 0.7882,  ..., 0.4431, 0.2157, 0.3294]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 3,  3, 24, 21,  2, 16,  8,  2, 24,  2, 22, 17, 12, 24,  3,  3]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.3804, 0.3098, 0.2549,  ..., 0.0392, 0.1294, 0.1686],\n",
            "         [0.3098, 0.4941, 0.5686,  ..., 0.1098, 0.4157, 0.4471],\n",
            "         [0.4667, 0.6863, 0.6000,  ..., 0.1961, 0.3686, 0.4627],\n",
            "         ...,\n",
            "         [0.0275, 0.0196, 0.0078,  ..., 0.0863, 0.0471, 0.0941],\n",
            "         [0.1686, 0.0824, 0.0706,  ..., 0.6510, 0.4235, 0.2706],\n",
            "         [0.3098, 0.2235, 0.2941,  ..., 0.2510, 0.2706, 0.2314]]]) tensor([[[0.3255, 0.4706, 0.2392,  ..., 0.0471, 0.0000, 0.0000],\n",
            "         [0.2196, 0.4941, 0.0039,  ..., 0.0745, 0.0000, 0.0000],\n",
            "         [0.0353, 0.1451, 0.0588,  ..., 0.0392, 0.0314, 0.0706],\n",
            "         ...,\n",
            "         [0.3176, 0.3608, 0.4902,  ..., 0.2667, 0.2784, 0.6000],\n",
            "         [0.6196, 0.6627, 0.7020,  ..., 0.4078, 0.4078, 0.2667],\n",
            "         [0.5176, 0.7020, 0.5373,  ..., 0.8314, 0.7529, 0.6863]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 5,  9, 12, 18,  2, 17, 16,  2, 21,  2,  2,  5, 22,  2,  2,  3]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.2667, 0.2863, 0.3098,  ..., 0.0039, 0.0039, 0.0000],\n",
            "         [0.0078, 0.0039, 0.0000,  ..., 0.0431, 0.0196, 0.0039],\n",
            "         [0.0314, 0.0196, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) tensor([[[0.3333, 0.3922, 0.3020,  ..., 0.0196, 0.0000, 0.0000],\n",
            "         [0.4000, 0.1961, 0.0039,  ..., 0.1176, 0.0000, 0.0000],\n",
            "         [0.0039, 0.0157, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.3804, 0.5765, 0.4549,  ..., 0.7647, 0.3608, 0.5490],\n",
            "         [0.7294, 0.3686, 0.4275,  ..., 0.3373, 0.5373, 0.7843],\n",
            "         [0.8392, 0.7098, 0.6471,  ..., 0.1922, 0.6039, 0.8588]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([18, 24,  2,  9,  2, 24,  3,  2, 10, 24, 22,  2,  2,  3,  2,  2]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.3529, 0.3216, 0.3176,  ..., 0.3569, 0.3059, 0.2588],\n",
            "         [0.4275, 0.5255, 0.4706,  ..., 0.4353, 0.4471, 0.4784],\n",
            "         [0.3961, 0.2667, 0.4000,  ..., 0.5608, 0.4824, 0.4471],\n",
            "         ...,\n",
            "         [0.2510, 0.0863, 0.1765,  ..., 0.1255, 0.1373, 0.1059],\n",
            "         [0.0627, 0.0392, 0.1176,  ..., 0.1176, 0.0667, 0.1059],\n",
            "         [0.5255, 0.2824, 0.4588,  ..., 0.3059, 0.2549, 0.4314]]]) tensor([[[0.4980, 0.5216, 0.5529,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.2314, 0.2196, 0.2039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.3412, 0.3020, 0.2431,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.5922, 0.5294, 0.4275,  ..., 0.6235, 0.5961, 0.5804],\n",
            "         [0.6314, 0.5725, 0.4784,  ..., 0.4667, 0.6667, 0.7961],\n",
            "         [0.8275, 0.7490, 0.6235,  ..., 0.2588, 0.3608, 0.4235]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([10, 22,  2, 23,  3, 24, 16,  3,  2,  2,  3,  3,  2,  8,  3,  2]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.2431, 0.1333, 0.2275,  ..., 0.2902, 0.3333, 0.2588],\n",
            "         [0.3490, 0.4706, 0.5176,  ..., 0.3961, 0.2745, 0.3608],\n",
            "         [0.2471, 0.4196, 0.4118,  ..., 0.4196, 0.3020, 0.4745],\n",
            "         ...,\n",
            "         [0.4627, 0.5176, 0.5294,  ..., 0.4157, 0.5020, 0.5647],\n",
            "         [0.5686, 0.5059, 0.5647,  ..., 0.4863, 0.4902, 0.4275],\n",
            "         [0.5804, 0.6078, 0.5255,  ..., 0.4667, 0.4510, 0.4039]]]) tensor([[[0.2353, 0.4471, 0.2196,  ..., 0.0549, 0.0000, 0.0000],\n",
            "         [0.2627, 0.4314, 0.0000,  ..., 0.0510, 0.0000, 0.0000],\n",
            "         [0.1569, 0.3059, 0.1451,  ..., 0.0784, 0.2627, 0.3176],\n",
            "         ...,\n",
            "         [0.3647, 0.7608, 0.6118,  ..., 0.1765, 0.2314, 0.3490],\n",
            "         [0.2627, 0.3412, 0.3922,  ..., 0.0392, 0.1490, 0.4549],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 2,  2,  6, 24,  2,  2, 10,  3, 24,  1, 24,  2, 11,  3, 11, 21]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.2431, 0.1333, 0.2275,  ..., 0.2902, 0.3333, 0.2588],\n",
            "         [0.3490, 0.4706, 0.5176,  ..., 0.3961, 0.2745, 0.3608],\n",
            "         [0.2471, 0.4196, 0.4118,  ..., 0.4196, 0.3020, 0.4745],\n",
            "         ...,\n",
            "         [0.5569, 0.6196, 0.5373,  ..., 0.4667, 0.5216, 0.4980],\n",
            "         [0.4667, 0.4824, 0.6039,  ..., 0.5490, 0.5059, 0.4824],\n",
            "         [0.4275, 0.4745, 0.5294,  ..., 0.4235, 0.3098, 0.4706]]]) tensor([[[0.1020, 0.0471, 0.0118,  ..., 0.0941, 0.0039, 0.0039],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0863, 0.1020, 0.0510,  ..., 0.0431, 0.0863, 0.1451],\n",
            "         ...,\n",
            "         [0.1922, 0.1804, 0.2000,  ..., 0.1765, 0.2039, 0.1451],\n",
            "         [0.1098, 0.1020, 0.1294,  ..., 0.1451, 0.1686, 0.1569],\n",
            "         [0.2314, 0.2078, 0.1373,  ..., 0.0980, 0.1255, 0.1216]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 2, 15, 11,  5, 21, 21,  2,  2, 15, 10, 24,  3,  2, 14,  9, 22]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.2824, 0.2863, 0.3373,  ..., 0.2588, 0.3059, 0.3059],\n",
            "         [0.3882, 0.2902, 0.5412,  ..., 0.4863, 0.3059, 0.3333],\n",
            "         [0.4510, 0.3216, 0.4549,  ..., 0.4980, 0.5961, 0.4118],\n",
            "         ...,\n",
            "         [0.1961, 0.1608, 0.1686,  ..., 0.2000, 0.2314, 0.1922],\n",
            "         [0.3059, 0.5333, 0.3098,  ..., 0.4000, 0.5725, 0.4627],\n",
            "         [0.3647, 0.6235, 0.3725,  ..., 0.3020, 0.4118, 0.3804]]]) tensor([[[0.0549, 0.0078, 0.0000,  ..., 0.0078, 0.0078, 0.0078],\n",
            "         [0.1569, 0.1059, 0.1412,  ..., 0.1804, 0.1922, 0.1765],\n",
            "         [0.3216, 0.2039, 0.2980,  ..., 0.1804, 0.1961, 0.2980],\n",
            "         ...,\n",
            "         [0.2000, 0.1686, 0.1765,  ..., 0.1765, 0.1961, 0.1725],\n",
            "         [0.1922, 0.1725, 0.2078,  ..., 0.1725, 0.1647, 0.1882],\n",
            "         [0.1725, 0.1608, 0.1765,  ..., 0.0667, 0.0784, 0.0784]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 2,  3,  3,  7, 22,  8,  6, 24,  6,  2, 24,  2, 10,  2,  8, 11]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.1765, 0.2353, 0.2000,  ..., 0.0196, 0.0000, 0.3098],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.1373, 0.0902, 0.2353],\n",
            "         [0.2941, 0.3765, 0.2902,  ..., 0.6078, 0.5647, 0.5608],\n",
            "         ...,\n",
            "         [0.4118, 0.5961, 0.5765,  ..., 0.4392, 0.6275, 0.3176],\n",
            "         [0.2706, 0.5765, 0.5059,  ..., 0.4824, 0.5216, 0.3294],\n",
            "         [0.2784, 0.0627, 0.1569,  ..., 0.4980, 0.4824, 0.5216]]]) tensor([[[0.2706, 0.3961, 0.2902,  ..., 0.0235, 0.0000, 0.0000],\n",
            "         [0.0588, 0.2510, 0.0039,  ..., 0.1098, 0.0000, 0.0000],\n",
            "         [0.0118, 0.0431, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.5451, 0.6431, 0.6980,  ..., 0.5137, 0.6902, 0.6745],\n",
            "         [0.5647, 0.4431, 0.6157,  ..., 0.4980, 0.5294, 0.2941],\n",
            "         [0.7098, 0.3804, 0.2157,  ..., 0.4863, 0.4118, 0.2039]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 1, 13, 15,  2,  2,  5,  3,  3,  2, 15, 17,  4,  2, 10,  3, 11]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.1490, 0.1490, 0.1608,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0078, 0.0078, 0.0235,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0353,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) tensor([[[0.0627, 0.0078, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0902, 0.0784, 0.0941,  ..., 0.1373, 0.1490, 0.1255],\n",
            "         [0.3373, 0.1686, 0.2706,  ..., 0.2118, 0.2235, 0.3059],\n",
            "         ...,\n",
            "         [0.0471, 0.0588, 0.0667,  ..., 0.0863, 0.0588, 0.0824],\n",
            "         [0.0275, 0.0980, 0.0824,  ..., 0.1569, 0.0588, 0.1765],\n",
            "         [0.0980, 0.1608, 0.0667,  ..., 0.0941, 0.0784, 0.1216]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([10,  7,  3,  9, 22,  2,  3,  3,  3, 22,  2,  2, 16, 24, 13,  3]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.1412, 0.1647, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.6196, 0.5529, 0.5294,  ..., 0.4275, 0.3961, 0.3451],\n",
            "         [0.6471, 0.5294, 0.5412,  ..., 0.3333, 0.4235, 0.3529],\n",
            "         [0.3882, 0.4392, 0.4627,  ..., 0.6392, 0.6078, 0.3333]]]) tensor([[[0.2118, 0.3412, 0.2157,  ..., 0.0549, 0.0000, 0.0000],\n",
            "         [0.1059, 0.4627, 0.0039,  ..., 0.0471, 0.0000, 0.0000],\n",
            "         [0.2235, 0.2431, 0.0549,  ..., 0.1333, 0.2471, 0.1098],\n",
            "         ...,\n",
            "         [0.6667, 0.3137, 0.3843,  ..., 0.6196, 0.5137, 0.7451],\n",
            "         [0.5882, 0.2157, 0.3216,  ..., 0.6549, 0.4471, 0.6275],\n",
            "         [0.2627, 0.4706, 0.5451,  ..., 0.4275, 0.3804, 0.4588]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([13, 22, 10, 11,  2, 24,  2, 10,  7,  3, 11, 22,  2,  3,  3, 22]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.2000, 0.2000, 0.2118,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.5843, 0.5843, 0.5843,  ..., 0.1647, 0.1451, 0.1451],\n",
            "         [0.3412, 0.3412, 0.3333,  ..., 0.0118, 0.0078, 0.0078],\n",
            "         ...,\n",
            "         [0.3294, 0.3294, 0.3137,  ..., 0.2549, 0.2510, 0.2510],\n",
            "         [0.4863, 0.4863, 0.5098,  ..., 0.2706, 0.2706, 0.2706],\n",
            "         [0.2588, 0.2588, 0.2549,  ..., 0.4745, 0.5020, 0.5020]]]) tensor([[[0.2431, 0.1333, 0.2275,  ..., 0.2902, 0.3333, 0.2588],\n",
            "         [0.3490, 0.4706, 0.5176,  ..., 0.3961, 0.2745, 0.3608],\n",
            "         [0.2471, 0.4196, 0.4118,  ..., 0.4196, 0.3020, 0.4745],\n",
            "         ...,\n",
            "         [0.5569, 0.6196, 0.5373,  ..., 0.4667, 0.5216, 0.4980],\n",
            "         [0.4667, 0.4824, 0.6039,  ..., 0.5490, 0.5059, 0.4824],\n",
            "         [0.4275, 0.4745, 0.5294,  ..., 0.4275, 0.3098, 0.4706]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 2, 22,  8, 15,  5,  2,  3,  2,  2, 14,  2, 15, 22,  3, 12,  2]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.2824, 0.3216, 0.3843,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.1686, 0.1647, 0.1569,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.3412, 0.3020, 0.2431,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.6314, 0.6157, 0.6000,  ..., 0.5765, 0.5059, 0.4627],\n",
            "         [0.2627, 0.3294, 0.4353,  ..., 0.5569, 0.5255, 0.5059],\n",
            "         [0.3529, 0.2745, 0.1412,  ..., 0.4353, 0.4980, 0.5333]]]) tensor([[[0.2627, 0.3843, 0.2784,  ..., 0.0275, 0.0000, 0.0000],\n",
            "         [0.0431, 0.1922, 0.0039,  ..., 0.1020, 0.0000, 0.0000],\n",
            "         [0.0039, 0.0118, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.6078, 0.6196, 0.4353,  ..., 0.6157, 0.6353, 0.5765],\n",
            "         [0.6118, 0.6784, 0.5373,  ..., 0.2510, 0.2235, 0.1255],\n",
            "         [0.1216, 0.1059, 0.1059,  ..., 0.0000, 0.0000, 0.0000]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([11,  2,  3,  3,  2, 10, 24,  3,  2,  6,  2,  7, 12, 12, 22,  9]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.3098, 0.2980, 0.0196,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.1412, 0.0471, 0.0275,  ..., 0.2196, 0.0118, 0.0000],\n",
            "         [0.2196, 0.3569, 0.2902,  ..., 0.4157, 0.2431, 0.3922],\n",
            "         ...,\n",
            "         [0.4078, 0.4392, 0.3255,  ..., 0.1294, 0.1216, 0.1176],\n",
            "         [0.1961, 0.0980, 0.0980,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0392, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) tensor([[[0.2431, 0.2784, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.3529, 0.2667, 0.2235],\n",
            "         [0.1843, 0.3176, 0.4196,  ..., 0.8275, 0.6627, 0.6196],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 7,  2, 22, 10, 10,  3, 24,  2, 18,  2, 24,  2,  3,  2,  2,  2]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.3647, 0.3529, 0.3216,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.8353, 0.5608, 0.1255,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.1216, 0.3176,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.3294, 0.2980, 0.2510,  ..., 0.2784, 0.2510, 0.2314],\n",
            "         [0.3569, 0.3098, 0.2392,  ..., 0.4039, 0.2863, 0.2118],\n",
            "         [0.4549, 0.3686, 0.2275,  ..., 0.0392, 0.0275, 0.0196]]]) tensor([[[0.1529, 0.0745, 0.0980,  ..., 0.1569, 0.0471, 0.0000],\n",
            "         [0.0000, 0.0039, 0.0196,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0471, 0.0549, 0.0588,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 2,  3, 10, 13, 14,  2, 12,  2,  3, 16,  2,  3,  2, 18,  2,  2]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.3020, 0.3020, 0.3137,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0667, 0.0667, 0.0824,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.2902, 0.2902, 0.2863,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.8431, 0.8431, 0.7216,  ..., 0.1608, 0.0824, 0.0824],\n",
            "         [0.7961, 0.7961, 0.6667,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) tensor([[[0.2118, 0.3059, 0.4510,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0235, 0.0941, 0.2039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0039, 0.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.7569, 0.6431, 0.4706,  ..., 0.4784, 0.2784, 0.1529],\n",
            "         [0.6235, 0.6196, 0.6157,  ..., 0.4471, 0.4824, 0.5059],\n",
            "         [0.7647, 0.6667, 0.5098,  ..., 0.3490, 0.4902, 0.5765]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 2,  3,  2,  8,  3,  2,  2,  3,  2,  3,  2, 19, 22,  2, 10, 17]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.2118, 0.3059, 0.4510,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0235, 0.0941, 0.2039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0039, 0.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.3412, 0.4314, 0.5725,  ..., 0.3176, 0.2941, 0.2784],\n",
            "         [0.4627, 0.4627, 0.4706,  ..., 0.5020, 0.5059, 0.5098],\n",
            "         [0.4863, 0.4863, 0.4824,  ..., 0.4471, 0.3373, 0.2667]]]) tensor([[[0.2784, 0.3922, 0.2980,  ..., 0.0196, 0.0000, 0.0000],\n",
            "         [0.0510, 0.2196, 0.0039,  ..., 0.1176, 0.0000, 0.0000],\n",
            "         [0.0039, 0.0157, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.6902, 0.5294, 0.5059,  ..., 0.6941, 0.4549, 0.5804],\n",
            "         [0.8471, 0.8118, 0.6667,  ..., 0.5961, 0.3098, 0.1725],\n",
            "         [0.3686, 0.4588, 0.7804,  ..., 0.2667, 0.3608, 0.4941]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 3,  2,  8,  3,  2, 24, 24, 24, 22,  9,  2,  1,  2,  3,  3, 23]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.4157, 0.4549, 0.5098,  ..., 0.0000, 0.0118, 0.0157],\n",
            "         [0.3922, 0.4510, 0.5412,  ..., 0.0039, 0.0196, 0.0353],\n",
            "         [0.0000, 0.0078, 0.0196,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) tensor([[[0.4157, 0.4549, 0.5098,  ..., 0.0000, 0.0118, 0.0157],\n",
            "         [0.3922, 0.4510, 0.5412,  ..., 0.0039, 0.0196, 0.0353],\n",
            "         [0.0000, 0.0078, 0.0196,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 3,  1,  7, 13, 13, 10,  4,  5,  3, 16, 24, 23, 24,  2,  2,  2]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.1412, 0.1647, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.2039, 0.4706, 0.5216,  ..., 0.4000, 0.5412, 0.5059],\n",
            "         [0.4902, 0.6392, 0.5255,  ..., 0.2431, 0.4706, 0.3451],\n",
            "         [0.4431, 0.4157, 0.4980,  ..., 0.2863, 0.5059, 0.5647]]]) tensor([[[0.0627, 0.0078, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0863, 0.0784, 0.0902,  ..., 0.1333, 0.1451, 0.1255],\n",
            "         [0.3373, 0.1647, 0.2706,  ..., 0.2157, 0.2275, 0.3059],\n",
            "         ...,\n",
            "         [0.1255, 0.1333, 0.1490,  ..., 0.1294, 0.1059, 0.0549],\n",
            "         [0.0863, 0.1333, 0.1098,  ..., 0.1647, 0.1294, 0.0745],\n",
            "         [0.1137, 0.3137, 0.4902,  ..., 0.1333, 0.1255, 0.1098]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([11,  3,  2, 11, 22,  2, 24,  2,  7,  9, 13, 24,  2,  3,  2, 24]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.2784, 0.3922, 0.2980,  ..., 0.0196, 0.0000, 0.0000],\n",
            "         [0.0510, 0.2196, 0.0039,  ..., 0.1176, 0.0000, 0.0000],\n",
            "         [0.0039, 0.0157, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.7059, 0.7098, 0.7529,  ..., 0.4078, 0.4392, 0.2157],\n",
            "         [0.4039, 0.6745, 0.3529,  ..., 0.3608, 0.0902, 0.2980],\n",
            "         [0.0980, 0.1922, 0.5059,  ..., 0.2275, 0.3882, 0.6824]]]) tensor([[[0.3686, 0.3961, 0.4353,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.1922, 0.1843, 0.1725,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.3412, 0.3020, 0.2431,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.6353, 0.6000, 0.5451,  ..., 0.4078, 0.3804, 0.3608],\n",
            "         [0.8000, 0.7098, 0.5647,  ..., 0.3412, 0.3569, 0.3686],\n",
            "         [0.5176, 0.4706, 0.4000,  ..., 0.5804, 0.6078, 0.6235]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 3,  4,  3,  2,  3,  2,  5,  2, 13, 20,  2,  2,  2, 22,  2,  2]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.2431, 0.2784, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.2275, 0.1490, 0.2000],\n",
            "         [0.4824, 0.4078, 0.2706,  ..., 0.4510, 0.4431, 0.4784],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) tensor([[[0.2824, 0.2824, 0.2824,  ..., 0.0902, 0.0902, 0.0902],\n",
            "         [0.2863, 0.2863, 0.2706,  ..., 0.2078, 0.2196, 0.2196],\n",
            "         [0.0000, 0.0000, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
            "         ...,\n",
            "         [0.2941, 0.2941, 0.2902,  ..., 0.2039, 0.1412, 0.1412],\n",
            "         [0.3020, 0.3020, 0.2627,  ..., 0.0392, 0.0314, 0.0314],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([24, 12, 14, 10, 12,  2,  2, 13,  3,  2, 13,  2,  4,  9,  2,  3]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.2627, 0.3922, 0.2784,  ..., 0.0275, 0.0000, 0.0000],\n",
            "         [0.0549, 0.2353, 0.0039,  ..., 0.1020, 0.0000, 0.0000],\n",
            "         [0.0078, 0.0392, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.1725, 0.2980, 0.3176,  ..., 0.4078, 0.4627, 0.5725],\n",
            "         [0.5765, 0.4275, 0.4627,  ..., 0.3294, 0.7059, 0.9176],\n",
            "         [0.3922, 0.2431, 0.1922,  ..., 0.8157, 0.5843, 0.3843]]]) tensor([[[0.2431, 0.1333, 0.2275,  ..., 0.2902, 0.3333, 0.2588],\n",
            "         [0.3490, 0.4706, 0.5176,  ..., 0.3961, 0.2745, 0.3608],\n",
            "         [0.2471, 0.4196, 0.4118,  ..., 0.4196, 0.3020, 0.4745],\n",
            "         ...,\n",
            "         [0.5569, 0.6196, 0.5373,  ..., 0.4667, 0.5216, 0.4980],\n",
            "         [0.4667, 0.4824, 0.6039,  ..., 0.5490, 0.5059, 0.4824],\n",
            "         [0.4275, 0.4745, 0.5294,  ..., 0.4235, 0.3098, 0.4706]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 4,  2, 24,  2,  5,  8, 11, 16,  1,  3,  2,  7,  2, 11, 16, 24]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.1843, 0.2902, 0.2000,  ..., 0.0824, 0.0000, 0.2706],\n",
            "         [0.1176, 0.2275, 0.2118,  ..., 0.0392, 0.0000, 0.1255],\n",
            "         [0.5765, 0.3373, 0.0314,  ..., 0.3333, 0.2392, 0.0314],\n",
            "         ...,\n",
            "         [0.2706, 0.5412, 0.5843,  ..., 0.4745, 0.2706, 0.6039],\n",
            "         [0.5765, 0.5843, 0.5529,  ..., 0.3843, 0.2196, 0.3804],\n",
            "         [0.4000, 0.5373, 0.9137,  ..., 0.6039, 0.4118, 0.5059]]]) tensor([[[0.2078, 0.3412, 0.2118,  ..., 0.0588, 0.0000, 0.0000],\n",
            "         [0.5137, 0.3333, 0.0000,  ..., 0.0471, 0.0000, 0.0000],\n",
            "         [0.3059, 0.2588, 0.1098,  ..., 0.0353, 0.0863, 0.0588],\n",
            "         ...,\n",
            "         [0.6510, 0.2588, 0.4353,  ..., 0.5529, 0.4980, 0.3098],\n",
            "         [0.5176, 0.5922, 0.6980,  ..., 0.4000, 0.3686, 0.2392],\n",
            "         [0.3137, 0.2392, 0.3137,  ..., 0.0000, 0.0000, 0.0000]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 3, 22, 24, 16,  2,  2, 22,  3,  2, 11, 11,  8,  3,  2,  8,  2]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.2431, 0.1333, 0.2275,  ..., 0.2902, 0.3333, 0.2588],\n",
            "         [0.3490, 0.4706, 0.5176,  ..., 0.3961, 0.2745, 0.3608],\n",
            "         [0.2471, 0.4196, 0.4118,  ..., 0.4196, 0.3020, 0.4745],\n",
            "         ...,\n",
            "         [0.4627, 0.5176, 0.5294,  ..., 0.4157, 0.5020, 0.5647],\n",
            "         [0.5686, 0.5059, 0.5647,  ..., 0.4863, 0.4902, 0.4275],\n",
            "         [0.5804, 0.6078, 0.5255,  ..., 0.4667, 0.4510, 0.4039]]]) tensor([[[0.3216, 0.2863, 0.0196,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.1686, 0.0157, 0.0275,  ..., 0.1765, 0.2941, 0.0431],\n",
            "         [0.2157, 0.4000, 0.5059,  ..., 0.4275, 0.6392, 0.2549],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 2,  2,  2, 24, 10, 17,  3,  2,  2, 22,  2, 13, 14, 24, 24, 22]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.1569, 0.2471, 0.3882,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.1333, 0.1451, 0.1569,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.3412, 0.3020, 0.2431,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.7451, 0.6314, 0.4549,  ..., 0.2745, 0.4745, 0.6000],\n",
            "         [0.7255, 0.6039, 0.4118,  ..., 0.3647, 0.5765, 0.7020],\n",
            "         [0.7176, 0.5333, 0.2353,  ..., 0.2627, 0.2941, 0.3137]]]) tensor([[[0.2275, 0.3529, 0.2353,  ..., 0.0471, 0.0000, 0.0000],\n",
            "         [0.4980, 0.3569, 0.0000,  ..., 0.0706, 0.0000, 0.0000],\n",
            "         [0.2824, 0.2235, 0.1059,  ..., 0.0784, 0.0941, 0.0588],\n",
            "         ...,\n",
            "         [0.1490, 0.4745, 0.6471,  ..., 0.3020, 0.2196, 0.2627],\n",
            "         [0.0510, 0.4235, 0.6078,  ..., 0.4980, 0.3098, 0.1333],\n",
            "         [0.0275, 0.3255, 0.5529,  ..., 0.7373, 0.4196, 0.5882]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([18,  2, 22,  3,  2, 22,  3,  2, 10, 24,  6,  3,  2,  3, 13, 11]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.4392, 0.3686, 0.2549,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.2118, 0.1765, 0.1216,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.3412, 0.3020, 0.2431,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.4824, 0.5373, 0.6275,  ..., 0.7843, 0.5686, 0.4353],\n",
            "         [0.4392, 0.5059, 0.6078,  ..., 0.6118, 0.6588, 0.6863],\n",
            "         [0.6510, 0.6118, 0.5451,  ..., 0.7216, 0.5333, 0.4157]]]) tensor([[[0.2431, 0.1333, 0.2275,  ..., 0.2902, 0.3333, 0.2588],\n",
            "         [0.3490, 0.4706, 0.5176,  ..., 0.3961, 0.2745, 0.3608],\n",
            "         [0.2471, 0.4196, 0.4118,  ..., 0.4196, 0.3020, 0.4745],\n",
            "         ...,\n",
            "         [0.4627, 0.5176, 0.5294,  ..., 0.4157, 0.5020, 0.5647],\n",
            "         [0.5686, 0.5059, 0.5647,  ..., 0.4863, 0.4902, 0.4275],\n",
            "         [0.5804, 0.6078, 0.5255,  ..., 0.4667, 0.4510, 0.4039]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([20,  2,  2,  3, 24,  2, 11,  3, 24,  2, 22, 10,  8,  1,  3, 23]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.2588, 0.2588, 0.2706,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.1294, 0.1294, 0.1373,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.1922, 0.1922, 0.1843,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.4196, 0.4196, 0.4275,  ..., 0.4902, 0.4353, 0.4353],\n",
            "         [0.5216, 0.5216, 0.4902,  ..., 0.5608, 0.5176, 0.5176],\n",
            "         [0.8275, 0.8275, 0.6824,  ..., 0.0902, 0.0784, 0.0784]]]) tensor([[[0.0902, 0.0392, 0.0000,  ..., 0.0039, 0.0196, 0.0157],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.1412, 0.1137, 0.1255,  ..., 0.0431, 0.1216, 0.0667],\n",
            "         ...,\n",
            "         [0.2588, 0.2392, 0.4471,  ..., 0.4706, 0.3569, 0.2902],\n",
            "         [0.1059, 0.2000, 0.2627,  ..., 0.1882, 0.1529, 0.0980],\n",
            "         [0.0784, 0.0667, 0.0824,  ..., 0.1216, 0.0902, 0.0431]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 4,  2,  2,  1, 22,  2, 22,  2, 18, 22, 11, 10,  2,  2, 11,  2]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.4431, 0.4824, 0.5529,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.2157, 0.2118, 0.2039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.3412, 0.3020, 0.2431,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.4392, 0.5020, 0.6039,  ..., 0.5333, 0.4157, 0.3373],\n",
            "         [0.5569, 0.4667, 0.3216,  ..., 0.5686, 0.5020, 0.4588],\n",
            "         [0.5373, 0.4706, 0.3608,  ..., 0.7686, 0.7804, 0.7882]]]) tensor([[[0.2353, 0.4471, 0.2196,  ..., 0.0549, 0.0000, 0.0000],\n",
            "         [0.2627, 0.4314, 0.0000,  ..., 0.0510, 0.0000, 0.0000],\n",
            "         [0.2627, 0.1843, 0.1490,  ..., 0.1961, 0.1608, 0.1098],\n",
            "         ...,\n",
            "         [0.7373, 0.6784, 0.4471,  ..., 0.7098, 0.6824, 0.4745],\n",
            "         [0.5961, 0.4745, 0.3608,  ..., 0.4157, 0.3569, 0.5176],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 2,  2,  2,  3,  2, 11,  3,  2,  3,  2,  5, 22,  5,  2, 24,  2]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.4510, 0.4039, 0.3294,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.7098, 0.5137, 0.2000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.2000, 0.1373, 0.0392,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) tensor([[[0.3255, 0.4706, 0.2392,  ..., 0.0471, 0.0000, 0.0000],\n",
            "         [0.2196, 0.4941, 0.0039,  ..., 0.0745, 0.0000, 0.0000],\n",
            "         [0.1098, 0.1176, 0.0627,  ..., 0.0196, 0.0118, 0.0157],\n",
            "         ...,\n",
            "         [0.4745, 0.3569, 0.3961,  ..., 0.6353, 0.3137, 0.4667],\n",
            "         [0.3098, 0.4118, 0.5255,  ..., 0.4706, 0.3451, 0.4275],\n",
            "         [0.3176, 0.6784, 0.6235,  ..., 0.6824, 0.7569, 0.5176]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 2, 17, 11, 13,  2,  3, 12,  2,  3,  3,  3, 24, 13,  9,  2,  3]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.3804, 0.3647, 0.1529,  ..., 0.0863, 0.0706, 0.1176],\n",
            "         [0.4196, 0.3412, 0.4902,  ..., 0.3176, 0.2588, 0.3686],\n",
            "         [0.5255, 0.3020, 0.4863,  ..., 0.1922, 0.3569, 0.5843],\n",
            "         ...,\n",
            "         [0.6275, 0.6980, 0.6667,  ..., 0.5412, 0.7490, 0.5373],\n",
            "         [0.4510, 0.4588, 0.4039,  ..., 0.3059, 0.4275, 0.3098],\n",
            "         [0.2706, 0.2235, 0.1569,  ..., 0.2314, 0.3098, 0.2431]]]) tensor([[[0.3529, 0.2510, 0.1843,  ..., 0.1725, 0.2314, 0.1451],\n",
            "         [0.5333, 0.3373, 0.4353,  ..., 0.4039, 0.3373, 0.2157],\n",
            "         [0.6118, 0.3725, 0.3843,  ..., 0.4627, 0.2941, 0.4588],\n",
            "         ...,\n",
            "         [0.4314, 0.5333, 0.4706,  ..., 0.4980, 0.5020, 0.5490],\n",
            "         [0.4627, 0.5686, 0.4941,  ..., 0.4431, 0.5059, 0.5098],\n",
            "         [0.2549, 0.4314, 0.3451,  ..., 0.1922, 0.2667, 0.1490]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([17, 15,  2, 21, 21,  3,  2,  3,  2, 10, 10,  7,  2, 16,  0, 24]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.1529, 0.0745, 0.0980,  ..., 0.1569, 0.0471, 0.0000],\n",
            "         [0.0000, 0.0039, 0.0196,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.0667, 0.0588, 0.0745,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) tensor([[[0.5882, 0.5059, 0.3686,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.3804, 0.4078, 0.4510,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.2000, 0.2157, 0.2392,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.5608, 0.5373, 0.4980,  ..., 0.4275, 0.4824, 0.5137],\n",
            "         [0.4275, 0.4353, 0.4431,  ..., 0.5608, 0.7255, 0.8314],\n",
            "         [0.6902, 0.6431, 0.5725,  ..., 0.4824, 0.6863, 0.8196]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 3, 22,  4, 14,  3,  7, 19,  2,  6,  2, 24, 24,  3,  3,  2,  2]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.2353, 0.1490, 0.1843,  ..., 0.0431, 0.1176, 0.1255],\n",
            "         [0.2745, 0.4824, 0.5490,  ..., 0.1098, 0.4275, 0.4549],\n",
            "         [0.4824, 0.6980, 0.6039,  ..., 0.2039, 0.3686, 0.4627],\n",
            "         ...,\n",
            "         [0.0275, 0.0118, 0.0196,  ..., 0.0824, 0.1059, 0.0549],\n",
            "         [0.2824, 0.2157, 0.4902,  ..., 0.1961, 0.2980, 0.2549],\n",
            "         [0.3529, 0.2706, 0.4078,  ..., 0.1882, 0.2118, 0.2353]]]) tensor([[[0.1412, 0.1647, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.5490, 0.2667, 0.5569,  ..., 0.4235, 0.4157, 0.6000],\n",
            "         [0.5020, 0.3098, 0.3608,  ..., 0.4431, 0.2549, 0.4235],\n",
            "         [0.4118, 0.3647, 0.2627,  ..., 0.4157, 0.3529, 0.4235]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 8,  2, 13, 18, 11,  3,  3,  6, 10,  2, 15,  2,  2,  2,  3,  3]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.2627, 0.3922, 0.2784,  ..., 0.0275, 0.0000, 0.0000],\n",
            "         [0.0549, 0.2353, 0.0039,  ..., 0.1020, 0.0000, 0.0000],\n",
            "         [0.0078, 0.0392, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.8902, 0.5686, 0.3529,  ..., 0.6196, 0.5373, 0.6078],\n",
            "         [0.6235, 0.4392, 0.1333,  ..., 0.4667, 0.4784, 0.4471],\n",
            "         [0.7647, 0.6471, 0.3490,  ..., 0.5765, 0.4235, 0.4824]]]) tensor([[[0.1961, 0.1961, 0.2118,  ..., 0.0039, 0.0039, 0.0039],\n",
            "         [0.2196, 0.2196, 0.3020,  ..., 0.1647, 0.1451, 0.1451],\n",
            "         [0.1059, 0.1059, 0.1333,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.2431, 0.2431, 0.2549,  ..., 0.3255, 0.3176, 0.3176],\n",
            "         [0.4941, 0.4941, 0.5020,  ..., 0.2627, 0.2745, 0.2745],\n",
            "         [0.3020, 0.3020, 0.2627,  ..., 0.5412, 0.5490, 0.5490]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([13, 13, 21,  2, 15,  2,  2,  2,  2, 13,  3,  9, 14,  2, 24, 11]) torch.LongTensor\n",
            "========================================\n",
            "tensor([[[0.4784, 0.4824, 0.4824,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.5176, 0.5255, 0.5412,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.1529, 0.4000,  ..., 0.0157, 0.1529, 0.2392],\n",
            "         ...,\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]) tensor([[[0.4392, 0.3412, 0.1765,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.2118, 0.1686, 0.0980,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         [0.3412, 0.3020, 0.2431,  ..., 0.0000, 0.0000, 0.0000],\n",
            "         ...,\n",
            "         [0.7608, 0.6784, 0.5412,  ..., 0.5373, 0.6275, 0.6824],\n",
            "         [0.5725, 0.5765, 0.5804,  ..., 0.5294, 0.7137, 0.8275],\n",
            "         [0.5922, 0.5490, 0.4784,  ..., 0.4549, 0.6353, 0.7451]]]) torch.FloatTensor torch.Size([16, 1, 224, 224])\n",
            "tensor([ 4, 24,  7, 13,  3, 10,  2, 15, 13,  2,  2,  2,  2,  3,  2,  2]) torch.LongTensor\n",
            "========================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-269755f275fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m20\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[1;32m    134\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2816\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2818\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2820\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzwh_FveLziU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    np_img = img.numpy()\n",
        "\n",
        "    plt.imshow(np.transpose(np_img, (1, 2, 0)))  # Convert (C, W, H) to (W, H, C)\n",
        "\n",
        "    print(np_img.shape)  # np_img shape\n",
        "    print((np.transpose(np_img, (1, 2, 0))).shape)  # transposed shape "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7dFOopxMBpA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7220720d-875a-4cd9-d7ee-d24b8e96f32a"
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "print(labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 6,  2, 17,  3, 11, 10, 18, 14,  3,  2,  3, 12,  2,  3,  3, 24])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xkethBEMCzi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "0ebd24c9-3642-4f4a-e27c-7b1573055b08"
      },
      "source": [
        "print(images.shape)\n",
        "imshow(torchvision.utils.make_grid(images, nrow=4))\n",
        "print(images.shape)\n",
        "print((torchvision.utils.make_grid(images)).shape)\n",
        "print(\"\".join(\"%5s \"%classes[labels[j]] for j in range(16)))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 1, 224, 224])\n",
            "(3, 906, 906)\n",
            "(906, 906, 3)\n",
            "torch.Size([16, 1, 224, 224])\n",
            "torch.Size([3, 454, 1810])\n",
            "C2LOP.P Allaple.A Obfuscator.AD Allaple.L Instantaccess Fakerean Rbot!gen Lolyda.AA3 Allaple.L Allaple.A Allaple.L Lolyda.AA1 Allaple.A Allaple.L Allaple.L Yuner.A \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5HQz_o3MFlu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "1e77394a-5b97-4270-a757-f644e31bb219"
      },
      "source": [
        "device = torch.device(\"cuda\")  # device = torch.device(\"cuda\")\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(224*224, 1000)\n",
        "        self.fc21 = nn.Linear(1000, 100)\n",
        "        self.fc22 = nn.Linear(1000, 100)\n",
        "        self.fc3 = nn.Linear(100, 1000)\n",
        "        self.fc4 = nn.Linear(1000, 224*224)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return self.fc21(h1), self.fc22(h1)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h3))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x.view(-1, 224*224))\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return self.decode(z), mu, logvar\n",
        "\n",
        "\n",
        "model = VAE().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "print(model)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VAE(\n",
            "  (fc1): Linear(in_features=50176, out_features=1000, bias=True)\n",
            "  (fc21): Linear(in_features=1000, out_features=100, bias=True)\n",
            "  (fc22): Linear(in_features=1000, out_features=100, bias=True)\n",
            "  (fc3): Linear(in_features=100, out_features=1000, bias=True)\n",
            "  (fc4): Linear(in_features=1000, out_features=50176, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9khLnNT3MG7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reconstruction + KL divergence losses summed over all elements and batch\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 224*224), reduction='sum')\n",
        "\n",
        "    # see Appendix B from VAE paper:\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "    # https://arxiv.org/abs/1312.6114\n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "    return BCE + KLD\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "        train_loss += loss.item()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 10 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader),\n",
        "                loss.item() / len(data)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "          epoch, train_loss / len(train_loader.dataset)))\n",
        "\n",
        "\n",
        "def test(epoch):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, _) in enumerate(test_loader):\n",
        "            data = data.to(device)\n",
        "            recon_batch, mu, logvar = model(data)\n",
        "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
        "            if i == 0:\n",
        "                n = min(data.size(0), 8)\n",
        "                comparison = torch.cat([data[:n],\n",
        "                                      recon_batch.view(16, 1, 224, 224)[:n]])\n",
        "                save_image(comparison.cpu(),\n",
        "                         './results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RlJbqlOMI4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0cc3893-7587-4956-f377-44a36159c69c"
      },
      "source": [
        "epochs = 10\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "        print(epoch)\n",
        "        train(epoch)\n",
        "        test(epoch)\n",
        "        with torch.no_grad():\n",
        "            sample = torch.randn(64, 100).to(device)\n",
        "            sample = model.decode(sample).cpu()\n",
        "            save_image(sample.view(64, 1, 224, 224),\n",
        "                       './results/sample_' + str(epoch) + '.png')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Train Epoch: 1 [0/7471 (0%)]\tLoss: 35144.554688\n",
            "Train Epoch: 1 [160/7471 (2%)]\tLoss: 37112.292969\n",
            "Train Epoch: 1 [320/7471 (4%)]\tLoss: 36045.386719\n",
            "Train Epoch: 1 [480/7471 (6%)]\tLoss: 36299.152344\n",
            "Train Epoch: 1 [640/7471 (9%)]\tLoss: 35308.894531\n",
            "Train Epoch: 1 [800/7471 (11%)]\tLoss: 36019.789062\n",
            "Train Epoch: 1 [960/7471 (13%)]\tLoss: 35335.089844\n",
            "Train Epoch: 1 [1120/7471 (15%)]\tLoss: 35478.378906\n",
            "Train Epoch: 1 [1280/7471 (17%)]\tLoss: 36800.453125\n",
            "Train Epoch: 1 [1440/7471 (19%)]\tLoss: 35627.734375\n",
            "Train Epoch: 1 [1600/7471 (21%)]\tLoss: 35588.335938\n",
            "Train Epoch: 1 [1760/7471 (24%)]\tLoss: 34776.808594\n",
            "Train Epoch: 1 [1920/7471 (26%)]\tLoss: 34689.984375\n",
            "Train Epoch: 1 [2080/7471 (28%)]\tLoss: 33599.160156\n",
            "Train Epoch: 1 [2240/7471 (30%)]\tLoss: 33220.531250\n",
            "Train Epoch: 1 [2400/7471 (32%)]\tLoss: 34695.988281\n",
            "Train Epoch: 1 [2560/7471 (34%)]\tLoss: 34285.089844\n",
            "Train Epoch: 1 [2720/7471 (36%)]\tLoss: 33368.648438\n",
            "Train Epoch: 1 [2880/7471 (39%)]\tLoss: 34473.574219\n",
            "Train Epoch: 1 [3040/7471 (41%)]\tLoss: 34099.796875\n",
            "Train Epoch: 1 [3200/7471 (43%)]\tLoss: 32031.796875\n",
            "Train Epoch: 1 [3360/7471 (45%)]\tLoss: 34246.367188\n",
            "Train Epoch: 1 [3520/7471 (47%)]\tLoss: 33857.082031\n",
            "Train Epoch: 1 [3680/7471 (49%)]\tLoss: 32408.269531\n",
            "Train Epoch: 1 [3840/7471 (51%)]\tLoss: 33123.343750\n",
            "Train Epoch: 1 [4000/7471 (54%)]\tLoss: 32864.679688\n",
            "Train Epoch: 1 [4160/7471 (56%)]\tLoss: 32779.210938\n",
            "Train Epoch: 1 [4320/7471 (58%)]\tLoss: 34258.949219\n",
            "Train Epoch: 1 [4480/7471 (60%)]\tLoss: 31962.285156\n",
            "Train Epoch: 1 [4640/7471 (62%)]\tLoss: 34113.640625\n",
            "Train Epoch: 1 [4800/7471 (64%)]\tLoss: 33265.117188\n",
            "Train Epoch: 1 [4960/7471 (66%)]\tLoss: 33736.597656\n",
            "Train Epoch: 1 [5120/7471 (69%)]\tLoss: 32720.892578\n",
            "Train Epoch: 1 [5280/7471 (71%)]\tLoss: 33812.472656\n",
            "Train Epoch: 1 [5440/7471 (73%)]\tLoss: 32059.425781\n",
            "Train Epoch: 1 [5600/7471 (75%)]\tLoss: 33311.781250\n",
            "Train Epoch: 1 [5760/7471 (77%)]\tLoss: 33726.566406\n",
            "Train Epoch: 1 [5920/7471 (79%)]\tLoss: 32384.890625\n",
            "Train Epoch: 1 [6080/7471 (81%)]\tLoss: 33125.527344\n",
            "Train Epoch: 1 [6240/7471 (84%)]\tLoss: 29853.271484\n",
            "Train Epoch: 1 [6400/7471 (86%)]\tLoss: 32942.562500\n",
            "Train Epoch: 1 [6560/7471 (88%)]\tLoss: 33790.109375\n",
            "Train Epoch: 1 [6720/7471 (90%)]\tLoss: 33453.289062\n",
            "Train Epoch: 1 [6880/7471 (92%)]\tLoss: 33470.117188\n",
            "Train Epoch: 1 [7040/7471 (94%)]\tLoss: 34110.066406\n",
            "Train Epoch: 1 [7200/7471 (96%)]\tLoss: 33172.207031\n",
            "Train Epoch: 1 [7360/7471 (99%)]\tLoss: 33713.984375\n",
            "====> Epoch: 1 Average loss: 34316.5399\n",
            "====> Test set loss: 33235.8615\n",
            "2\n",
            "Train Epoch: 2 [0/7471 (0%)]\tLoss: 33227.917969\n",
            "Train Epoch: 2 [160/7471 (2%)]\tLoss: 32699.068359\n",
            "Train Epoch: 2 [320/7471 (4%)]\tLoss: 32000.455078\n",
            "Train Epoch: 2 [480/7471 (6%)]\tLoss: 33383.984375\n",
            "Train Epoch: 2 [640/7471 (9%)]\tLoss: 32496.390625\n",
            "Train Epoch: 2 [800/7471 (11%)]\tLoss: 34030.609375\n",
            "Train Epoch: 2 [960/7471 (13%)]\tLoss: 32719.087891\n",
            "Train Epoch: 2 [1120/7471 (15%)]\tLoss: 33009.101562\n",
            "Train Epoch: 2 [1280/7471 (17%)]\tLoss: 31258.558594\n",
            "Train Epoch: 2 [1440/7471 (19%)]\tLoss: 34044.621094\n",
            "Train Epoch: 2 [1600/7471 (21%)]\tLoss: 32954.093750\n",
            "Train Epoch: 2 [1760/7471 (24%)]\tLoss: 33348.625000\n",
            "Train Epoch: 2 [1920/7471 (26%)]\tLoss: 32548.822266\n",
            "Train Epoch: 2 [2080/7471 (28%)]\tLoss: 33671.000000\n",
            "Train Epoch: 2 [2240/7471 (30%)]\tLoss: 33428.035156\n",
            "Train Epoch: 2 [2400/7471 (32%)]\tLoss: 33974.898438\n",
            "Train Epoch: 2 [2560/7471 (34%)]\tLoss: 32050.998047\n",
            "Train Epoch: 2 [2720/7471 (36%)]\tLoss: 33639.402344\n",
            "Train Epoch: 2 [2880/7471 (39%)]\tLoss: 33843.078125\n",
            "Train Epoch: 2 [3040/7471 (41%)]\tLoss: 33708.082031\n",
            "Train Epoch: 2 [3200/7471 (43%)]\tLoss: 33805.699219\n",
            "Train Epoch: 2 [3360/7471 (45%)]\tLoss: 33518.804688\n",
            "Train Epoch: 2 [3520/7471 (47%)]\tLoss: 32774.144531\n",
            "Train Epoch: 2 [3680/7471 (49%)]\tLoss: 32235.378906\n",
            "Train Epoch: 2 [3840/7471 (51%)]\tLoss: 33419.687500\n",
            "Train Epoch: 2 [4000/7471 (54%)]\tLoss: 30524.949219\n",
            "Train Epoch: 2 [4160/7471 (56%)]\tLoss: 32649.892578\n",
            "Train Epoch: 2 [4320/7471 (58%)]\tLoss: 32010.712891\n",
            "Train Epoch: 2 [4480/7471 (60%)]\tLoss: 34206.503906\n",
            "Train Epoch: 2 [4640/7471 (62%)]\tLoss: 33601.468750\n",
            "Train Epoch: 2 [4800/7471 (64%)]\tLoss: 32658.701172\n",
            "Train Epoch: 2 [4960/7471 (66%)]\tLoss: 33339.621094\n",
            "Train Epoch: 2 [5120/7471 (69%)]\tLoss: 32977.285156\n",
            "Train Epoch: 2 [5280/7471 (71%)]\tLoss: 33125.578125\n",
            "Train Epoch: 2 [5440/7471 (73%)]\tLoss: 31944.560547\n",
            "Train Epoch: 2 [5600/7471 (75%)]\tLoss: 33123.792969\n",
            "Train Epoch: 2 [5760/7471 (77%)]\tLoss: 32902.300781\n",
            "Train Epoch: 2 [5920/7471 (79%)]\tLoss: 33109.031250\n",
            "Train Epoch: 2 [6080/7471 (81%)]\tLoss: 33023.152344\n",
            "Train Epoch: 2 [6240/7471 (84%)]\tLoss: 32446.447266\n",
            "Train Epoch: 2 [6400/7471 (86%)]\tLoss: 33112.394531\n",
            "Train Epoch: 2 [6560/7471 (88%)]\tLoss: 33301.300781\n",
            "Train Epoch: 2 [6720/7471 (90%)]\tLoss: 31612.587891\n",
            "Train Epoch: 2 [6880/7471 (92%)]\tLoss: 32107.062500\n",
            "Train Epoch: 2 [7040/7471 (94%)]\tLoss: 32412.769531\n",
            "Train Epoch: 2 [7200/7471 (96%)]\tLoss: 31970.582031\n",
            "Train Epoch: 2 [7360/7471 (99%)]\tLoss: 32765.619141\n",
            "====> Epoch: 2 Average loss: 32843.8272\n",
            "====> Test set loss: 32684.2838\n",
            "3\n",
            "Train Epoch: 3 [0/7471 (0%)]\tLoss: 31062.437500\n",
            "Train Epoch: 3 [160/7471 (2%)]\tLoss: 33070.941406\n",
            "Train Epoch: 3 [320/7471 (4%)]\tLoss: 31543.087891\n",
            "Train Epoch: 3 [480/7471 (6%)]\tLoss: 31546.085938\n",
            "Train Epoch: 3 [640/7471 (9%)]\tLoss: 32325.132812\n",
            "Train Epoch: 3 [800/7471 (11%)]\tLoss: 32784.640625\n",
            "Train Epoch: 3 [960/7471 (13%)]\tLoss: 31911.376953\n",
            "Train Epoch: 3 [1120/7471 (15%)]\tLoss: 33407.242188\n",
            "Train Epoch: 3 [1280/7471 (17%)]\tLoss: 32725.451172\n",
            "Train Epoch: 3 [1440/7471 (19%)]\tLoss: 31697.923828\n",
            "Train Epoch: 3 [1600/7471 (21%)]\tLoss: 33720.839844\n",
            "Train Epoch: 3 [1760/7471 (24%)]\tLoss: 34117.207031\n",
            "Train Epoch: 3 [1920/7471 (26%)]\tLoss: 32053.687500\n",
            "Train Epoch: 3 [2080/7471 (28%)]\tLoss: 32432.695312\n",
            "Train Epoch: 3 [2240/7471 (30%)]\tLoss: 32506.662109\n",
            "Train Epoch: 3 [2400/7471 (32%)]\tLoss: 32657.654297\n",
            "Train Epoch: 3 [2560/7471 (34%)]\tLoss: 32008.392578\n",
            "Train Epoch: 3 [2720/7471 (36%)]\tLoss: 33510.019531\n",
            "Train Epoch: 3 [2880/7471 (39%)]\tLoss: 31774.156250\n",
            "Train Epoch: 3 [3040/7471 (41%)]\tLoss: 33125.855469\n",
            "Train Epoch: 3 [3200/7471 (43%)]\tLoss: 32913.726562\n",
            "Train Epoch: 3 [3360/7471 (45%)]\tLoss: 33536.164062\n",
            "Train Epoch: 3 [3520/7471 (47%)]\tLoss: 33520.785156\n",
            "Train Epoch: 3 [3680/7471 (49%)]\tLoss: 32214.203125\n",
            "Train Epoch: 3 [3840/7471 (51%)]\tLoss: 33207.476562\n",
            "Train Epoch: 3 [4000/7471 (54%)]\tLoss: 32357.398438\n",
            "Train Epoch: 3 [4160/7471 (56%)]\tLoss: 33462.707031\n",
            "Train Epoch: 3 [4320/7471 (58%)]\tLoss: 32984.410156\n",
            "Train Epoch: 3 [4480/7471 (60%)]\tLoss: 32478.111328\n",
            "Train Epoch: 3 [4640/7471 (62%)]\tLoss: 32953.570312\n",
            "Train Epoch: 3 [4800/7471 (64%)]\tLoss: 32621.140625\n",
            "Train Epoch: 3 [4960/7471 (66%)]\tLoss: 32414.726562\n",
            "Train Epoch: 3 [5120/7471 (69%)]\tLoss: 33233.257812\n",
            "Train Epoch: 3 [5280/7471 (71%)]\tLoss: 32929.687500\n",
            "Train Epoch: 3 [5440/7471 (73%)]\tLoss: 33086.757812\n",
            "Train Epoch: 3 [5600/7471 (75%)]\tLoss: 31550.441406\n",
            "Train Epoch: 3 [5760/7471 (77%)]\tLoss: 31992.140625\n",
            "Train Epoch: 3 [5920/7471 (79%)]\tLoss: 32681.964844\n",
            "Train Epoch: 3 [6080/7471 (81%)]\tLoss: 33949.812500\n",
            "Train Epoch: 3 [6240/7471 (84%)]\tLoss: 33740.253906\n",
            "Train Epoch: 3 [6400/7471 (86%)]\tLoss: 32712.771484\n",
            "Train Epoch: 3 [6560/7471 (88%)]\tLoss: 32154.558594\n",
            "Train Epoch: 3 [6720/7471 (90%)]\tLoss: 31652.556641\n",
            "Train Epoch: 3 [6880/7471 (92%)]\tLoss: 31482.498047\n",
            "Train Epoch: 3 [7040/7471 (94%)]\tLoss: 32217.738281\n",
            "Train Epoch: 3 [7200/7471 (96%)]\tLoss: 32962.203125\n",
            "Train Epoch: 3 [7360/7471 (99%)]\tLoss: 33225.527344\n",
            "====> Epoch: 3 Average loss: 32705.8193\n",
            "====> Test set loss: 32630.1413\n",
            "4\n",
            "Train Epoch: 4 [0/7471 (0%)]\tLoss: 32514.156250\n",
            "Train Epoch: 4 [160/7471 (2%)]\tLoss: 31508.023438\n",
            "Train Epoch: 4 [320/7471 (4%)]\tLoss: 31408.193359\n",
            "Train Epoch: 4 [480/7471 (6%)]\tLoss: 33898.789062\n",
            "Train Epoch: 4 [640/7471 (9%)]\tLoss: 33622.347656\n",
            "Train Epoch: 4 [800/7471 (11%)]\tLoss: 32282.298828\n",
            "Train Epoch: 4 [960/7471 (13%)]\tLoss: 32809.710938\n",
            "Train Epoch: 4 [1120/7471 (15%)]\tLoss: 32789.539062\n",
            "Train Epoch: 4 [1280/7471 (17%)]\tLoss: 33647.835938\n",
            "Train Epoch: 4 [1440/7471 (19%)]\tLoss: 32865.855469\n",
            "Train Epoch: 4 [1600/7471 (21%)]\tLoss: 32443.812500\n",
            "Train Epoch: 4 [1760/7471 (24%)]\tLoss: 32237.650391\n",
            "Train Epoch: 4 [1920/7471 (26%)]\tLoss: 32267.226562\n",
            "Train Epoch: 4 [2080/7471 (28%)]\tLoss: 32478.478516\n",
            "Train Epoch: 4 [2240/7471 (30%)]\tLoss: 30780.906250\n",
            "Train Epoch: 4 [2400/7471 (32%)]\tLoss: 33812.558594\n",
            "Train Epoch: 4 [2560/7471 (34%)]\tLoss: 32143.650391\n",
            "Train Epoch: 4 [2720/7471 (36%)]\tLoss: 33374.988281\n",
            "Train Epoch: 4 [2880/7471 (39%)]\tLoss: 34015.933594\n",
            "Train Epoch: 4 [3040/7471 (41%)]\tLoss: 33321.625000\n",
            "Train Epoch: 4 [3200/7471 (43%)]\tLoss: 32604.398438\n",
            "Train Epoch: 4 [3360/7471 (45%)]\tLoss: 33045.761719\n",
            "Train Epoch: 4 [3520/7471 (47%)]\tLoss: 32917.160156\n",
            "Train Epoch: 4 [3680/7471 (49%)]\tLoss: 31868.638672\n",
            "Train Epoch: 4 [3840/7471 (51%)]\tLoss: 33242.890625\n",
            "Train Epoch: 4 [4000/7471 (54%)]\tLoss: 32717.103516\n",
            "Train Epoch: 4 [4160/7471 (56%)]\tLoss: 33049.769531\n",
            "Train Epoch: 4 [4320/7471 (58%)]\tLoss: 33345.082031\n",
            "Train Epoch: 4 [4480/7471 (60%)]\tLoss: 31821.322266\n",
            "Train Epoch: 4 [4640/7471 (62%)]\tLoss: 32549.625000\n",
            "Train Epoch: 4 [4800/7471 (64%)]\tLoss: 33048.085938\n",
            "Train Epoch: 4 [4960/7471 (66%)]\tLoss: 33343.074219\n",
            "Train Epoch: 4 [5120/7471 (69%)]\tLoss: 33079.417969\n",
            "Train Epoch: 4 [5280/7471 (71%)]\tLoss: 32533.994141\n",
            "Train Epoch: 4 [5440/7471 (73%)]\tLoss: 33083.316406\n",
            "Train Epoch: 4 [5600/7471 (75%)]\tLoss: 32824.253906\n",
            "Train Epoch: 4 [5760/7471 (77%)]\tLoss: 32181.865234\n",
            "Train Epoch: 4 [5920/7471 (79%)]\tLoss: 33339.234375\n",
            "Train Epoch: 4 [6080/7471 (81%)]\tLoss: 31388.554688\n",
            "Train Epoch: 4 [6240/7471 (84%)]\tLoss: 32535.492188\n",
            "Train Epoch: 4 [6400/7471 (86%)]\tLoss: 33548.957031\n",
            "Train Epoch: 4 [6560/7471 (88%)]\tLoss: 32276.683594\n",
            "Train Epoch: 4 [6720/7471 (90%)]\tLoss: 32475.488281\n",
            "Train Epoch: 4 [6880/7471 (92%)]\tLoss: 31597.062500\n",
            "Train Epoch: 4 [7040/7471 (94%)]\tLoss: 31945.917969\n",
            "Train Epoch: 4 [7200/7471 (96%)]\tLoss: 30493.152344\n",
            "Train Epoch: 4 [7360/7471 (99%)]\tLoss: 32127.427734\n",
            "====> Epoch: 4 Average loss: 32507.0929\n",
            "====> Test set loss: 32631.2162\n",
            "5\n",
            "Train Epoch: 5 [0/7471 (0%)]\tLoss: 33137.457031\n",
            "Train Epoch: 5 [160/7471 (2%)]\tLoss: 33453.847656\n",
            "Train Epoch: 5 [320/7471 (4%)]\tLoss: 32521.152344\n",
            "Train Epoch: 5 [480/7471 (6%)]\tLoss: 32593.376953\n",
            "Train Epoch: 5 [640/7471 (9%)]\tLoss: 33217.058594\n",
            "Train Epoch: 5 [800/7471 (11%)]\tLoss: 32642.849609\n",
            "Train Epoch: 5 [960/7471 (13%)]\tLoss: 31279.716797\n",
            "Train Epoch: 5 [1120/7471 (15%)]\tLoss: 32088.750000\n",
            "Train Epoch: 5 [1280/7471 (17%)]\tLoss: 32599.390625\n",
            "Train Epoch: 5 [1440/7471 (19%)]\tLoss: 33436.734375\n",
            "Train Epoch: 5 [1600/7471 (21%)]\tLoss: 33404.460938\n",
            "Train Epoch: 5 [1760/7471 (24%)]\tLoss: 33553.914062\n",
            "Train Epoch: 5 [1920/7471 (26%)]\tLoss: 30913.123047\n",
            "Train Epoch: 5 [2080/7471 (28%)]\tLoss: 33011.355469\n",
            "Train Epoch: 5 [2240/7471 (30%)]\tLoss: 30609.208984\n",
            "Train Epoch: 5 [2400/7471 (32%)]\tLoss: 31527.099609\n",
            "Train Epoch: 5 [2560/7471 (34%)]\tLoss: 33849.636719\n",
            "Train Epoch: 5 [2720/7471 (36%)]\tLoss: 32553.097656\n",
            "Train Epoch: 5 [2880/7471 (39%)]\tLoss: 32222.283203\n",
            "Train Epoch: 5 [3040/7471 (41%)]\tLoss: 31534.265625\n",
            "Train Epoch: 5 [3200/7471 (43%)]\tLoss: 32832.300781\n",
            "Train Epoch: 5 [3360/7471 (45%)]\tLoss: 32622.123047\n",
            "Train Epoch: 5 [3520/7471 (47%)]\tLoss: 32942.179688\n",
            "Train Epoch: 5 [3680/7471 (49%)]\tLoss: 32491.449219\n",
            "Train Epoch: 5 [3840/7471 (51%)]\tLoss: 32345.888672\n",
            "Train Epoch: 5 [4000/7471 (54%)]\tLoss: 31939.480469\n",
            "Train Epoch: 5 [4160/7471 (56%)]\tLoss: 32445.060547\n",
            "Train Epoch: 5 [4320/7471 (58%)]\tLoss: 33758.425781\n",
            "Train Epoch: 5 [4480/7471 (60%)]\tLoss: 32857.824219\n",
            "Train Epoch: 5 [4640/7471 (62%)]\tLoss: 32055.818359\n",
            "Train Epoch: 5 [4800/7471 (64%)]\tLoss: 33504.761719\n",
            "Train Epoch: 5 [4960/7471 (66%)]\tLoss: 33005.847656\n",
            "Train Epoch: 5 [5120/7471 (69%)]\tLoss: 33549.402344\n",
            "Train Epoch: 5 [5280/7471 (71%)]\tLoss: 31373.007812\n",
            "Train Epoch: 5 [5440/7471 (73%)]\tLoss: 32529.533203\n",
            "Train Epoch: 5 [5600/7471 (75%)]\tLoss: 30826.279297\n",
            "Train Epoch: 5 [5760/7471 (77%)]\tLoss: 31634.382812\n",
            "Train Epoch: 5 [5920/7471 (79%)]\tLoss: 33732.515625\n",
            "Train Epoch: 5 [6080/7471 (81%)]\tLoss: 31966.529297\n",
            "Train Epoch: 5 [6240/7471 (84%)]\tLoss: 32734.250000\n",
            "Train Epoch: 5 [6400/7471 (86%)]\tLoss: 31206.041016\n",
            "Train Epoch: 5 [6560/7471 (88%)]\tLoss: 33699.351562\n",
            "Train Epoch: 5 [6720/7471 (90%)]\tLoss: 33092.039062\n",
            "Train Epoch: 5 [6880/7471 (92%)]\tLoss: 33141.105469\n",
            "Train Epoch: 5 [7040/7471 (94%)]\tLoss: 32666.732422\n",
            "Train Epoch: 5 [7200/7471 (96%)]\tLoss: 32828.742188\n",
            "Train Epoch: 5 [7360/7471 (99%)]\tLoss: 31645.607422\n",
            "====> Epoch: 5 Average loss: 37151.3793\n",
            "====> Test set loss: 32465.4595\n",
            "6\n",
            "Train Epoch: 6 [0/7471 (0%)]\tLoss: 32110.035156\n",
            "Train Epoch: 6 [160/7471 (2%)]\tLoss: 33372.777344\n",
            "Train Epoch: 6 [320/7471 (4%)]\tLoss: 31299.166016\n",
            "Train Epoch: 6 [480/7471 (6%)]\tLoss: 32664.457031\n",
            "Train Epoch: 6 [640/7471 (9%)]\tLoss: 32401.865234\n",
            "Train Epoch: 6 [800/7471 (11%)]\tLoss: 32968.960938\n",
            "Train Epoch: 6 [960/7471 (13%)]\tLoss: 32583.835938\n",
            "Train Epoch: 6 [1120/7471 (15%)]\tLoss: 33207.492188\n",
            "Train Epoch: 6 [1280/7471 (17%)]\tLoss: 31772.755859\n",
            "Train Epoch: 6 [1440/7471 (19%)]\tLoss: 32842.863281\n",
            "Train Epoch: 6 [1600/7471 (21%)]\tLoss: 33353.738281\n",
            "Train Epoch: 6 [1760/7471 (24%)]\tLoss: 33131.609375\n",
            "Train Epoch: 6 [1920/7471 (26%)]\tLoss: 32614.822266\n",
            "Train Epoch: 6 [2080/7471 (28%)]\tLoss: 32525.773438\n",
            "Train Epoch: 6 [2240/7471 (30%)]\tLoss: 32467.917969\n",
            "Train Epoch: 6 [2400/7471 (32%)]\tLoss: 33797.808594\n",
            "Train Epoch: 6 [2560/7471 (34%)]\tLoss: 31432.664062\n",
            "Train Epoch: 6 [2720/7471 (36%)]\tLoss: 32050.681641\n",
            "Train Epoch: 6 [2880/7471 (39%)]\tLoss: 33371.425781\n",
            "Train Epoch: 6 [3040/7471 (41%)]\tLoss: 31296.257812\n",
            "Train Epoch: 6 [3200/7471 (43%)]\tLoss: 33139.562500\n",
            "Train Epoch: 6 [3360/7471 (45%)]\tLoss: 33337.449219\n",
            "Train Epoch: 6 [3520/7471 (47%)]\tLoss: 32181.839844\n",
            "Train Epoch: 6 [3680/7471 (49%)]\tLoss: 32092.140625\n",
            "Train Epoch: 6 [3840/7471 (51%)]\tLoss: 32620.992188\n",
            "Train Epoch: 6 [4000/7471 (54%)]\tLoss: 33195.886719\n",
            "Train Epoch: 6 [4160/7471 (56%)]\tLoss: 33661.328125\n",
            "Train Epoch: 6 [4320/7471 (58%)]\tLoss: 32878.296875\n",
            "Train Epoch: 6 [4480/7471 (60%)]\tLoss: 32623.509766\n",
            "Train Epoch: 6 [4640/7471 (62%)]\tLoss: 32080.517578\n",
            "Train Epoch: 6 [4800/7471 (64%)]\tLoss: 33399.175781\n",
            "Train Epoch: 6 [4960/7471 (66%)]\tLoss: 31456.015625\n",
            "Train Epoch: 6 [5120/7471 (69%)]\tLoss: 31360.460938\n",
            "Train Epoch: 6 [5280/7471 (71%)]\tLoss: 31666.361328\n",
            "Train Epoch: 6 [5440/7471 (73%)]\tLoss: 33058.187500\n",
            "Train Epoch: 6 [5600/7471 (75%)]\tLoss: 32915.515625\n",
            "Train Epoch: 6 [5760/7471 (77%)]\tLoss: 33128.347656\n",
            "Train Epoch: 6 [5920/7471 (79%)]\tLoss: 31095.468750\n",
            "Train Epoch: 6 [6080/7471 (81%)]\tLoss: 32856.156250\n",
            "Train Epoch: 6 [6240/7471 (84%)]\tLoss: 31428.044922\n",
            "Train Epoch: 6 [6400/7471 (86%)]\tLoss: 32826.339844\n",
            "Train Epoch: 6 [6560/7471 (88%)]\tLoss: 31747.234375\n",
            "Train Epoch: 6 [6720/7471 (90%)]\tLoss: 32949.265625\n",
            "Train Epoch: 6 [6880/7471 (92%)]\tLoss: 31111.753906\n",
            "Train Epoch: 6 [7040/7471 (94%)]\tLoss: 30606.845703\n",
            "Train Epoch: 6 [7200/7471 (96%)]\tLoss: 32613.783203\n",
            "Train Epoch: 6 [7360/7471 (99%)]\tLoss: 33330.972656\n",
            "====> Epoch: 6 Average loss: 32451.7464\n",
            "====> Test set loss: 90794.5469\n",
            "7\n",
            "Train Epoch: 7 [0/7471 (0%)]\tLoss: 33171.839844\n",
            "Train Epoch: 7 [160/7471 (2%)]\tLoss: 33505.402344\n",
            "Train Epoch: 7 [320/7471 (4%)]\tLoss: 31781.996094\n",
            "Train Epoch: 7 [480/7471 (6%)]\tLoss: 33145.734375\n",
            "Train Epoch: 7 [640/7471 (9%)]\tLoss: 32619.451172\n",
            "Train Epoch: 7 [800/7471 (11%)]\tLoss: 29857.339844\n",
            "Train Epoch: 7 [960/7471 (13%)]\tLoss: 33774.738281\n",
            "Train Epoch: 7 [1120/7471 (15%)]\tLoss: 32339.140625\n",
            "Train Epoch: 7 [1280/7471 (17%)]\tLoss: 32606.994141\n",
            "Train Epoch: 7 [1440/7471 (19%)]\tLoss: 33356.113281\n",
            "Train Epoch: 7 [1600/7471 (21%)]\tLoss: 33279.933594\n",
            "Train Epoch: 7 [1760/7471 (24%)]\tLoss: 31402.833984\n",
            "Train Epoch: 7 [1920/7471 (26%)]\tLoss: 33276.492188\n",
            "Train Epoch: 7 [2080/7471 (28%)]\tLoss: 33274.101562\n",
            "Train Epoch: 7 [2240/7471 (30%)]\tLoss: 32015.539062\n",
            "Train Epoch: 7 [2400/7471 (32%)]\tLoss: 33439.269531\n",
            "Train Epoch: 7 [2560/7471 (34%)]\tLoss: 31474.724609\n",
            "Train Epoch: 7 [2720/7471 (36%)]\tLoss: 33829.847656\n",
            "Train Epoch: 7 [2880/7471 (39%)]\tLoss: 30904.431641\n",
            "Train Epoch: 7 [3040/7471 (41%)]\tLoss: 32661.531250\n",
            "Train Epoch: 7 [3200/7471 (43%)]\tLoss: 32412.167969\n",
            "Train Epoch: 7 [3360/7471 (45%)]\tLoss: 32638.746094\n",
            "Train Epoch: 7 [3520/7471 (47%)]\tLoss: 32234.746094\n",
            "Train Epoch: 7 [3680/7471 (49%)]\tLoss: 31462.800781\n",
            "Train Epoch: 7 [3840/7471 (51%)]\tLoss: 33890.449219\n",
            "Train Epoch: 7 [4000/7471 (54%)]\tLoss: 33524.207031\n",
            "Train Epoch: 7 [4160/7471 (56%)]\tLoss: 31653.824219\n",
            "Train Epoch: 7 [4320/7471 (58%)]\tLoss: 32348.734375\n",
            "Train Epoch: 7 [4480/7471 (60%)]\tLoss: 30547.171875\n",
            "Train Epoch: 7 [4640/7471 (62%)]\tLoss: 31799.445312\n",
            "Train Epoch: 7 [4800/7471 (64%)]\tLoss: 33305.238281\n",
            "Train Epoch: 7 [4960/7471 (66%)]\tLoss: 31837.076172\n",
            "Train Epoch: 7 [5120/7471 (69%)]\tLoss: 32786.992188\n",
            "Train Epoch: 7 [5280/7471 (71%)]\tLoss: 32270.447266\n",
            "Train Epoch: 7 [5440/7471 (73%)]\tLoss: 31980.207031\n",
            "Train Epoch: 7 [5600/7471 (75%)]\tLoss: 32745.148438\n",
            "Train Epoch: 7 [5760/7471 (77%)]\tLoss: 32486.281250\n",
            "Train Epoch: 7 [5920/7471 (79%)]\tLoss: 33906.742188\n",
            "Train Epoch: 7 [6080/7471 (81%)]\tLoss: 33242.582031\n",
            "Train Epoch: 7 [6240/7471 (84%)]\tLoss: 32358.544922\n",
            "Train Epoch: 7 [6400/7471 (86%)]\tLoss: 30070.861328\n",
            "Train Epoch: 7 [6560/7471 (88%)]\tLoss: 31396.287109\n",
            "Train Epoch: 7 [6720/7471 (90%)]\tLoss: 33281.746094\n",
            "Train Epoch: 7 [6880/7471 (92%)]\tLoss: 30949.388672\n",
            "Train Epoch: 7 [7040/7471 (94%)]\tLoss: 32674.667969\n",
            "Train Epoch: 7 [7200/7471 (96%)]\tLoss: 33505.367188\n",
            "Train Epoch: 7 [7360/7471 (99%)]\tLoss: 31688.072266\n",
            "====> Epoch: 7 Average loss: 6878829.1984\n",
            "====> Test set loss: 32515.8339\n",
            "8\n",
            "Train Epoch: 8 [0/7471 (0%)]\tLoss: 33003.738281\n",
            "Train Epoch: 8 [160/7471 (2%)]\tLoss: 32561.660156\n",
            "Train Epoch: 8 [320/7471 (4%)]\tLoss: 30902.035156\n",
            "Train Epoch: 8 [480/7471 (6%)]\tLoss: 32668.882812\n",
            "Train Epoch: 8 [640/7471 (9%)]\tLoss: 33039.046875\n",
            "Train Epoch: 8 [800/7471 (11%)]\tLoss: 33004.890625\n",
            "Train Epoch: 8 [960/7471 (13%)]\tLoss: 33140.839844\n",
            "Train Epoch: 8 [1120/7471 (15%)]\tLoss: 33064.953125\n",
            "Train Epoch: 8 [1280/7471 (17%)]\tLoss: 31069.728516\n",
            "Train Epoch: 8 [1440/7471 (19%)]\tLoss: 33071.488281\n",
            "Train Epoch: 8 [1600/7471 (21%)]\tLoss: 33734.617188\n",
            "Train Epoch: 8 [1760/7471 (24%)]\tLoss: 32553.572266\n",
            "Train Epoch: 8 [1920/7471 (26%)]\tLoss: 32995.671875\n",
            "Train Epoch: 8 [2080/7471 (28%)]\tLoss: 32704.052734\n",
            "Train Epoch: 8 [2240/7471 (30%)]\tLoss: 31126.898438\n",
            "Train Epoch: 8 [2400/7471 (32%)]\tLoss: 31614.429688\n",
            "Train Epoch: 8 [2560/7471 (34%)]\tLoss: 32220.478516\n",
            "Train Epoch: 8 [2720/7471 (36%)]\tLoss: 32292.574219\n",
            "Train Epoch: 8 [2880/7471 (39%)]\tLoss: 33080.078125\n",
            "Train Epoch: 8 [3040/7471 (41%)]\tLoss: 33717.343750\n",
            "Train Epoch: 8 [3200/7471 (43%)]\tLoss: 33703.375000\n",
            "Train Epoch: 8 [3360/7471 (45%)]\tLoss: 33451.683594\n",
            "Train Epoch: 8 [3520/7471 (47%)]\tLoss: 30852.816406\n",
            "Train Epoch: 8 [3680/7471 (49%)]\tLoss: 31002.615234\n",
            "Train Epoch: 8 [3840/7471 (51%)]\tLoss: 32651.541016\n",
            "Train Epoch: 8 [4000/7471 (54%)]\tLoss: 32117.029297\n",
            "Train Epoch: 8 [4160/7471 (56%)]\tLoss: 33612.320312\n",
            "Train Epoch: 8 [4320/7471 (58%)]\tLoss: 31880.351562\n",
            "Train Epoch: 8 [4480/7471 (60%)]\tLoss: 31034.703125\n",
            "Train Epoch: 8 [4640/7471 (62%)]\tLoss: 30934.867188\n",
            "Train Epoch: 8 [4800/7471 (64%)]\tLoss: 29522.154297\n",
            "Train Epoch: 8 [4960/7471 (66%)]\tLoss: 31037.861328\n",
            "Train Epoch: 8 [5120/7471 (69%)]\tLoss: 32818.871094\n",
            "Train Epoch: 8 [5280/7471 (71%)]\tLoss: 33064.171875\n",
            "Train Epoch: 8 [5440/7471 (73%)]\tLoss: 32509.705078\n",
            "Train Epoch: 8 [5600/7471 (75%)]\tLoss: 32203.814453\n",
            "Train Epoch: 8 [5760/7471 (77%)]\tLoss: 32607.429688\n",
            "Train Epoch: 8 [5920/7471 (79%)]\tLoss: 33294.320312\n",
            "Train Epoch: 8 [6080/7471 (81%)]\tLoss: 31521.685547\n",
            "Train Epoch: 8 [6240/7471 (84%)]\tLoss: 30982.222656\n",
            "Train Epoch: 8 [6400/7471 (86%)]\tLoss: 33369.347656\n",
            "Train Epoch: 8 [6560/7471 (88%)]\tLoss: 33186.812500\n",
            "Train Epoch: 8 [6720/7471 (90%)]\tLoss: 31502.810547\n",
            "Train Epoch: 8 [6880/7471 (92%)]\tLoss: 32718.693359\n",
            "Train Epoch: 8 [7040/7471 (94%)]\tLoss: 32899.972656\n",
            "Train Epoch: 8 [7200/7471 (96%)]\tLoss: 33420.125000\n",
            "Train Epoch: 8 [7360/7471 (99%)]\tLoss: 32468.775391\n",
            "====> Epoch: 8 Average loss: 32417.2791\n",
            "====> Test set loss: 32376.2964\n",
            "9\n",
            "Train Epoch: 9 [0/7471 (0%)]\tLoss: 33956.531250\n",
            "Train Epoch: 9 [160/7471 (2%)]\tLoss: 32795.304688\n",
            "Train Epoch: 9 [320/7471 (4%)]\tLoss: 32088.501953\n",
            "Train Epoch: 9 [480/7471 (6%)]\tLoss: 32089.623047\n",
            "Train Epoch: 9 [640/7471 (9%)]\tLoss: 33018.179688\n",
            "Train Epoch: 9 [800/7471 (11%)]\tLoss: 31264.068359\n",
            "Train Epoch: 9 [960/7471 (13%)]\tLoss: 32742.039062\n",
            "Train Epoch: 9 [1120/7471 (15%)]\tLoss: 31522.271484\n",
            "Train Epoch: 9 [1280/7471 (17%)]\tLoss: 32637.355469\n",
            "Train Epoch: 9 [1440/7471 (19%)]\tLoss: 32428.148438\n",
            "Train Epoch: 9 [1600/7471 (21%)]\tLoss: 31382.595703\n",
            "Train Epoch: 9 [1760/7471 (24%)]\tLoss: 32844.367188\n",
            "Train Epoch: 9 [1920/7471 (26%)]\tLoss: 30610.716797\n",
            "Train Epoch: 9 [2080/7471 (28%)]\tLoss: 30899.304688\n",
            "Train Epoch: 9 [2240/7471 (30%)]\tLoss: 32825.132812\n",
            "Train Epoch: 9 [2400/7471 (32%)]\tLoss: 32054.037109\n",
            "Train Epoch: 9 [2560/7471 (34%)]\tLoss: 32293.121094\n",
            "Train Epoch: 9 [2720/7471 (36%)]\tLoss: 31675.191406\n",
            "Train Epoch: 9 [2880/7471 (39%)]\tLoss: 32134.183594\n",
            "Train Epoch: 9 [3040/7471 (41%)]\tLoss: 32350.763672\n",
            "Train Epoch: 9 [3200/7471 (43%)]\tLoss: 32734.812500\n",
            "Train Epoch: 9 [3360/7471 (45%)]\tLoss: 33754.191406\n",
            "Train Epoch: 9 [3520/7471 (47%)]\tLoss: 32167.912109\n",
            "Train Epoch: 9 [3680/7471 (49%)]\tLoss: 32967.691406\n",
            "Train Epoch: 9 [3840/7471 (51%)]\tLoss: 32879.953125\n",
            "Train Epoch: 9 [4000/7471 (54%)]\tLoss: 33553.964844\n",
            "Train Epoch: 9 [4160/7471 (56%)]\tLoss: 33617.355469\n",
            "Train Epoch: 9 [4320/7471 (58%)]\tLoss: 32696.582031\n",
            "Train Epoch: 9 [4480/7471 (60%)]\tLoss: 30645.248047\n",
            "Train Epoch: 9 [4640/7471 (62%)]\tLoss: 31887.177734\n",
            "Train Epoch: 9 [4800/7471 (64%)]\tLoss: 32462.029297\n",
            "Train Epoch: 9 [4960/7471 (66%)]\tLoss: 33448.261719\n",
            "Train Epoch: 9 [5120/7471 (69%)]\tLoss: 32306.326172\n",
            "Train Epoch: 9 [5280/7471 (71%)]\tLoss: 31258.117188\n",
            "Train Epoch: 9 [5440/7471 (73%)]\tLoss: 32022.138672\n",
            "Train Epoch: 9 [5600/7471 (75%)]\tLoss: 32903.054688\n",
            "Train Epoch: 9 [5760/7471 (77%)]\tLoss: 31287.455078\n",
            "Train Epoch: 9 [5920/7471 (79%)]\tLoss: 33190.503906\n",
            "Train Epoch: 9 [6080/7471 (81%)]\tLoss: 32994.093750\n",
            "Train Epoch: 9 [6240/7471 (84%)]\tLoss: 34148.320312\n",
            "Train Epoch: 9 [6400/7471 (86%)]\tLoss: 33085.671875\n",
            "Train Epoch: 9 [6560/7471 (88%)]\tLoss: 32706.494141\n",
            "Train Epoch: 9 [6720/7471 (90%)]\tLoss: 32677.373047\n",
            "Train Epoch: 9 [6880/7471 (92%)]\tLoss: 32973.023438\n",
            "Train Epoch: 9 [7040/7471 (94%)]\tLoss: 33467.562500\n",
            "Train Epoch: 9 [7200/7471 (96%)]\tLoss: 33452.246094\n",
            "Train Epoch: 9 [7360/7471 (99%)]\tLoss: 32517.537109\n",
            "====> Epoch: 9 Average loss: 32565.9557\n",
            "====> Test set loss: 32953.5387\n",
            "10\n",
            "Train Epoch: 10 [0/7471 (0%)]\tLoss: 33761.359375\n",
            "Train Epoch: 10 [160/7471 (2%)]\tLoss: 33279.457031\n",
            "Train Epoch: 10 [320/7471 (4%)]\tLoss: 34064.187500\n",
            "Train Epoch: 10 [480/7471 (6%)]\tLoss: 32660.910156\n",
            "Train Epoch: 10 [640/7471 (9%)]\tLoss: 32599.339844\n",
            "Train Epoch: 10 [800/7471 (11%)]\tLoss: 32786.308594\n",
            "Train Epoch: 10 [960/7471 (13%)]\tLoss: 31461.775391\n",
            "Train Epoch: 10 [1120/7471 (15%)]\tLoss: 31960.640625\n",
            "Train Epoch: 10 [1280/7471 (17%)]\tLoss: 33733.781250\n",
            "Train Epoch: 10 [1440/7471 (19%)]\tLoss: 32502.058594\n",
            "Train Epoch: 10 [1600/7471 (21%)]\tLoss: 32909.781250\n",
            "Train Epoch: 10 [1760/7471 (24%)]\tLoss: 32045.589844\n",
            "Train Epoch: 10 [1920/7471 (26%)]\tLoss: 32661.197266\n",
            "Train Epoch: 10 [2080/7471 (28%)]\tLoss: 31033.441406\n",
            "Train Epoch: 10 [2240/7471 (30%)]\tLoss: 33442.613281\n",
            "Train Epoch: 10 [2400/7471 (32%)]\tLoss: 32662.812500\n",
            "Train Epoch: 10 [2560/7471 (34%)]\tLoss: 33498.777344\n",
            "Train Epoch: 10 [2720/7471 (36%)]\tLoss: 32237.910156\n",
            "Train Epoch: 10 [2880/7471 (39%)]\tLoss: 32611.359375\n",
            "Train Epoch: 10 [3040/7471 (41%)]\tLoss: 32507.800781\n",
            "Train Epoch: 10 [3200/7471 (43%)]\tLoss: 31756.894531\n",
            "Train Epoch: 10 [3360/7471 (45%)]\tLoss: 31850.773438\n",
            "Train Epoch: 10 [3520/7471 (47%)]\tLoss: 32460.984375\n",
            "Train Epoch: 10 [3680/7471 (49%)]\tLoss: 32228.937500\n",
            "Train Epoch: 10 [3840/7471 (51%)]\tLoss: 31712.259766\n",
            "Train Epoch: 10 [4000/7471 (54%)]\tLoss: 32730.013672\n",
            "Train Epoch: 10 [4160/7471 (56%)]\tLoss: 32639.251953\n",
            "Train Epoch: 10 [4320/7471 (58%)]\tLoss: 33690.855469\n",
            "Train Epoch: 10 [4480/7471 (60%)]\tLoss: 33202.773438\n",
            "Train Epoch: 10 [4640/7471 (62%)]\tLoss: 33797.636719\n",
            "Train Epoch: 10 [4800/7471 (64%)]\tLoss: 33176.800781\n",
            "Train Epoch: 10 [4960/7471 (66%)]\tLoss: 32880.839844\n",
            "Train Epoch: 10 [5120/7471 (69%)]\tLoss: 31786.640625\n",
            "Train Epoch: 10 [5280/7471 (71%)]\tLoss: 32210.189453\n",
            "Train Epoch: 10 [5440/7471 (73%)]\tLoss: 31600.628906\n",
            "Train Epoch: 10 [5600/7471 (75%)]\tLoss: 33295.398438\n",
            "Train Epoch: 10 [5760/7471 (77%)]\tLoss: 33669.562500\n",
            "Train Epoch: 10 [5920/7471 (79%)]\tLoss: 32908.734375\n",
            "Train Epoch: 10 [6080/7471 (81%)]\tLoss: 31931.660156\n",
            "Train Epoch: 10 [6240/7471 (84%)]\tLoss: 33227.984375\n",
            "Train Epoch: 10 [6400/7471 (86%)]\tLoss: 32395.128906\n",
            "Train Epoch: 10 [6560/7471 (88%)]\tLoss: 32736.998047\n",
            "Train Epoch: 10 [6720/7471 (90%)]\tLoss: 33175.050781\n",
            "Train Epoch: 10 [6880/7471 (92%)]\tLoss: 33619.558594\n",
            "Train Epoch: 10 [7040/7471 (94%)]\tLoss: 32973.910156\n",
            "Train Epoch: 10 [7200/7471 (96%)]\tLoss: 31549.468750\n",
            "Train Epoch: 10 [7360/7471 (99%)]\tLoss: 30592.187500\n",
            "====> Epoch: 10 Average loss: 32804.2513\n",
            "====> Test set loss: 32572.7599\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-etHurkWMp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}