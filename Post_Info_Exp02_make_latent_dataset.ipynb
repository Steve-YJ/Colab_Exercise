{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Post-Info_Exp02_make_latent_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPNdXQM2Aj7QGbQxqqcRpkB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Steve-YJ/Colab_Exercise/blob/master/Post_Info_Exp02_make_latent_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unmaetS6775A",
        "colab_type": "text"
      },
      "source": [
        "# README.MD\n",
        "* Post-InfoSec-Exp02<br>\n",
        "    ‚úÖ Complete\n",
        "    * Makedir-automatically\n",
        "        * e.g) Post_Exp01\n",
        "            * recon_sampling\n",
        "            * plot_train_test_loss\n",
        "            * plot_latent_vector<br>\n",
        "            \n",
        "    * Add Classifier\n",
        "        * higher accuracy\n",
        "<br>\n",
        "\n",
        "üîñ In this Notebook\n",
        "* Simplify code for additional training \n",
        "    * üìå Load_VAE_State_dict\n",
        "    * üìå Extract Latent vector & make Training set\n",
        "        * (9339, 100) -> add label ==> (9339, 101)\n",
        "        * make pandas dataframe for ML Training\n",
        "            * Save Pandas as csv(for future training)\n",
        "    * üìå Classify it & Improve it\n",
        "    \n",
        "* ‚úÖ Check Point\n",
        "    * Keep training Exp05<br>\n",
        "    Exp05ÏóêÏÑú Ïã§ÌóòÏù¥ ÏûòÎêú Î™®Îç∏ ParameterÎ•º Í∞ÄÏßÄÍ≥† Ï∂îÍ∞ÄÎ°ú Ïã§ÌóòÌï©ÎãàÎã§.\n",
        "        * After Epoch 10, Train it\n",
        "        * Reduce Learning rate: 1e-5 to 1e-3\n",
        "    * ModelÏùÑ Îã§Ïãú trainingÏãúÌÇ¨ ÌïÑÏöîÎäî ÏóÜÏäµÎãàÎã§. -20.07.23.Thur-\n",
        "\n",
        "## Reference\n",
        "* Reference repository: https://github.com/pytorch/examples/tree/master/vae\n",
        "\n",
        "* Reference for Visualization: https://github.com/tayden/VAE-Latent-Space-Explorer/blob/master/scripts/VAE.ipynb\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdftPIvEY7Jt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4808373e-0af3-4ae4-a9ba-eb880270a7b4"
      },
      "source": [
        "! python --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xA26hx-ZKss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61976775-0254-4696-d160-b92fcea85e25"
      },
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XiHjsMD8MO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "62c7bbf3-ebab-420d-871b-ad3a1900d1e1"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Jul 23 12:14:31 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.51.05    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDUY6YNV8Vs9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "os9GS8R_KCWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "3e330255-e8ad-4364-a3d9-dec3bd6ed2e5"
      },
      "source": [
        "# drive mount\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XeJBewoLDOr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9c4d14f0-7100-43d8-9a30-4e50f7c014ea"
      },
      "source": [
        "%cd drive/My\\ Drive/Post_InfoSec_Exps\n",
        "! pwd"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Post_InfoSec_Exps\n",
            "/content/drive/My Drive/Post_InfoSec_Exps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1BBWVWCzYUu",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "Add\n",
        "\n",
        "* makedir Automatically\n",
        "    * \n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq1dTrJFzdiB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e07210a6-caab-40ae-f81d-5cfcccf0f5d5"
      },
      "source": [
        "import os\n",
        "path = os.getcwd()\n",
        "# print(path)\n",
        "print(\"The current working directory is %s\" %path)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The current working directory is /content/drive/My Drive/Post_InfoSec_Exps\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_DlwsPu0v1b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e73326bd-ad35-4e4a-b3cd-e1f62c507277"
      },
      "source": [
        "%cd Post_Exp02\n",
        "path = os.getcwd()\n",
        "# print(path)\n",
        "! pwd\n",
        "path"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Post_InfoSec_Exps/Post_Exp02\n",
            "/content/drive/My Drive/Post_InfoSec_Exps/Post_Exp02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Post_InfoSec_Exps/Post_Exp02'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8fmqK4t0_M_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "8ac3c9ac-c703-46e8-8bdd-b6105fb9c221"
      },
      "source": [
        "'''\n",
        "# Ïã§ÌóòÏùÑ Ìïú Î≤à ÎÅùÎÇ∏ Ïù¥ÌõÑÎ°úÎäî ÏÇ¨Ïö© x\n",
        "# make directory\n",
        "\n",
        "def makedir(dirname):\n",
        "    \n",
        "    try:\n",
        "        os.mkdir(path + '/' + dirname)\n",
        "    except OSError:\n",
        "        print(\"Creation of the directory %s failed\" % path)\n",
        "    else:\n",
        "        print(\"Successfully created the directory %s\" % path)\n",
        "    return\n",
        "\n",
        "dir_list = ['recon_sampling', 'plot_train_test_loss', 'plot_latent_vector']\n",
        "\n",
        "for i in range(len(dir_list)):\n",
        "    print(dir_list[i])\n",
        "    print(path + '/' + dir_list[i])\n",
        "    makedir(dir_list[i])\n",
        "\n",
        "\n",
        "! ls\n",
        "'''"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recon_sampling\n",
            "/content/drive/My Drive/Post_InfoSec_Exps/Post_Exp02/recon_sampling\n",
            "Successfully created the directory /content/drive/My Drive/Post_InfoSec_Exps/Post_Exp02\n",
            "plot_train_test_loss\n",
            "/content/drive/My Drive/Post_InfoSec_Exps/Post_Exp02/plot_train_test_loss\n",
            "Successfully created the directory /content/drive/My Drive/Post_InfoSec_Exps/Post_Exp02\n",
            "plot_latent_vector\n",
            "/content/drive/My Drive/Post_InfoSec_Exps/Post_Exp02/plot_latent_vector\n",
            "Successfully created the directory /content/drive/My Drive/Post_InfoSec_Exps/Post_Exp02\n",
            "Exp05_model_save_10Epochs.pth  plot_train_test_loss\n",
            "plot_latent_vector\t       recon_sampling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbW9zos52P22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "154e4071-0392-4e0f-86cf-67b2e8880893"
      },
      "source": [
        "print(type(dir_list[0]))\n",
        "print(dir_list[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'str'>\n",
            "recon_sampling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YQ-tynL2Saj",
        "colab_type": "text"
      },
      "source": [
        "## 01. Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Dmz78nUKxGx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "60e65f40-ae54-41a1-f76e-cdca041620d9"
      },
      "source": [
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        " \n",
        "# https://towardsdatascience.com/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b\n",
        "import seaborn as sns\n",
        "\n",
        "# save single numpy array\n",
        "# https://numpy.org/doc/stable/reference/generated/numpy.save.html#numpy.save\n",
        "from tempfile import TemporaryFile\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piAH_1eCafJC",
        "colab_type": "text"
      },
      "source": [
        "## 02. Data Preprocessing\n",
        "* Load dataset\n",
        "* preprocess it\n",
        "    * transforms\n",
        "    * make custom dataset\n",
        "    * train_test split: <code>torch.utils.data.random_split</code>\n",
        "    * train_test_loader\n",
        "\n",
        "### Work Flow\n",
        "* transforms module ÏÇ¨Ïö©Ìï¥ÏÑú image data compose ÌïòÍ∏∞\n",
        "    * size Ï°∞Ï†ï, normalize, tensor Î≥ÄÌôò\n",
        "* ImageFolderÎ•º Ïù¥Ïö©Ìï¥ dataload\n",
        "* dataset split: train dataset, test dataset\n",
        "* DataLoaderÎ°ú batchÎã®ÏúÑ dataset Î∂àÎü¨Ïò§Í∏∞"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0trLTWY5Edx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "033973ec-054f-46fb-8e4d-d51c0eed999e"
      },
      "source": [
        "! pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Post_InfoSec_Exps/Post_Exp01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05u2akkWKR4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms = transforms.Compose([\n",
        "                                transforms.Resize((224, 224)),                # Change size of Image to (224, 224)\n",
        "                                transforms.Grayscale(num_output_channels=1),  # Makes it 1-dimension channel\n",
        "                                transforms.ToTensor(),                        # Convert a PIL Image or numpy.ndarray to tensor.\n",
        "                                                                              # Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8\n",
        "                                                                              # In the other cases, tensors are returned without scaling.\n",
        "                                # transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "                                \n",
        "                                ])\n",
        "\n",
        "# make custom dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='../../InformationSecurity_Summer/malimg',\n",
        "                                            transform=transforms)  # make custom dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdfkHTBrgA5U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "826105e1-dfca-48ae-e1fc-763974c0d0d8"
      },
      "source": [
        "trainset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset ImageFolder\n",
              "    Number of datapoints: 9339\n",
              "    Root location: ../../InformationSecurity_Summer/malimg\n",
              "    StandardTransform\n",
              "Transform: Compose(\n",
              "               Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR)\n",
              "               Grayscale(num_output_channels=1)\n",
              "               ToTensor()\n",
              "           )"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lx1-yQH1KutR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "142539f1-72be-402d-f7ef-320923c53df7"
      },
      "source": [
        "# classes = trainset.classes\n",
        "classes = trainset.classes\n",
        "classes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Adialer.C',\n",
              " 'Agent.FYI',\n",
              " 'Allaple.A',\n",
              " 'Allaple.L',\n",
              " 'Alueron.gen!J',\n",
              " 'Autorun.K',\n",
              " 'C2LOP.P',\n",
              " 'C2LOP.gen!g',\n",
              " 'Dialplatform.B',\n",
              " 'Dontovo.A',\n",
              " 'Fakerean',\n",
              " 'Instantaccess',\n",
              " 'Lolyda.AA1',\n",
              " 'Lolyda.AA2',\n",
              " 'Lolyda.AA3',\n",
              " 'Lolyda.AT',\n",
              " 'Malex.gen!J',\n",
              " 'Obfuscator.AD',\n",
              " 'Rbot!gen',\n",
              " 'Skintrim.N',\n",
              " 'Swizzor.gen!E',\n",
              " 'Swizzor.gen!I',\n",
              " 'VB.AT',\n",
              " 'Wintrim.BX',\n",
              " 'Yuner.A']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB6yE7h9Lu9A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "85427345-f84b-4693-b77a-088a488e19df"
      },
      "source": [
        "full_dataset = trainset\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "print(train_size, test_size)\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7471 1868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvaDlRrGLm5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_dataset,\n",
        "                         batch_size=16,\n",
        "                         shuffle=True,\n",
        "                         pin_memory=True) \n",
        "test_loader = DataLoader(test_dataset,\n",
        "                        batch_size=16,\n",
        "                        shuffle=True,\n",
        "                        pin_memory=True)  # Instead, we recommend using automatic memory pinning (i.e., setting pin_memory=True)\n",
        "                                          #  which enables fast data transfer to CUDA-enabled GPUs\n",
        "\n",
        "# First, insert all test dataset\n",
        "# test_loader_10: testloader for latent vector visualization\n",
        "test_loader_10 = DataLoader(test_dataset,\n",
        "                        batch_size=1868,\n",
        "                        shuffle=True,\n",
        "                        pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hzwh_FveLziU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    np_img = img.numpy()\n",
        "\n",
        "    plt.imshow(np.transpose(np_img, (1, 2, 0)))  # Convert (C, W, H) to (W, H, C)\n",
        "\n",
        "    print(np_img.shape)  # np_img shape\n",
        "    print((np.transpose(np_img, (1, 2, 0))).shape)  # transposed shape "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7dFOopxMBpA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cda73c81-0949-4b5b-8cc2-63f30f3c05df"
      },
      "source": [
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "print(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([24, 11,  4,  3, 11,  2,  3,  2, 14, 14,  2,  3,  3, 24,  2,  2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xkethBEMCzi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "f4ba22da-4fd9-47d4-9b4e-b9196cde5e8f"
      },
      "source": [
        "print(images.shape)\n",
        "imshow(torchvision.utils.make_grid(images, nrow=4))\n",
        "print(images.shape)\n",
        "print((torchvision.utils.make_grid(images)).shape)\n",
        "print(\"\".join(\"%5s \"%classes[labels[j]] for j in range(16)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 1, 224, 224])\n",
            "(3, 906, 906)\n",
            "(906, 906, 3)\n",
            "torch.Size([16, 1, 224, 224])\n",
            "torch.Size([3, 454, 1810])\n",
            "Yuner.A Instantaccess Alueron.gen!J Allaple.L Instantaccess Allaple.A Allaple.L Allaple.A Lolyda.AA3 Lolyda.AA3 Allaple.A Allaple.L Allaple.L Yuner.A Allaple.A Allaple.A \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0K7aSEKd3PD",
        "colab_type": "text"
      },
      "source": [
        "## 03. Define VAE Class\n",
        "* Initialize\n",
        "    * (224, 224) input Ïù¥ÎØ∏ÏßÄÎ•º ÌÜµÌï¥ 1Ï∞®Ïõê 100Í∞úÏùò latent vectorÎ•º ÏÉùÏÑ±ÌïòÎäî EncoderÎÑ§Ìä∏ÏõåÌÅ¨ Ï†ïÏùò\n",
        "    * 100Í∞úÏùò latent vectorÎ°úÎ∂ÄÌÑ∞ X_hatÏùÑ Î≥µÏõêÌïòÎäî Decoder Network Ï†ïÏùò\n",
        "* encode\n",
        "* reparameterize\n",
        "* decode\n",
        "* forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5HQz_o3MFlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\")  # device = torch.device(\"cuda\")\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VAE, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(224*224, 1000)\n",
        "        self.fc21 = nn.Linear(1000, 100)\n",
        "        self.fc22 = nn.Linear(1000, 100)\n",
        "        self.fc3 = nn.Linear(100, 1000)\n",
        "        self.fc4 = nn.Linear(1000, 224*224)\n",
        "\n",
        "    def encode(self, x):\n",
        "        h1 = F.relu(self.fc1(x))\n",
        "        return self.fc21(h1), self.fc22(h1)\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5*logvar)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps*std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h3 = F.relu(self.fc3(z))\n",
        "        return torch.sigmoid(self.fc4(h3))\n",
        "# lossÍ∞íÏù¥ ÏïàÏ§ÑÎ©¥ sigmoidÌï®ÏàòÎ•º Ï†úÍ±∞ÌïòÍ≥† BCE with Logits LossÎ•º ÏÇ¨Ïö©Ìï¥Î≥ºÍπå?\n",
        "# https://nuguziii.github.io/dev/dev-002/\n",
        "\n",
        "    def forward(self, x):\n",
        "        mu, logvar = self.encode(x.view(-1, 224*224))\n",
        "        z = self.reparameterize(mu, logvar)  # z's shape => (batch_size, 100)\n",
        "        return self.decode(z), mu, logvar, z"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAL0qyER6Foz",
        "colab_type": "text"
      },
      "source": [
        "# Post-Exp02."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol92_AqEWnOe",
        "colab_type": "text"
      },
      "source": [
        "### Load State Dict\n",
        "* Exp05_Epoch10\n",
        "* <code>Exp05_model_save_10Epochs.pth</code>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "geWI_1HR8JvQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3a01fa62-1394-4c67-960f-1cdfa73d114a"
      },
      "source": [
        "! pwd"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Post_InfoSec_Exps/Post_Exp02\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APz4JQj49Xs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "673f7397-cc08-485c-c3c3-3c8b43141023"
      },
      "source": [
        "# Load State_dict\n",
        "PATH_State_Dict = './Exp05_model_save_10Epochs.pth'\n",
        "\n",
        "model = VAE().to(device)\n",
        "model.load_state_dict(torch.load(PATH_State_Dict))\n",
        "model.eval\n",
        "\n",
        "model"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VAE(\n",
              "  (fc1): Linear(in_features=50176, out_features=1000, bias=True)\n",
              "  (fc21): Linear(in_features=1000, out_features=100, bias=True)\n",
              "  (fc22): Linear(in_features=1000, out_features=100, bias=True)\n",
              "  (fc3): Linear(in_features=100, out_features=1000, bias=True)\n",
              "  (fc4): Linear(in_features=1000, out_features=50176, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85s3nFV139Wj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a3ef5270-098b-41f5-a0cd-57481940602f"
      },
      "source": [
        "print('Num of {} parameters'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Num of 100704376 parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DYXuc5EqnFtX",
        "colab_type": "text"
      },
      "source": [
        "# Skip Below Cells\n",
        "* Skip Training Cells\n",
        "\n",
        "======================================= Skip it ===================================================\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehTMNYpD7EyP",
        "colab_type": "text"
      },
      "source": [
        "*Note*<br>\n",
        "‚úÖ Reducing Learning rate<br>\n",
        "1e-3 to 1e-5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGmI2AwE9Z8e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=1e-5)  # reducing learning rate after 10 Epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dne6cgWqgkH",
        "colab_type": "text"
      },
      "source": [
        "‚úÖ Update<br>\n",
        "\n",
        "```\n",
        " BCE LossÏôÄ Regulation LossÎ•º Ï∂îÍ∞ÄÌï¥Ï§¨ÏäµÎãàÎã§. -20.07.22.wed-\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7IOpEdM8571",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2a6ac72e-d2e1-4207-9f78-f4f062a61e77"
      },
      "source": [
        "! pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Post_InfoSec_Exps/Post_Exp01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwGox4j89pQb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# track and save train, test loss through Dictionary\n",
        "# \n",
        "Epoch_Loss = {'list_epoch': [],\n",
        "              'list_train_loss': [],\n",
        "              'list_test_loss': [],\n",
        "              # Add BCE Loss & Regularization Loss\n",
        "              'list_recon_loss': [],  # BCE Loss\n",
        "              'list_reg_loss': []     # KL Term\n",
        "            }\n",
        "\n",
        "# Save & Loading Model for Inference\n",
        "# Reference: https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
        "\n",
        "# PATH = '/Again_original_Exp01_200-Epoch.pth'\n",
        "\n",
        "PATH = 'Epochs.pth'\n",
        "# latent_vector = np.zeros((16, 100))\n",
        "color_palette = np.zeros((1868))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwaH7SvuxvWA",
        "colab_type": "text"
      },
      "source": [
        "*Note*<br>\n",
        "* Plot Every Epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9khLnNT3MG7a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reconstruction + KL divergence losses summed over all elements and batch\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "\n",
        "    # BCE - Reconstruction Loss\n",
        "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 224*224), reduction='sum')  # (input, target, ... reduction)\n",
        "\n",
        "    # see Appendix B from VAE paper:\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "    # https://arxiv.org/abs/1312.6114\n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "\n",
        "    # KLD Term: Regularization\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "\n",
        "\n",
        "    # ADD BCE & KLD Loss\n",
        "    Epoch_Loss['list_recon_loss'].append(BCE)\n",
        "    Epoch_Loss['list_reg_loss'].append(KLD)\n",
        "    return BCE + KLD\n",
        "\n",
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    # latent_vector = np.zeros(())\n",
        "    # latent_label = 0\n",
        "\n",
        "    for batch_idx, (data, _) in enumerate(train_loader):\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_batch, mu, logvar, z= model(data)\n",
        "    \n",
        "       \n",
        "        loss = loss_function(recon_batch, data, mu, logvar)\n",
        "        loss.backward()  # backwardÎ•º Ìï¥Ï£ºÍ≥†Ïöî\n",
        "        train_loss += loss.item()  # loss.item() Í∞úÍøÄ...\n",
        "        optimizer.step()\n",
        "\n",
        "        # if batch_idx % 10 == 0:\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "            epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "            100. * batch_idx / len(train_loader),\n",
        "            loss.item() / len(data)))\n",
        "\n",
        "    print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
        "          epoch, train_loss / len(train_loader.dataset)))\n",
        "    \n",
        "    Epoch_Loss['list_epoch'].append(epoch)\n",
        "    Epoch_Loss['list_train_loss'].append(train_loss / len(train_loader.dataset))\n",
        "   \n",
        "def test(epoch):\n",
        "    # Every Epoch Îã®ÏúÑÎ°ú ÏûëÏóÖ\n",
        "    # model.state_dict() Ï†ÄÏû• Î∞è latent_vector Ï†ÄÏû•\n",
        "    # plot latent vector\n",
        "    # if epoch % 10 == 0:  # EpochÏù¥ 10Ïùò Î∞∞ÏàòÏùºÎïå\n",
        "    # save model.state_dict() per 10 Epochs\n",
        "    torch.save(model.state_dict(), ('./model_save_' + str(epoch) + PATH))  # Epoch Îã®ÏúÑ parameter Ï†ÄÏû•\n",
        "\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for i, (data, _) in enumerate(test_loader):\n",
        "            data = data.to(device)\n",
        "            recon_batch, mu, logvar, z = model(data)\n",
        "            # z vectorÎäî torch type\n",
        "            # latent_vector = z.detach().cpu().clone().numpy()\n",
        "\n",
        "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
        "            if i == 0:\n",
        "                n = min(data.size(0), 8)\n",
        "                comparison = torch.cat([data[:n],\n",
        "                                    recon_batch.view(16, 1, 224, 224)[:n]])\n",
        "                save_image(comparison.cpu(),\n",
        "                        './recon_sampling/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
        "    # Epoch_Loss['list_epoch'].append(epoch)\n",
        "    Epoch_Loss['list_test_loss'].append(test_loss)\n",
        "\n",
        "    # save latent vector's every 10 Epoch's\n",
        "    # load_whole test_data \n",
        "    for i, (data, _) in enumerate(test_loader_10):  # load_whole test_data\n",
        "        data = data.to(device)\n",
        "        recon_batch, mu, logvar, z = model(data)\n",
        "    # save latent_vector per 10 Epochs\n",
        "        latent_vector = z.detach().cpu().clone().numpy()  # change tensor type data to cpu().numpy()\n",
        "                                                            # latent_vector_size: (num_of_data, 100)\n",
        "        color_palette = _.detach().cpu().clone().numpy()\n",
        "        with open(('./'+str(10+epoch)+'Epoch_z_vector.npy'), 'wb') as f:\n",
        "            np.save(f, latent_vector)  # but latent vector size is (16, 100).... just 16...\n",
        "                                        # 1 Epoch Îã®ÏúÑÎ°ú latent vectorÎ•º Ï†ÄÏû•ÌïúÎã§\n",
        "                                        # Ïù¥ ÎñÑ, latent vectorÏùò sizeÎäî test_datasetÏùò ÌÅ¨Í∏∞Í∞Ä ÎêòÏñ¥Ïïº ÌïúÎã§\n",
        "                                        # Í≤∞Í≥ºÍ∞íÏù¥ Ï¢ãÏùÄ vectorÎäî Ï¢ãÏùÄ featureÎ°ú ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎã§.\n",
        "    # plot latent vector Every 10 Epochs\n",
        "    # t-SNE for Dimensionality reduction\n",
        "    Z_embedded = TSNE(n_components=2).fit_transform(latent_vector)\n",
        "    \n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))  # setup the plot\n",
        "\n",
        "    x = Z_embedded[:, 0]\n",
        "    y = Z_embedded[:, 1]\n",
        "    label = color_palette\n",
        "    # label[10:12] = 0  # make sure there are some 0 values to show up as grey\n",
        "    print(\"==\"*20, \"params\", \"==\"*20)\n",
        "    print(\"Z_embedded.shape:\", Z_embedded.shape)\n",
        "    print(\"label.shape:\", label.shape)\n",
        "    # tsne_data = np.vstack((Z_embedded, label))\n",
        "    tsne_data = np.c_[Z_embedded, label]\n",
        "    tsne_df = pd.DataFrame(data=tsne_data, columns=(\"Dim_1\", \"Dim_2\", \"label\"))\n",
        "    sns.FacetGrid(tsne_df, hue=\"label\", size=6).map(plt.scatter, 'Dim_1', 'Dim_2').add_legend()\n",
        "    plt.savefig('./plot_latent_vector/' + str(epoch) + '_t_SNE.png', dpi=300)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NEC7SFANZODp",
        "colab_type": "text"
      },
      "source": [
        "*Notice*<br>\n",
        "Train Again!<br>\n",
        "Change BCE loss param_reduction to 'sum'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RlJbqlOMI4G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc38d83c-739e-41b2-9eb9-ce3c8b00f2f7"
      },
      "source": [
        "epochs = 20\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "        print(epoch)\n",
        "        train(epoch)\n",
        "        test(epoch)\n",
        "        # https://stackoverflow.com/questions/40766909/suggestions-to-plot-overlapping-lines-in-matplotlib\n",
        "        plt.plot(Epoch_Loss['list_epoch'],Epoch_Loss['list_train_loss'], label=\"train_loss\", alpha=0.7)\n",
        "        plt.plot(Epoch_Loss['list_epoch'],Epoch_Loss['list_test_loss'], label=\"test_loss\", alpha=0.5)\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Loss Score')\n",
        "        plt.title('Train_Test_Loss')\n",
        "        plt.legend()\n",
        "        plt.savefig('./plot_train_test_loss/'+str(epoch)+'_epoch.png', dpi=300)\n",
        "        plt.show()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            sample = torch.randn(64, 100).to(device)\n",
        "            sample = model.decode(sample).cpu()\n",
        "            save_image(sample.view(64, 1, 224, 224),\n",
        "                       './recon_sampling/sampling_' + str(epoch) + '.png')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "Train Epoch: 1 [0/7471 (0%)]\tLoss: 31925.111328\n",
            "Train Epoch: 1 [16/7471 (0%)]\tLoss: 31171.705078\n",
            "Train Epoch: 1 [32/7471 (0%)]\tLoss: 32803.324219\n",
            "Train Epoch: 1 [48/7471 (1%)]\tLoss: 31213.982422\n",
            "Train Epoch: 1 [64/7471 (1%)]\tLoss: 32848.988281\n",
            "Train Epoch: 1 [80/7471 (1%)]\tLoss: 30937.785156\n",
            "Train Epoch: 1 [96/7471 (1%)]\tLoss: 31197.062500\n",
            "Train Epoch: 1 [112/7471 (1%)]\tLoss: 32406.113281\n",
            "Train Epoch: 1 [128/7471 (2%)]\tLoss: 31881.794922\n",
            "Train Epoch: 1 [144/7471 (2%)]\tLoss: 33512.074219\n",
            "Train Epoch: 1 [160/7471 (2%)]\tLoss: 31117.408203\n",
            "Train Epoch: 1 [176/7471 (2%)]\tLoss: 30998.169922\n",
            "Train Epoch: 1 [192/7471 (3%)]\tLoss: 30990.775391\n",
            "Train Epoch: 1 [208/7471 (3%)]\tLoss: 32683.599609\n",
            "Train Epoch: 1 [224/7471 (3%)]\tLoss: 32421.382812\n",
            "Train Epoch: 1 [240/7471 (3%)]\tLoss: 32100.914062\n",
            "Train Epoch: 1 [256/7471 (3%)]\tLoss: 33242.398438\n",
            "Train Epoch: 1 [272/7471 (4%)]\tLoss: 32735.517578\n",
            "Train Epoch: 1 [288/7471 (4%)]\tLoss: 32545.660156\n",
            "Train Epoch: 1 [304/7471 (4%)]\tLoss: 33369.800781\n",
            "Train Epoch: 1 [320/7471 (4%)]\tLoss: 32240.607422\n",
            "Train Epoch: 1 [336/7471 (4%)]\tLoss: 31034.125000\n",
            "Train Epoch: 1 [352/7471 (5%)]\tLoss: 31169.039062\n",
            "Train Epoch: 1 [368/7471 (5%)]\tLoss: 32178.927734\n",
            "Train Epoch: 1 [384/7471 (5%)]\tLoss: 31743.414062\n",
            "Train Epoch: 1 [400/7471 (5%)]\tLoss: 31805.296875\n",
            "Train Epoch: 1 [416/7471 (6%)]\tLoss: 31370.666016\n",
            "Train Epoch: 1 [432/7471 (6%)]\tLoss: 32735.355469\n",
            "Train Epoch: 1 [448/7471 (6%)]\tLoss: 33172.824219\n",
            "Train Epoch: 1 [464/7471 (6%)]\tLoss: 33187.027344\n",
            "Train Epoch: 1 [480/7471 (6%)]\tLoss: 32199.712891\n",
            "Train Epoch: 1 [496/7471 (7%)]\tLoss: 31611.855469\n",
            "Train Epoch: 1 [512/7471 (7%)]\tLoss: 30026.650391\n",
            "Train Epoch: 1 [528/7471 (7%)]\tLoss: 30526.082031\n",
            "Train Epoch: 1 [544/7471 (7%)]\tLoss: 33118.664062\n",
            "Train Epoch: 1 [560/7471 (7%)]\tLoss: 32505.044922\n",
            "Train Epoch: 1 [576/7471 (8%)]\tLoss: 32780.480469\n",
            "Train Epoch: 1 [592/7471 (8%)]\tLoss: 29955.224609\n",
            "Train Epoch: 1 [608/7471 (8%)]\tLoss: 31918.222656\n",
            "Train Epoch: 1 [624/7471 (8%)]\tLoss: 32719.501953\n",
            "Train Epoch: 1 [640/7471 (9%)]\tLoss: 31833.345703\n",
            "Train Epoch: 1 [656/7471 (9%)]\tLoss: 32227.126953\n",
            "Train Epoch: 1 [672/7471 (9%)]\tLoss: 31199.279297\n",
            "Train Epoch: 1 [688/7471 (9%)]\tLoss: 32584.064453\n",
            "Train Epoch: 1 [704/7471 (9%)]\tLoss: 31645.500000\n",
            "Train Epoch: 1 [720/7471 (10%)]\tLoss: 31874.925781\n",
            "Train Epoch: 1 [736/7471 (10%)]\tLoss: 31856.714844\n",
            "Train Epoch: 1 [752/7471 (10%)]\tLoss: 32110.386719\n",
            "Train Epoch: 1 [768/7471 (10%)]\tLoss: 32348.888672\n",
            "Train Epoch: 1 [784/7471 (10%)]\tLoss: 32381.958984\n",
            "Train Epoch: 1 [800/7471 (11%)]\tLoss: 31898.968750\n",
            "Train Epoch: 1 [816/7471 (11%)]\tLoss: 31967.566406\n",
            "Train Epoch: 1 [832/7471 (11%)]\tLoss: 32478.986328\n",
            "Train Epoch: 1 [848/7471 (11%)]\tLoss: 33065.332031\n",
            "Train Epoch: 1 [864/7471 (12%)]\tLoss: 34205.757812\n",
            "Train Epoch: 1 [880/7471 (12%)]\tLoss: 31526.361328\n",
            "Train Epoch: 1 [896/7471 (12%)]\tLoss: 31937.902344\n",
            "Train Epoch: 1 [912/7471 (12%)]\tLoss: 32215.884766\n",
            "Train Epoch: 1 [928/7471 (12%)]\tLoss: 32380.166016\n",
            "Train Epoch: 1 [944/7471 (13%)]\tLoss: 32409.457031\n",
            "Train Epoch: 1 [960/7471 (13%)]\tLoss: 33272.640625\n",
            "Train Epoch: 1 [976/7471 (13%)]\tLoss: 32827.964844\n",
            "Train Epoch: 1 [992/7471 (13%)]\tLoss: 33117.355469\n",
            "Train Epoch: 1 [1008/7471 (13%)]\tLoss: 32136.914062\n",
            "Train Epoch: 1 [1024/7471 (14%)]\tLoss: 32928.867188\n",
            "Train Epoch: 1 [1040/7471 (14%)]\tLoss: 32465.500000\n",
            "Train Epoch: 1 [1056/7471 (14%)]\tLoss: 30749.417969\n",
            "Train Epoch: 1 [1072/7471 (14%)]\tLoss: 33044.640625\n",
            "Train Epoch: 1 [1088/7471 (15%)]\tLoss: 29153.691406\n",
            "Train Epoch: 1 [1104/7471 (15%)]\tLoss: 32472.496094\n",
            "Train Epoch: 1 [1120/7471 (15%)]\tLoss: 33023.152344\n",
            "Train Epoch: 1 [1136/7471 (15%)]\tLoss: 32510.064453\n",
            "Train Epoch: 1 [1152/7471 (15%)]\tLoss: 32312.306641\n",
            "Train Epoch: 1 [1168/7471 (16%)]\tLoss: 32410.796875\n",
            "Train Epoch: 1 [1184/7471 (16%)]\tLoss: 30817.878906\n",
            "Train Epoch: 1 [1200/7471 (16%)]\tLoss: 33690.949219\n",
            "Train Epoch: 1 [1216/7471 (16%)]\tLoss: 33428.683594\n",
            "Train Epoch: 1 [1232/7471 (16%)]\tLoss: 32915.101562\n",
            "Train Epoch: 1 [1248/7471 (17%)]\tLoss: 32427.947266\n",
            "Train Epoch: 1 [1264/7471 (17%)]\tLoss: 32123.662109\n",
            "Train Epoch: 1 [1280/7471 (17%)]\tLoss: 30887.236328\n",
            "Train Epoch: 1 [1296/7471 (17%)]\tLoss: 31321.828125\n",
            "Train Epoch: 1 [1312/7471 (18%)]\tLoss: 32799.386719\n",
            "Train Epoch: 1 [1328/7471 (18%)]\tLoss: 32841.105469\n",
            "Train Epoch: 1 [1344/7471 (18%)]\tLoss: 32988.113281\n",
            "Train Epoch: 1 [1360/7471 (18%)]\tLoss: 30888.984375\n",
            "Train Epoch: 1 [1376/7471 (18%)]\tLoss: 33963.941406\n",
            "Train Epoch: 1 [1392/7471 (19%)]\tLoss: 30497.371094\n",
            "Train Epoch: 1 [1408/7471 (19%)]\tLoss: 30949.667969\n",
            "Train Epoch: 1 [1424/7471 (19%)]\tLoss: 32144.361328\n",
            "Train Epoch: 1 [1440/7471 (19%)]\tLoss: 33575.835938\n",
            "Train Epoch: 1 [1456/7471 (19%)]\tLoss: 32211.162109\n",
            "Train Epoch: 1 [1472/7471 (20%)]\tLoss: 30920.992188\n",
            "Train Epoch: 1 [1488/7471 (20%)]\tLoss: 33569.546875\n",
            "Train Epoch: 1 [1504/7471 (20%)]\tLoss: 32283.667969\n",
            "Train Epoch: 1 [1520/7471 (20%)]\tLoss: 33615.105469\n",
            "Train Epoch: 1 [1536/7471 (21%)]\tLoss: 31421.072266\n",
            "Train Epoch: 1 [1552/7471 (21%)]\tLoss: 32271.019531\n",
            "Train Epoch: 1 [1568/7471 (21%)]\tLoss: 32411.570312\n",
            "Train Epoch: 1 [1584/7471 (21%)]\tLoss: 31579.224609\n",
            "Train Epoch: 1 [1600/7471 (21%)]\tLoss: 31328.943359\n",
            "Train Epoch: 1 [1616/7471 (22%)]\tLoss: 31136.619141\n",
            "Train Epoch: 1 [1632/7471 (22%)]\tLoss: 32912.855469\n",
            "Train Epoch: 1 [1648/7471 (22%)]\tLoss: 31885.000000\n",
            "Train Epoch: 1 [1664/7471 (22%)]\tLoss: 30994.886719\n",
            "Train Epoch: 1 [1680/7471 (22%)]\tLoss: 33246.390625\n",
            "Train Epoch: 1 [1696/7471 (23%)]\tLoss: 33225.742188\n",
            "Train Epoch: 1 [1712/7471 (23%)]\tLoss: 31507.052734\n",
            "Train Epoch: 1 [1728/7471 (23%)]\tLoss: 31418.796875\n",
            "Train Epoch: 1 [1744/7471 (23%)]\tLoss: 32722.468750\n",
            "Train Epoch: 1 [1760/7471 (24%)]\tLoss: 30690.773438\n",
            "Train Epoch: 1 [1776/7471 (24%)]\tLoss: 32150.658203\n",
            "Train Epoch: 1 [1792/7471 (24%)]\tLoss: 32923.609375\n",
            "Train Epoch: 1 [1808/7471 (24%)]\tLoss: 30975.634766\n",
            "Train Epoch: 1 [1824/7471 (24%)]\tLoss: 31477.994141\n",
            "Train Epoch: 1 [1840/7471 (25%)]\tLoss: 33880.265625\n",
            "Train Epoch: 1 [1856/7471 (25%)]\tLoss: 33388.105469\n",
            "Train Epoch: 1 [1872/7471 (25%)]\tLoss: 32997.566406\n",
            "Train Epoch: 1 [1888/7471 (25%)]\tLoss: 32233.412109\n",
            "Train Epoch: 1 [1904/7471 (25%)]\tLoss: 30382.556641\n",
            "Train Epoch: 1 [1920/7471 (26%)]\tLoss: 33095.625000\n",
            "Train Epoch: 1 [1936/7471 (26%)]\tLoss: 30882.695312\n",
            "Train Epoch: 1 [1952/7471 (26%)]\tLoss: 32852.703125\n",
            "Train Epoch: 1 [1968/7471 (26%)]\tLoss: 31316.675781\n",
            "Train Epoch: 1 [1984/7471 (27%)]\tLoss: 32097.720703\n",
            "Train Epoch: 1 [2000/7471 (27%)]\tLoss: 33027.812500\n",
            "Train Epoch: 1 [2016/7471 (27%)]\tLoss: 31766.767578\n",
            "Train Epoch: 1 [2032/7471 (27%)]\tLoss: 29739.982422\n",
            "Train Epoch: 1 [2048/7471 (27%)]\tLoss: 30317.617188\n",
            "Train Epoch: 1 [2064/7471 (28%)]\tLoss: 32453.646484\n",
            "Train Epoch: 1 [2080/7471 (28%)]\tLoss: 33001.621094\n",
            "Train Epoch: 1 [2096/7471 (28%)]\tLoss: 32843.089844\n",
            "Train Epoch: 1 [2112/7471 (28%)]\tLoss: 32559.863281\n",
            "Train Epoch: 1 [2128/7471 (28%)]\tLoss: 31369.826172\n",
            "Train Epoch: 1 [2144/7471 (29%)]\tLoss: 31828.400391\n",
            "Train Epoch: 1 [2160/7471 (29%)]\tLoss: 32189.191406\n",
            "Train Epoch: 1 [2176/7471 (29%)]\tLoss: 32744.156250\n",
            "Train Epoch: 1 [2192/7471 (29%)]\tLoss: 32796.171875\n",
            "Train Epoch: 1 [2208/7471 (30%)]\tLoss: 33015.316406\n",
            "Train Epoch: 1 [2224/7471 (30%)]\tLoss: 32348.240234\n",
            "Train Epoch: 1 [2240/7471 (30%)]\tLoss: 32452.707031\n",
            "Train Epoch: 1 [2256/7471 (30%)]\tLoss: 33803.906250\n",
            "Train Epoch: 1 [2272/7471 (30%)]\tLoss: 32499.064453\n",
            "Train Epoch: 1 [2288/7471 (31%)]\tLoss: 32334.462891\n",
            "Train Epoch: 1 [2304/7471 (31%)]\tLoss: 32103.212891\n",
            "Train Epoch: 1 [2320/7471 (31%)]\tLoss: 32716.515625\n",
            "Train Epoch: 1 [2336/7471 (31%)]\tLoss: 31743.310547\n",
            "Train Epoch: 1 [2352/7471 (31%)]\tLoss: 33054.667969\n",
            "Train Epoch: 1 [2368/7471 (32%)]\tLoss: 33032.996094\n",
            "Train Epoch: 1 [2384/7471 (32%)]\tLoss: 33759.019531\n",
            "Train Epoch: 1 [2400/7471 (32%)]\tLoss: 32721.126953\n",
            "Train Epoch: 1 [2416/7471 (32%)]\tLoss: 32151.902344\n",
            "Train Epoch: 1 [2432/7471 (33%)]\tLoss: 33726.535156\n",
            "Train Epoch: 1 [2448/7471 (33%)]\tLoss: 33560.558594\n",
            "Train Epoch: 1 [2464/7471 (33%)]\tLoss: 32197.216797\n",
            "Train Epoch: 1 [2480/7471 (33%)]\tLoss: 32985.300781\n",
            "Train Epoch: 1 [2496/7471 (33%)]\tLoss: 32657.990234\n",
            "Train Epoch: 1 [2512/7471 (34%)]\tLoss: 33087.265625\n",
            "Train Epoch: 1 [2528/7471 (34%)]\tLoss: 33128.460938\n",
            "Train Epoch: 1 [2544/7471 (34%)]\tLoss: 31618.279297\n",
            "Train Epoch: 1 [2560/7471 (34%)]\tLoss: 32350.914062\n",
            "Train Epoch: 1 [2576/7471 (34%)]\tLoss: 32056.566406\n",
            "Train Epoch: 1 [2592/7471 (35%)]\tLoss: 32880.089844\n",
            "Train Epoch: 1 [2608/7471 (35%)]\tLoss: 32218.388672\n",
            "Train Epoch: 1 [2624/7471 (35%)]\tLoss: 32747.294922\n",
            "Train Epoch: 1 [2640/7471 (35%)]\tLoss: 32273.974609\n",
            "Train Epoch: 1 [2656/7471 (36%)]\tLoss: 31798.238281\n",
            "Train Epoch: 1 [2672/7471 (36%)]\tLoss: 32671.949219\n",
            "Train Epoch: 1 [2688/7471 (36%)]\tLoss: 33129.085938\n",
            "Train Epoch: 1 [2704/7471 (36%)]\tLoss: 32751.556641\n",
            "Train Epoch: 1 [2720/7471 (36%)]\tLoss: 33103.960938\n",
            "Train Epoch: 1 [2736/7471 (37%)]\tLoss: 33223.691406\n",
            "Train Epoch: 1 [2752/7471 (37%)]\tLoss: 32799.085938\n",
            "Train Epoch: 1 [2768/7471 (37%)]\tLoss: 32010.449219\n",
            "Train Epoch: 1 [2784/7471 (37%)]\tLoss: 32379.671875\n",
            "Train Epoch: 1 [2800/7471 (37%)]\tLoss: 33432.359375\n",
            "Train Epoch: 1 [2816/7471 (38%)]\tLoss: 32959.789062\n",
            "Train Epoch: 1 [2832/7471 (38%)]\tLoss: 29908.390625\n",
            "Train Epoch: 1 [2848/7471 (38%)]\tLoss: 31476.105469\n",
            "Train Epoch: 1 [2864/7471 (38%)]\tLoss: 32240.873047\n",
            "Train Epoch: 1 [2880/7471 (39%)]\tLoss: 31101.757812\n",
            "Train Epoch: 1 [2896/7471 (39%)]\tLoss: 33191.320312\n",
            "Train Epoch: 1 [2912/7471 (39%)]\tLoss: 32442.455078\n",
            "Train Epoch: 1 [2928/7471 (39%)]\tLoss: 32530.027344\n",
            "Train Epoch: 1 [2944/7471 (39%)]\tLoss: 31844.945312\n",
            "Train Epoch: 1 [2960/7471 (40%)]\tLoss: 32220.132812\n",
            "Train Epoch: 1 [2976/7471 (40%)]\tLoss: 33459.984375\n",
            "Train Epoch: 1 [2992/7471 (40%)]\tLoss: 32438.740234\n",
            "Train Epoch: 1 [3008/7471 (40%)]\tLoss: 30539.853516\n",
            "Train Epoch: 1 [3024/7471 (40%)]\tLoss: 33936.316406\n",
            "Train Epoch: 1 [3040/7471 (41%)]\tLoss: 33246.554688\n",
            "Train Epoch: 1 [3056/7471 (41%)]\tLoss: 33171.273438\n",
            "Train Epoch: 1 [3072/7471 (41%)]\tLoss: 31033.195312\n",
            "Train Epoch: 1 [3088/7471 (41%)]\tLoss: 32858.660156\n",
            "Train Epoch: 1 [3104/7471 (42%)]\tLoss: 33022.929688\n",
            "Train Epoch: 1 [3120/7471 (42%)]\tLoss: 31437.310547\n",
            "Train Epoch: 1 [3136/7471 (42%)]\tLoss: 32872.054688\n",
            "Train Epoch: 1 [3152/7471 (42%)]\tLoss: 32032.687500\n",
            "Train Epoch: 1 [3168/7471 (42%)]\tLoss: 32480.371094\n",
            "Train Epoch: 1 [3184/7471 (43%)]\tLoss: 31723.115234\n",
            "Train Epoch: 1 [3200/7471 (43%)]\tLoss: 32481.210938\n",
            "Train Epoch: 1 [3216/7471 (43%)]\tLoss: 32018.402344\n",
            "Train Epoch: 1 [3232/7471 (43%)]\tLoss: 32981.433594\n",
            "Train Epoch: 1 [3248/7471 (43%)]\tLoss: 32132.437500\n",
            "Train Epoch: 1 [3264/7471 (44%)]\tLoss: 32857.121094\n",
            "Train Epoch: 1 [3280/7471 (44%)]\tLoss: 32259.111328\n",
            "Train Epoch: 1 [3296/7471 (44%)]\tLoss: 32844.917969\n",
            "Train Epoch: 1 [3312/7471 (44%)]\tLoss: 32912.937500\n",
            "Train Epoch: 1 [3328/7471 (45%)]\tLoss: 32318.707031\n",
            "Train Epoch: 1 [3344/7471 (45%)]\tLoss: 31760.058594\n",
            "Train Epoch: 1 [3360/7471 (45%)]\tLoss: 32040.822266\n",
            "Train Epoch: 1 [3376/7471 (45%)]\tLoss: 32684.695312\n",
            "Train Epoch: 1 [3392/7471 (45%)]\tLoss: 30847.927734\n",
            "Train Epoch: 1 [3408/7471 (46%)]\tLoss: 32583.919922\n",
            "Train Epoch: 1 [3424/7471 (46%)]\tLoss: 32102.669922\n",
            "Train Epoch: 1 [3440/7471 (46%)]\tLoss: 32172.501953\n",
            "Train Epoch: 1 [3456/7471 (46%)]\tLoss: 32234.910156\n",
            "Train Epoch: 1 [3472/7471 (46%)]\tLoss: 31095.960938\n",
            "Train Epoch: 1 [3488/7471 (47%)]\tLoss: 30727.085938\n",
            "Train Epoch: 1 [3504/7471 (47%)]\tLoss: 30673.281250\n",
            "Train Epoch: 1 [3520/7471 (47%)]\tLoss: 33785.652344\n",
            "Train Epoch: 1 [3536/7471 (47%)]\tLoss: 30430.935547\n",
            "Train Epoch: 1 [3552/7471 (48%)]\tLoss: 32215.996094\n",
            "Train Epoch: 1 [3568/7471 (48%)]\tLoss: 34026.164062\n",
            "Train Epoch: 1 [3584/7471 (48%)]\tLoss: 30936.455078\n",
            "Train Epoch: 1 [3600/7471 (48%)]\tLoss: 32273.724609\n",
            "Train Epoch: 1 [3616/7471 (48%)]\tLoss: 33275.992188\n",
            "Train Epoch: 1 [3632/7471 (49%)]\tLoss: 32649.154297\n",
            "Train Epoch: 1 [3648/7471 (49%)]\tLoss: 33614.839844\n",
            "Train Epoch: 1 [3664/7471 (49%)]\tLoss: 31927.652344\n",
            "Train Epoch: 1 [3680/7471 (49%)]\tLoss: 31464.632812\n",
            "Train Epoch: 1 [3696/7471 (49%)]\tLoss: 31645.791016\n",
            "Train Epoch: 1 [3712/7471 (50%)]\tLoss: 33109.218750\n",
            "Train Epoch: 1 [3728/7471 (50%)]\tLoss: 30978.234375\n",
            "Train Epoch: 1 [3744/7471 (50%)]\tLoss: 33635.621094\n",
            "Train Epoch: 1 [3760/7471 (50%)]\tLoss: 33023.906250\n",
            "Train Epoch: 1 [3776/7471 (51%)]\tLoss: 32800.941406\n",
            "Train Epoch: 1 [3792/7471 (51%)]\tLoss: 31369.675781\n",
            "Train Epoch: 1 [3808/7471 (51%)]\tLoss: 32501.687500\n",
            "Train Epoch: 1 [3824/7471 (51%)]\tLoss: 31805.625000\n",
            "Train Epoch: 1 [3840/7471 (51%)]\tLoss: 30738.261719\n",
            "Train Epoch: 1 [3856/7471 (52%)]\tLoss: 32621.298828\n",
            "Train Epoch: 1 [3872/7471 (52%)]\tLoss: 33554.238281\n",
            "Train Epoch: 1 [3888/7471 (52%)]\tLoss: 32697.748047\n",
            "Train Epoch: 1 [3904/7471 (52%)]\tLoss: 32502.466797\n",
            "Train Epoch: 1 [3920/7471 (52%)]\tLoss: 33816.074219\n",
            "Train Epoch: 1 [3936/7471 (53%)]\tLoss: 33018.386719\n",
            "Train Epoch: 1 [3952/7471 (53%)]\tLoss: 32554.746094\n",
            "Train Epoch: 1 [3968/7471 (53%)]\tLoss: 32454.375000\n",
            "Train Epoch: 1 [3984/7471 (53%)]\tLoss: 32824.753906\n",
            "Train Epoch: 1 [4000/7471 (54%)]\tLoss: 33759.847656\n",
            "Train Epoch: 1 [4016/7471 (54%)]\tLoss: 32750.720703\n",
            "Train Epoch: 1 [4032/7471 (54%)]\tLoss: 32503.070312\n",
            "Train Epoch: 1 [4048/7471 (54%)]\tLoss: 32491.626953\n",
            "Train Epoch: 1 [4064/7471 (54%)]\tLoss: 31636.742188\n",
            "Train Epoch: 1 [4080/7471 (55%)]\tLoss: 32308.929688\n",
            "Train Epoch: 1 [4096/7471 (55%)]\tLoss: 31960.236328\n",
            "Train Epoch: 1 [4112/7471 (55%)]\tLoss: 31250.660156\n",
            "Train Epoch: 1 [4128/7471 (55%)]\tLoss: 32577.353516\n",
            "Train Epoch: 1 [4144/7471 (55%)]\tLoss: 32452.251953\n",
            "Train Epoch: 1 [4160/7471 (56%)]\tLoss: 31209.009766\n",
            "Train Epoch: 1 [4176/7471 (56%)]\tLoss: 32728.968750\n",
            "Train Epoch: 1 [4192/7471 (56%)]\tLoss: 31926.869141\n",
            "Train Epoch: 1 [4208/7471 (56%)]\tLoss: 32445.662109\n",
            "Train Epoch: 1 [4224/7471 (57%)]\tLoss: 31678.193359\n",
            "Train Epoch: 1 [4240/7471 (57%)]\tLoss: 31790.029297\n",
            "Train Epoch: 1 [4256/7471 (57%)]\tLoss: 29633.228516\n",
            "Train Epoch: 1 [4272/7471 (57%)]\tLoss: 32385.042969\n",
            "Train Epoch: 1 [4288/7471 (57%)]\tLoss: 32040.574219\n",
            "Train Epoch: 1 [4304/7471 (58%)]\tLoss: 31537.923828\n",
            "Train Epoch: 1 [4320/7471 (58%)]\tLoss: 33072.808594\n",
            "Train Epoch: 1 [4336/7471 (58%)]\tLoss: 31069.396484\n",
            "Train Epoch: 1 [4352/7471 (58%)]\tLoss: 34088.195312\n",
            "Train Epoch: 1 [4368/7471 (58%)]\tLoss: 32125.746094\n",
            "Train Epoch: 1 [4384/7471 (59%)]\tLoss: 31305.623047\n",
            "Train Epoch: 1 [4400/7471 (59%)]\tLoss: 31765.951172\n",
            "Train Epoch: 1 [4416/7471 (59%)]\tLoss: 31944.062500\n",
            "Train Epoch: 1 [4432/7471 (59%)]\tLoss: 32731.753906\n",
            "Train Epoch: 1 [4448/7471 (60%)]\tLoss: 32467.789062\n",
            "Train Epoch: 1 [4464/7471 (60%)]\tLoss: 32505.419922\n",
            "Train Epoch: 1 [4480/7471 (60%)]\tLoss: 32260.105469\n",
            "Train Epoch: 1 [4496/7471 (60%)]\tLoss: 32039.599609\n",
            "Train Epoch: 1 [4512/7471 (60%)]\tLoss: 33070.203125\n",
            "Train Epoch: 1 [4528/7471 (61%)]\tLoss: 33029.093750\n",
            "Train Epoch: 1 [4544/7471 (61%)]\tLoss: 32661.310547\n",
            "Train Epoch: 1 [4560/7471 (61%)]\tLoss: 32903.800781\n",
            "Train Epoch: 1 [4576/7471 (61%)]\tLoss: 31894.984375\n",
            "Train Epoch: 1 [4592/7471 (61%)]\tLoss: 32219.638672\n",
            "Train Epoch: 1 [4608/7471 (62%)]\tLoss: 32997.882812\n",
            "Train Epoch: 1 [4624/7471 (62%)]\tLoss: 31432.888672\n",
            "Train Epoch: 1 [4640/7471 (62%)]\tLoss: 32750.410156\n",
            "Train Epoch: 1 [4656/7471 (62%)]\tLoss: 33385.144531\n",
            "Train Epoch: 1 [4672/7471 (63%)]\tLoss: 33063.980469\n",
            "Train Epoch: 1 [4688/7471 (63%)]\tLoss: 32792.636719\n",
            "Train Epoch: 1 [4704/7471 (63%)]\tLoss: 31583.599609\n",
            "Train Epoch: 1 [4720/7471 (63%)]\tLoss: 31376.718750\n",
            "Train Epoch: 1 [4736/7471 (63%)]\tLoss: 33081.214844\n",
            "Train Epoch: 1 [4752/7471 (64%)]\tLoss: 32336.187500\n",
            "Train Epoch: 1 [4768/7471 (64%)]\tLoss: 32322.363281\n",
            "Train Epoch: 1 [4784/7471 (64%)]\tLoss: 30791.806641\n",
            "Train Epoch: 1 [4800/7471 (64%)]\tLoss: 33166.210938\n",
            "Train Epoch: 1 [4816/7471 (64%)]\tLoss: 33626.246094\n",
            "Train Epoch: 1 [4832/7471 (65%)]\tLoss: 32820.441406\n",
            "Train Epoch: 1 [4848/7471 (65%)]\tLoss: 32790.605469\n",
            "Train Epoch: 1 [4864/7471 (65%)]\tLoss: 33038.101562\n",
            "Train Epoch: 1 [4880/7471 (65%)]\tLoss: 32284.216797\n",
            "Train Epoch: 1 [4896/7471 (66%)]\tLoss: 31188.361328\n",
            "Train Epoch: 1 [4912/7471 (66%)]\tLoss: 33204.042969\n",
            "Train Epoch: 1 [4928/7471 (66%)]\tLoss: 30434.583984\n",
            "Train Epoch: 1 [4944/7471 (66%)]\tLoss: 33458.464844\n",
            "Train Epoch: 1 [4960/7471 (66%)]\tLoss: 32567.037109\n",
            "Train Epoch: 1 [4976/7471 (67%)]\tLoss: 31139.320312\n",
            "Train Epoch: 1 [4992/7471 (67%)]\tLoss: 30853.546875\n",
            "Train Epoch: 1 [5008/7471 (67%)]\tLoss: 32904.574219\n",
            "Train Epoch: 1 [5024/7471 (67%)]\tLoss: 32915.507812\n",
            "Train Epoch: 1 [5040/7471 (67%)]\tLoss: 31750.298828\n",
            "Train Epoch: 1 [5056/7471 (68%)]\tLoss: 32872.121094\n",
            "Train Epoch: 1 [5072/7471 (68%)]\tLoss: 31176.255859\n",
            "Train Epoch: 1 [5088/7471 (68%)]\tLoss: 32122.816406\n",
            "Train Epoch: 1 [5104/7471 (68%)]\tLoss: 31182.748047\n",
            "Train Epoch: 1 [5120/7471 (69%)]\tLoss: 32236.966797\n",
            "Train Epoch: 1 [5136/7471 (69%)]\tLoss: 33461.308594\n",
            "Train Epoch: 1 [5152/7471 (69%)]\tLoss: 32030.226562\n",
            "Train Epoch: 1 [5168/7471 (69%)]\tLoss: 32585.748047\n",
            "Train Epoch: 1 [5184/7471 (69%)]\tLoss: 32900.144531\n",
            "Train Epoch: 1 [5200/7471 (70%)]\tLoss: 32392.818359\n",
            "Train Epoch: 1 [5216/7471 (70%)]\tLoss: 32008.974609\n",
            "Train Epoch: 1 [5232/7471 (70%)]\tLoss: 31810.484375\n",
            "Train Epoch: 1 [5248/7471 (70%)]\tLoss: 32680.482422\n",
            "Train Epoch: 1 [5264/7471 (70%)]\tLoss: 32424.486328\n",
            "Train Epoch: 1 [5280/7471 (71%)]\tLoss: 32001.660156\n",
            "Train Epoch: 1 [5296/7471 (71%)]\tLoss: 34065.640625\n",
            "Train Epoch: 1 [5312/7471 (71%)]\tLoss: 32599.193359\n",
            "Train Epoch: 1 [5328/7471 (71%)]\tLoss: 32084.849609\n",
            "Train Epoch: 1 [5344/7471 (72%)]\tLoss: 33107.894531\n",
            "Train Epoch: 1 [5360/7471 (72%)]\tLoss: 32244.517578\n",
            "Train Epoch: 1 [5376/7471 (72%)]\tLoss: 32620.832031\n",
            "Train Epoch: 1 [5392/7471 (72%)]\tLoss: 33481.304688\n",
            "Train Epoch: 1 [5408/7471 (72%)]\tLoss: 31401.593750\n",
            "Train Epoch: 1 [5424/7471 (73%)]\tLoss: 33248.609375\n",
            "Train Epoch: 1 [5440/7471 (73%)]\tLoss: 33057.269531\n",
            "Train Epoch: 1 [5456/7471 (73%)]\tLoss: 30967.875000\n",
            "Train Epoch: 1 [5472/7471 (73%)]\tLoss: 31211.267578\n",
            "Train Epoch: 1 [5488/7471 (73%)]\tLoss: 31981.607422\n",
            "Train Epoch: 1 [5504/7471 (74%)]\tLoss: 32902.210938\n",
            "Train Epoch: 1 [5520/7471 (74%)]\tLoss: 31677.740234\n",
            "Train Epoch: 1 [5536/7471 (74%)]\tLoss: 32940.914062\n",
            "Train Epoch: 1 [5552/7471 (74%)]\tLoss: 32327.878906\n",
            "Train Epoch: 1 [5568/7471 (75%)]\tLoss: 30539.728516\n",
            "Train Epoch: 1 [5584/7471 (75%)]\tLoss: 32273.001953\n",
            "Train Epoch: 1 [5600/7471 (75%)]\tLoss: 32604.089844\n",
            "Train Epoch: 1 [5616/7471 (75%)]\tLoss: 32286.919922\n",
            "Train Epoch: 1 [5632/7471 (75%)]\tLoss: 32900.890625\n",
            "Train Epoch: 1 [5648/7471 (76%)]\tLoss: 33327.343750\n",
            "Train Epoch: 1 [5664/7471 (76%)]\tLoss: 32519.949219\n",
            "Train Epoch: 1 [5680/7471 (76%)]\tLoss: 31805.111328\n",
            "Train Epoch: 1 [5696/7471 (76%)]\tLoss: 32656.828125\n",
            "Train Epoch: 1 [5712/7471 (76%)]\tLoss: 31893.216797\n",
            "Train Epoch: 1 [5728/7471 (77%)]\tLoss: 31664.013672\n",
            "Train Epoch: 1 [5744/7471 (77%)]\tLoss: 32056.830078\n",
            "Train Epoch: 1 [5760/7471 (77%)]\tLoss: 30236.947266\n",
            "Train Epoch: 1 [5776/7471 (77%)]\tLoss: 32989.746094\n",
            "Train Epoch: 1 [5792/7471 (78%)]\tLoss: 31338.103516\n",
            "Train Epoch: 1 [5808/7471 (78%)]\tLoss: 32209.492188\n",
            "Train Epoch: 1 [5824/7471 (78%)]\tLoss: 31179.382812\n",
            "Train Epoch: 1 [5840/7471 (78%)]\tLoss: 31879.136719\n",
            "Train Epoch: 1 [5856/7471 (78%)]\tLoss: 32106.458984\n",
            "Train Epoch: 1 [5872/7471 (79%)]\tLoss: 29129.189453\n",
            "Train Epoch: 1 [5888/7471 (79%)]\tLoss: 32617.208984\n",
            "Train Epoch: 1 [5904/7471 (79%)]\tLoss: 33787.390625\n",
            "Train Epoch: 1 [5920/7471 (79%)]\tLoss: 32744.242188\n",
            "Train Epoch: 1 [5936/7471 (79%)]\tLoss: 31028.921875\n",
            "Train Epoch: 1 [5952/7471 (80%)]\tLoss: 32581.080078\n",
            "Train Epoch: 1 [5968/7471 (80%)]\tLoss: 31412.048828\n",
            "Train Epoch: 1 [5984/7471 (80%)]\tLoss: 31662.808594\n",
            "Train Epoch: 1 [6000/7471 (80%)]\tLoss: 30555.425781\n",
            "Train Epoch: 1 [6016/7471 (81%)]\tLoss: 31602.689453\n",
            "Train Epoch: 1 [6032/7471 (81%)]\tLoss: 32808.882812\n",
            "Train Epoch: 1 [6048/7471 (81%)]\tLoss: 30171.802734\n",
            "Train Epoch: 1 [6064/7471 (81%)]\tLoss: 32095.593750\n",
            "Train Epoch: 1 [6080/7471 (81%)]\tLoss: 33186.332031\n",
            "Train Epoch: 1 [6096/7471 (82%)]\tLoss: 33134.195312\n",
            "Train Epoch: 1 [6112/7471 (82%)]\tLoss: 32888.761719\n",
            "Train Epoch: 1 [6128/7471 (82%)]\tLoss: 32586.671875\n",
            "Train Epoch: 1 [6144/7471 (82%)]\tLoss: 32155.113281\n",
            "Train Epoch: 1 [6160/7471 (82%)]\tLoss: 29840.115234\n",
            "Train Epoch: 1 [6176/7471 (83%)]\tLoss: 30828.591797\n",
            "Train Epoch: 1 [6192/7471 (83%)]\tLoss: 31486.578125\n",
            "Train Epoch: 1 [6208/7471 (83%)]\tLoss: 33814.167969\n",
            "Train Epoch: 1 [6224/7471 (83%)]\tLoss: 32422.775391\n",
            "Train Epoch: 1 [6240/7471 (84%)]\tLoss: 33440.433594\n",
            "Train Epoch: 1 [6256/7471 (84%)]\tLoss: 32011.921875\n",
            "Train Epoch: 1 [6272/7471 (84%)]\tLoss: 32684.085938\n",
            "Train Epoch: 1 [6288/7471 (84%)]\tLoss: 32955.683594\n",
            "Train Epoch: 1 [6304/7471 (84%)]\tLoss: 32315.722656\n",
            "Train Epoch: 1 [6320/7471 (85%)]\tLoss: 33338.644531\n",
            "Train Epoch: 1 [6336/7471 (85%)]\tLoss: 33237.628906\n",
            "Train Epoch: 1 [6352/7471 (85%)]\tLoss: 30926.601562\n",
            "Train Epoch: 1 [6368/7471 (85%)]\tLoss: 32803.937500\n",
            "Train Epoch: 1 [6384/7471 (85%)]\tLoss: 31962.035156\n",
            "Train Epoch: 1 [6400/7471 (86%)]\tLoss: 31264.728516\n",
            "Train Epoch: 1 [6416/7471 (86%)]\tLoss: 33658.402344\n",
            "Train Epoch: 1 [6432/7471 (86%)]\tLoss: 32004.271484\n",
            "Train Epoch: 1 [6448/7471 (86%)]\tLoss: 32839.441406\n",
            "Train Epoch: 1 [6464/7471 (87%)]\tLoss: 30662.273438\n",
            "Train Epoch: 1 [6480/7471 (87%)]\tLoss: 31486.712891\n",
            "Train Epoch: 1 [6496/7471 (87%)]\tLoss: 32604.095703\n",
            "Train Epoch: 1 [6512/7471 (87%)]\tLoss: 31563.121094\n",
            "Train Epoch: 1 [6528/7471 (87%)]\tLoss: 32784.644531\n",
            "Train Epoch: 1 [6544/7471 (88%)]\tLoss: 33377.113281\n",
            "Train Epoch: 1 [6560/7471 (88%)]\tLoss: 31603.050781\n",
            "Train Epoch: 1 [6576/7471 (88%)]\tLoss: 30492.515625\n",
            "Train Epoch: 1 [6592/7471 (88%)]\tLoss: 32519.898438\n",
            "Train Epoch: 1 [6608/7471 (88%)]\tLoss: 33405.148438\n",
            "Train Epoch: 1 [6624/7471 (89%)]\tLoss: 33976.011719\n",
            "Train Epoch: 1 [6640/7471 (89%)]\tLoss: 31809.201172\n",
            "Train Epoch: 1 [6656/7471 (89%)]\tLoss: 30782.886719\n",
            "Train Epoch: 1 [6672/7471 (89%)]\tLoss: 33341.593750\n",
            "Train Epoch: 1 [6688/7471 (90%)]\tLoss: 33313.441406\n",
            "Train Epoch: 1 [6704/7471 (90%)]\tLoss: 33431.570312\n",
            "Train Epoch: 1 [6720/7471 (90%)]\tLoss: 31974.259766\n",
            "Train Epoch: 1 [6736/7471 (90%)]\tLoss: 31199.501953\n",
            "Train Epoch: 1 [6752/7471 (90%)]\tLoss: 29577.220703\n",
            "Train Epoch: 1 [6768/7471 (91%)]\tLoss: 32086.980469\n",
            "Train Epoch: 1 [6784/7471 (91%)]\tLoss: 33168.933594\n",
            "Train Epoch: 1 [6800/7471 (91%)]\tLoss: 32091.451172\n",
            "Train Epoch: 1 [6816/7471 (91%)]\tLoss: 31168.150391\n",
            "Train Epoch: 1 [6832/7471 (91%)]\tLoss: 32197.166016\n",
            "Train Epoch: 1 [6848/7471 (92%)]\tLoss: 31317.914062\n",
            "Train Epoch: 1 [6864/7471 (92%)]\tLoss: 32447.894531\n",
            "Train Epoch: 1 [6880/7471 (92%)]\tLoss: 33062.531250\n",
            "Train Epoch: 1 [6896/7471 (92%)]\tLoss: 32022.275391\n",
            "Train Epoch: 1 [6912/7471 (93%)]\tLoss: 32781.242188\n",
            "Train Epoch: 1 [6928/7471 (93%)]\tLoss: 31025.154297\n",
            "Train Epoch: 1 [6944/7471 (93%)]\tLoss: 30681.205078\n",
            "Train Epoch: 1 [6960/7471 (93%)]\tLoss: 31342.234375\n",
            "Train Epoch: 1 [6976/7471 (93%)]\tLoss: 32825.589844\n",
            "Train Epoch: 1 [6992/7471 (94%)]\tLoss: 33578.808594\n",
            "Train Epoch: 1 [7008/7471 (94%)]\tLoss: 32331.970703\n",
            "Train Epoch: 1 [7024/7471 (94%)]\tLoss: 31611.460938\n",
            "Train Epoch: 1 [7040/7471 (94%)]\tLoss: 31839.128906\n",
            "Train Epoch: 1 [7056/7471 (94%)]\tLoss: 32547.082031\n",
            "Train Epoch: 1 [7072/7471 (95%)]\tLoss: 33410.496094\n",
            "Train Epoch: 1 [7088/7471 (95%)]\tLoss: 33062.722656\n",
            "Train Epoch: 1 [7104/7471 (95%)]\tLoss: 32305.771484\n",
            "Train Epoch: 1 [7120/7471 (95%)]\tLoss: 32226.695312\n",
            "Train Epoch: 1 [7136/7471 (96%)]\tLoss: 32729.656250\n",
            "Train Epoch: 1 [7152/7471 (96%)]\tLoss: 33317.347656\n",
            "Train Epoch: 1 [7168/7471 (96%)]\tLoss: 32558.228516\n",
            "Train Epoch: 1 [7184/7471 (96%)]\tLoss: 33334.621094\n",
            "Train Epoch: 1 [7200/7471 (96%)]\tLoss: 32097.214844\n",
            "Train Epoch: 1 [7216/7471 (97%)]\tLoss: 32555.521484\n",
            "Train Epoch: 1 [7232/7471 (97%)]\tLoss: 32713.726562\n",
            "Train Epoch: 1 [7248/7471 (97%)]\tLoss: 32365.761719\n",
            "Train Epoch: 1 [7264/7471 (97%)]\tLoss: 32284.152344\n",
            "Train Epoch: 1 [7280/7471 (97%)]\tLoss: 32547.371094\n",
            "Train Epoch: 1 [7296/7471 (98%)]\tLoss: 32268.189453\n",
            "Train Epoch: 1 [7312/7471 (98%)]\tLoss: 32857.031250\n",
            "Train Epoch: 1 [7328/7471 (98%)]\tLoss: 33011.195312\n",
            "Train Epoch: 1 [7344/7471 (98%)]\tLoss: 32645.019531\n",
            "Train Epoch: 1 [7360/7471 (99%)]\tLoss: 31515.314453\n",
            "Train Epoch: 1 [7376/7471 (99%)]\tLoss: 31529.474609\n",
            "Train Epoch: 1 [7392/7471 (99%)]\tLoss: 32851.410156\n",
            "Train Epoch: 1 [7408/7471 (99%)]\tLoss: 32923.753906\n",
            "Train Epoch: 1 [7424/7471 (99%)]\tLoss: 32590.480469\n",
            "Train Epoch: 1 [7440/7471 (100%)]\tLoss: 33093.289062\n",
            "Train Epoch: 1 [6990/7471 (100%)]\tLoss: 32722.229167\n",
            "====> Epoch: 1 Average loss: 32261.9303\n",
            "====> Test set loss: 32114.0442\n",
            "======================================== params ========================================\n",
            "Z_embedded.shape: (1868, 2)\n",
            "label.shape: (1868,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/axisgrid.py:243: UserWarning: The `size` parameter has been renamed to `height`; please update your code.\n",
            "  warnings.warn(msg, UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 490.25x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-63b463344fef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# https://stackoverflow.com/questions/40766909/suggestions-to-plot-overlapping-lines-in-matplotlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEpoch_Loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'list_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEpoch_Loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'list_train_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEpoch_Loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'list_epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEpoch_Loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'list_test_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test_loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (2,) and (1,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVHP1FKQ-jRG",
        "colab_type": "text"
      },
      "source": [
        "## Post-Exp02\n",
        "* Ï∂îÍ∞ÄÏã§Ìóò List\n",
        "    * Load VAE_State_Dict\n",
        "    * Extract Latent vector & make Training set(for DL/ML)\n",
        "        * ‚ùå(1868, 100)\n",
        "        * => For all training data: (9339, 100)\n",
        "        * => Add Labels: (9339, 101)\n",
        "        * Make Pandas DataFrame\n",
        "            * Make pd.DataFrame()\n",
        "            * Save DataFrame() to csv\n",
        "        * Make Classifier\n",
        "            * ML: Voting Classifier\n",
        "            * DL: \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aseri-h-7EG",
        "colab_type": "text"
      },
      "source": [
        "## 1. Linear Model(Deep Neural Network)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ7IipUSok1I",
        "colab_type": "text"
      },
      "source": [
        "## 02. Machine Learning Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgOIqgzIL5bZ",
        "colab_type": "text"
      },
      "source": [
        "### Preparing\n",
        "\n",
        "* Make Custom Dataset & Custom DataLoader\n",
        "* Load_VAE_State_Dict\n",
        "* Extract Latent Vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6GNo7uUpn5q",
        "colab_type": "text"
      },
      "source": [
        "#### Make Custom Dataset & Custom *DataLoader*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er-LCOkwZAGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms = transforms.Compose([\n",
        "                                transforms.Resize((224, 224)),                # Change size of Image to (224, 224)\n",
        "                                transforms.Grayscale(num_output_channels=1),  # Makes it 1-dimension channel\n",
        "                                transforms.ToTensor(),                        # Convert a PIL Image or numpy.ndarray to tensor.\n",
        "                                                                              # Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8\n",
        "                                                                              # In the other cases, tensors are returned without scaling.\n",
        "                                # transforms.Normalize(mean=[0.5], std=[0.5]),\n",
        "                                \n",
        "                                ])\n",
        "\n",
        "# make custom dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='../../InformationSecurity_Summer/malimg',\n",
        "                                            transform=transforms)  # make custom dataset"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q_Uxt8RKnoX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c7738665-7c37-473a-b048-6b3b332d86e0"
      },
      "source": [
        "full_dataset = trainset\n",
        "\n",
        "# maek train, val, test: 8:1:1\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = int(0.1 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "print(train_size, val_size, test_size)\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, val_size, test_size])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7471 933 935\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LlTgmqmLD49",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "07c83810-16d3-4ecd-9be6-0a4570d5f026"
      },
      "source": [
        "print(train_dataset, val_dataset, test_dataset)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<torch.utils.data.dataset.Subset object at 0x7f4282413358> <torch.utils.data.dataset.Subset object at 0x7f4282413208> <torch.utils.data.dataset.Subset object at 0x7f4282413e80>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PONkfMx_p7HI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 7471 + 933 + 935"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFtOxl6LAjQr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make custom data_loader\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                         batch_size=16,\n",
        "                         shuffle=True,\n",
        "                         pin_memory=True)\n",
        "val_loader = DataLoader(val_dataset,\n",
        "                        batch_size=16,\n",
        "                        shuffle=True,\n",
        "                        pin_memory=True)\n",
        " \n",
        "test_loader = DataLoader(test_dataset,\n",
        "                        batch_size=16,\n",
        "                        shuffle=True,\n",
        "                        pin_memory=True)  # Instead, we recommend using automatic memory pinning (i.e., setting pin_memory=True)\n",
        "                                          #  which enables fast data transfer to CUDA-enabled GPUs\n",
        "\n",
        "# First, insert all test dataset\n",
        "# z_loader: for latent vector extraction\n",
        "z_loader = DataLoader(full_dataset,\n",
        "                        batch_size=9339,\n",
        "                        shuffle=True,\n",
        "                        pin_memory=True)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46DY-WNkqDvI",
        "colab_type": "text"
      },
      "source": [
        "z_loader: for extract latent vectors<br>\n",
        "e.g) (9339, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxFcKQV6rXnp",
        "colab_type": "text"
      },
      "source": [
        "#### Load_VAE_State_Dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Jnm-xncL-Z6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "outputId": "3fa657b5-fff2-4212-b8c5-77e61dcd327e"
      },
      "source": [
        "# define_device\n",
        "device = torch.device(\"cuda\")  # device = torch.device(\"cuda\")\n",
        "\n",
        "# Load State_dict\n",
        "PATH_State_Dict = './Exp05_model_save_10Epochs.pth'\n",
        "\n",
        "model = VAE().to(device)  # VAE().to(device)\n",
        "model.load_state_dict(torch.load(PATH_State_Dict))\n",
        "model.eval()\n",
        "\n",
        "print(model)\n",
        "print('Num of {} parameters'.format(sum(p.numel() for p in model.parameters() if p.requires_grad)))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "VAE(\n",
            "  (fc1): Linear(in_features=50176, out_features=1000, bias=True)\n",
            "  (fc21): Linear(in_features=1000, out_features=100, bias=True)\n",
            "  (fc22): Linear(in_features=1000, out_features=100, bias=True)\n",
            "  (fc3): Linear(in_features=100, out_features=1000, bias=True)\n",
            "  (fc4): Linear(in_features=1000, out_features=50176, bias=True)\n",
            ")\n",
            "Num of 100704376 parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWAurQ4crfjV",
        "colab_type": "text"
      },
      "source": [
        "#### Extract Latent Vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdCXz2X4MM8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "58baa3b9-3282-450a-882b-59f8111cff0f"
      },
      "source": [
        "for i, (data, _) in enumerate(z_loader):  # load_whole data(9339)\n",
        "    data = data.to(device)\n",
        "    recon_batch, mu, logvar, z = model(data)\n",
        "    # save latent_vector\n",
        "    latent_vector = z.detach().cpu().clone().numpy()  # change tensor type data to cpu().numpy()\n",
        "                                                        # latent_vector_size: (num_of_data, 100)\n",
        "    # save label\n",
        "    label = _.detach().cpu().clone().numpy()\n",
        "    label =label.reshape(1, -1)\n",
        "    print(label.shape)\n",
        "\n",
        "    # concat_data\n",
        "    latent_z = np.concatenate((latent_vector, label.T), axis=1)  # latent_z: (9339, 101): (num_data, latent_z + label) \n",
        "    print(latent_z.shape)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 9339)\n",
            "(9339, 101)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-882050dc4718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_z\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'Epoch_z_vector.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_z\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# but latent vector size is (16, 100).... just 16...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                     \u001b[0;31m# 1 Epoch Îã®ÏúÑÎ°ú latent vectorÎ•º Ï†ÄÏû•ÌïúÎã§\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'epoch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wnVEyw519Dx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6453236-41e6-4da9-e16c-d52bd4224e7b"
      },
      "source": [
        "with open(('./'+str(10+1)+'Epoch_z_vector.npy'), 'wb') as f:\n",
        "        np.save(f, latent_z)  # but latent vector size is (16, 100).... just 16...\n",
        "                                    # 1 Epoch Îã®ÏúÑÎ°ú latent vectorÎ•º Ï†ÄÏû•ÌïúÎã§\n",
        "                                    # Ïù¥ ÎñÑ, latent vectorÏùò sizeÎäî test_datasetÏùò ÌÅ¨Í∏∞Í∞Ä ÎêòÏñ¥Ïïº ÌïúÎã§\n",
        "                                    # Í≤∞Í≥ºÍ∞íÏù¥ Ï¢ãÏùÄ vectorÎäî Ï¢ãÏùÄ featureÎ°ú ÏÇ¨Ïö©Ìï† Ïàò ÏûàÎã§.\n",
        "# plot latent vector Every 10 Epochs\n",
        "print(\"Svae Latent vector!\")"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Svae Latent vector!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3oE5MisNBCr",
        "colab_type": "text"
      },
      "source": [
        "### Datapreparation\n",
        "* make pandas DataFrame\n",
        "* save pandas dataframe to csv\n",
        "<br>\n",
        "\n",
        "\n",
        "\n",
        "next>>\n",
        "* data scaling\n",
        "* build model(define hypothesis)\n",
        "* evaluation\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "11Epoch_z_vector.npy\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtHtWgZ8MhPx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "830069ae-a881-492a-c1ef-772194bc652e"
      },
      "source": [
        "latent_vector = np.load('./11Epoch_z_vector.npy')\n",
        "print(\"Load Latent_v!\")\n",
        "print(latent_vector.shape)\n",
        "\n",
        "data = latent_vector"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Load Latent_v!\n",
            "(9339, 101)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvPj7HMuSGRZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "7e5dc263-107e-4651-feb8-c4a61119181c"
      },
      "source": [
        "print(data.shape)\n",
        "print(data[:, 100])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9339, 101)\n",
            "[ 7.  3.  2. ...  2. 24. 14.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MymxzpG2Q_ol",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "d0a38683-bbab-49f4-ddee-81765a947671"
      },
      "source": [
        "# numpy to pandas\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame(data=data[:, :101])\n",
        "data.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.074760</td>\n",
              "      <td>2.022230</td>\n",
              "      <td>0.005264</td>\n",
              "      <td>0.392614</td>\n",
              "      <td>-0.181036</td>\n",
              "      <td>-0.369056</td>\n",
              "      <td>-0.223493</td>\n",
              "      <td>-0.806400</td>\n",
              "      <td>-0.522159</td>\n",
              "      <td>-0.863526</td>\n",
              "      <td>-0.332633</td>\n",
              "      <td>0.775755</td>\n",
              "      <td>-0.695117</td>\n",
              "      <td>0.499550</td>\n",
              "      <td>1.331114</td>\n",
              "      <td>1.010958</td>\n",
              "      <td>-1.217542</td>\n",
              "      <td>-0.891008</td>\n",
              "      <td>1.298618</td>\n",
              "      <td>-0.270849</td>\n",
              "      <td>-1.139377</td>\n",
              "      <td>-0.198567</td>\n",
              "      <td>-0.673687</td>\n",
              "      <td>-0.939522</td>\n",
              "      <td>-0.688575</td>\n",
              "      <td>-0.216446</td>\n",
              "      <td>1.283347</td>\n",
              "      <td>1.394188</td>\n",
              "      <td>0.436754</td>\n",
              "      <td>1.491956</td>\n",
              "      <td>0.647735</td>\n",
              "      <td>-1.907286</td>\n",
              "      <td>0.695409</td>\n",
              "      <td>0.496752</td>\n",
              "      <td>0.252555</td>\n",
              "      <td>0.844662</td>\n",
              "      <td>0.994442</td>\n",
              "      <td>0.527004</td>\n",
              "      <td>-0.069175</td>\n",
              "      <td>2.074639</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.045161</td>\n",
              "      <td>1.134621</td>\n",
              "      <td>0.491393</td>\n",
              "      <td>0.331737</td>\n",
              "      <td>-0.923385</td>\n",
              "      <td>0.200713</td>\n",
              "      <td>-0.168143</td>\n",
              "      <td>-0.295930</td>\n",
              "      <td>1.023374</td>\n",
              "      <td>1.422266</td>\n",
              "      <td>1.467682</td>\n",
              "      <td>-0.442953</td>\n",
              "      <td>1.540047</td>\n",
              "      <td>-0.793314</td>\n",
              "      <td>-0.098048</td>\n",
              "      <td>-0.363689</td>\n",
              "      <td>-1.632762</td>\n",
              "      <td>-0.623801</td>\n",
              "      <td>0.204820</td>\n",
              "      <td>0.268576</td>\n",
              "      <td>-0.057341</td>\n",
              "      <td>-0.880265</td>\n",
              "      <td>0.499716</td>\n",
              "      <td>0.022444</td>\n",
              "      <td>1.150154</td>\n",
              "      <td>0.947700</td>\n",
              "      <td>-0.220021</td>\n",
              "      <td>1.836782</td>\n",
              "      <td>0.818549</td>\n",
              "      <td>0.410302</td>\n",
              "      <td>0.503128</td>\n",
              "      <td>0.823758</td>\n",
              "      <td>-1.162378</td>\n",
              "      <td>0.349801</td>\n",
              "      <td>0.135358</td>\n",
              "      <td>-0.380480</td>\n",
              "      <td>-1.025529</td>\n",
              "      <td>2.483093</td>\n",
              "      <td>0.761738</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.570940</td>\n",
              "      <td>1.355570</td>\n",
              "      <td>0.105026</td>\n",
              "      <td>2.382208</td>\n",
              "      <td>-0.421001</td>\n",
              "      <td>-0.251137</td>\n",
              "      <td>-1.256089</td>\n",
              "      <td>-0.081605</td>\n",
              "      <td>0.575721</td>\n",
              "      <td>-0.611078</td>\n",
              "      <td>1.050410</td>\n",
              "      <td>1.616762</td>\n",
              "      <td>-1.213972</td>\n",
              "      <td>-0.868891</td>\n",
              "      <td>-0.805596</td>\n",
              "      <td>1.750196</td>\n",
              "      <td>-1.986394</td>\n",
              "      <td>-0.687034</td>\n",
              "      <td>-1.014709</td>\n",
              "      <td>0.472611</td>\n",
              "      <td>-1.651651</td>\n",
              "      <td>-0.136497</td>\n",
              "      <td>-0.599357</td>\n",
              "      <td>0.035993</td>\n",
              "      <td>-0.385072</td>\n",
              "      <td>-0.072630</td>\n",
              "      <td>1.758502</td>\n",
              "      <td>-1.442734</td>\n",
              "      <td>-0.488999</td>\n",
              "      <td>1.340759</td>\n",
              "      <td>-0.206022</td>\n",
              "      <td>-2.262341</td>\n",
              "      <td>-0.838148</td>\n",
              "      <td>0.204638</td>\n",
              "      <td>1.830359</td>\n",
              "      <td>-1.756884</td>\n",
              "      <td>1.968087</td>\n",
              "      <td>0.105983</td>\n",
              "      <td>-0.933381</td>\n",
              "      <td>2.854934</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.283615</td>\n",
              "      <td>0.665029</td>\n",
              "      <td>-1.046107</td>\n",
              "      <td>0.905249</td>\n",
              "      <td>0.208101</td>\n",
              "      <td>-0.098505</td>\n",
              "      <td>-0.242531</td>\n",
              "      <td>-1.409439</td>\n",
              "      <td>1.884905</td>\n",
              "      <td>-0.161235</td>\n",
              "      <td>0.377333</td>\n",
              "      <td>0.232317</td>\n",
              "      <td>-0.222511</td>\n",
              "      <td>-0.197332</td>\n",
              "      <td>-2.173722</td>\n",
              "      <td>-2.001394</td>\n",
              "      <td>-1.578223</td>\n",
              "      <td>1.982911</td>\n",
              "      <td>-0.843730</td>\n",
              "      <td>0.328692</td>\n",
              "      <td>2.366330</td>\n",
              "      <td>0.573370</td>\n",
              "      <td>2.370511</td>\n",
              "      <td>0.124766</td>\n",
              "      <td>-0.318144</td>\n",
              "      <td>-0.366861</td>\n",
              "      <td>0.881986</td>\n",
              "      <td>-0.965351</td>\n",
              "      <td>0.707636</td>\n",
              "      <td>-0.615570</td>\n",
              "      <td>-0.830268</td>\n",
              "      <td>0.957833</td>\n",
              "      <td>-0.882062</td>\n",
              "      <td>-0.307394</td>\n",
              "      <td>0.492823</td>\n",
              "      <td>1.017216</td>\n",
              "      <td>-1.182661</td>\n",
              "      <td>-0.782644</td>\n",
              "      <td>-0.187560</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.292550</td>\n",
              "      <td>0.072045</td>\n",
              "      <td>0.844364</td>\n",
              "      <td>0.300852</td>\n",
              "      <td>-0.712505</td>\n",
              "      <td>-0.031150</td>\n",
              "      <td>-1.641721</td>\n",
              "      <td>-1.326200</td>\n",
              "      <td>0.468264</td>\n",
              "      <td>0.405294</td>\n",
              "      <td>0.274585</td>\n",
              "      <td>0.734321</td>\n",
              "      <td>-1.259570</td>\n",
              "      <td>-0.710230</td>\n",
              "      <td>0.620657</td>\n",
              "      <td>-0.604613</td>\n",
              "      <td>-1.502707</td>\n",
              "      <td>-0.846367</td>\n",
              "      <td>-0.289415</td>\n",
              "      <td>0.621050</td>\n",
              "      <td>0.164390</td>\n",
              "      <td>-0.636665</td>\n",
              "      <td>0.123245</td>\n",
              "      <td>-1.642753</td>\n",
              "      <td>0.341759</td>\n",
              "      <td>0.269346</td>\n",
              "      <td>-0.417853</td>\n",
              "      <td>-0.327364</td>\n",
              "      <td>0.346950</td>\n",
              "      <td>-0.343290</td>\n",
              "      <td>-0.870022</td>\n",
              "      <td>-2.237232</td>\n",
              "      <td>-1.001039</td>\n",
              "      <td>0.332311</td>\n",
              "      <td>0.308614</td>\n",
              "      <td>0.303245</td>\n",
              "      <td>1.927465</td>\n",
              "      <td>0.360988</td>\n",
              "      <td>-1.312021</td>\n",
              "      <td>2.855052</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.863498</td>\n",
              "      <td>0.764056</td>\n",
              "      <td>-0.806759</td>\n",
              "      <td>1.470122</td>\n",
              "      <td>0.078139</td>\n",
              "      <td>-0.287304</td>\n",
              "      <td>0.554923</td>\n",
              "      <td>1.620703</td>\n",
              "      <td>1.553455</td>\n",
              "      <td>0.890862</td>\n",
              "      <td>0.328180</td>\n",
              "      <td>0.058832</td>\n",
              "      <td>-0.548805</td>\n",
              "      <td>-1.027731</td>\n",
              "      <td>-0.848426</td>\n",
              "      <td>0.078214</td>\n",
              "      <td>-0.722003</td>\n",
              "      <td>0.630865</td>\n",
              "      <td>-1.226391</td>\n",
              "      <td>0.392899</td>\n",
              "      <td>1.764031</td>\n",
              "      <td>0.025501</td>\n",
              "      <td>1.249633</td>\n",
              "      <td>0.055706</td>\n",
              "      <td>-1.209505</td>\n",
              "      <td>-0.823930</td>\n",
              "      <td>-0.755709</td>\n",
              "      <td>-1.667844</td>\n",
              "      <td>-0.530449</td>\n",
              "      <td>-0.121031</td>\n",
              "      <td>-0.243825</td>\n",
              "      <td>1.972044</td>\n",
              "      <td>0.710414</td>\n",
              "      <td>-0.185604</td>\n",
              "      <td>0.622770</td>\n",
              "      <td>-0.601778</td>\n",
              "      <td>-0.272074</td>\n",
              "      <td>1.796188</td>\n",
              "      <td>0.707452</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.366257</td>\n",
              "      <td>0.230313</td>\n",
              "      <td>-0.684654</td>\n",
              "      <td>1.186263</td>\n",
              "      <td>-0.869948</td>\n",
              "      <td>0.027598</td>\n",
              "      <td>0.216340</td>\n",
              "      <td>-0.912180</td>\n",
              "      <td>0.685560</td>\n",
              "      <td>-0.748203</td>\n",
              "      <td>1.041265</td>\n",
              "      <td>1.858537</td>\n",
              "      <td>0.393133</td>\n",
              "      <td>-0.336696</td>\n",
              "      <td>-1.497047</td>\n",
              "      <td>0.672229</td>\n",
              "      <td>-1.200527</td>\n",
              "      <td>-0.784271</td>\n",
              "      <td>-0.051274</td>\n",
              "      <td>-0.142332</td>\n",
              "      <td>-0.622586</td>\n",
              "      <td>0.820196</td>\n",
              "      <td>-0.728867</td>\n",
              "      <td>-1.261010</td>\n",
              "      <td>0.080103</td>\n",
              "      <td>-0.134554</td>\n",
              "      <td>0.030223</td>\n",
              "      <td>-0.549437</td>\n",
              "      <td>-0.926755</td>\n",
              "      <td>-0.197334</td>\n",
              "      <td>0.596474</td>\n",
              "      <td>-1.475972</td>\n",
              "      <td>-1.531234</td>\n",
              "      <td>-1.742186</td>\n",
              "      <td>-0.263101</td>\n",
              "      <td>-0.330866</td>\n",
              "      <td>1.508977</td>\n",
              "      <td>1.013103</td>\n",
              "      <td>0.262295</td>\n",
              "      <td>2.951676</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.447134</td>\n",
              "      <td>0.939994</td>\n",
              "      <td>-0.528569</td>\n",
              "      <td>0.295357</td>\n",
              "      <td>1.007292</td>\n",
              "      <td>-1.410107</td>\n",
              "      <td>-0.549462</td>\n",
              "      <td>-0.839898</td>\n",
              "      <td>1.580592</td>\n",
              "      <td>0.526468</td>\n",
              "      <td>1.213918</td>\n",
              "      <td>1.710415</td>\n",
              "      <td>0.104702</td>\n",
              "      <td>-0.591928</td>\n",
              "      <td>-2.075770</td>\n",
              "      <td>-0.689329</td>\n",
              "      <td>-1.475914</td>\n",
              "      <td>0.928908</td>\n",
              "      <td>-0.693722</td>\n",
              "      <td>-0.120317</td>\n",
              "      <td>1.701780</td>\n",
              "      <td>-0.189897</td>\n",
              "      <td>0.634573</td>\n",
              "      <td>0.078916</td>\n",
              "      <td>0.625399</td>\n",
              "      <td>-1.398061</td>\n",
              "      <td>1.101900</td>\n",
              "      <td>-0.179323</td>\n",
              "      <td>1.081376</td>\n",
              "      <td>0.486084</td>\n",
              "      <td>-0.229846</td>\n",
              "      <td>0.954376</td>\n",
              "      <td>-0.954479</td>\n",
              "      <td>-0.760801</td>\n",
              "      <td>1.614972</td>\n",
              "      <td>-1.063161</td>\n",
              "      <td>-0.848987</td>\n",
              "      <td>-0.328555</td>\n",
              "      <td>-1.058898</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.899964</td>\n",
              "      <td>-1.596224</td>\n",
              "      <td>1.688782</td>\n",
              "      <td>1.025586</td>\n",
              "      <td>-1.451643</td>\n",
              "      <td>-0.427293</td>\n",
              "      <td>-0.525212</td>\n",
              "      <td>-1.822712</td>\n",
              "      <td>-0.458857</td>\n",
              "      <td>-0.987899</td>\n",
              "      <td>-1.426500</td>\n",
              "      <td>1.793921</td>\n",
              "      <td>0.550701</td>\n",
              "      <td>0.433661</td>\n",
              "      <td>-0.740163</td>\n",
              "      <td>-1.197379</td>\n",
              "      <td>-2.953953</td>\n",
              "      <td>-1.603912</td>\n",
              "      <td>-2.593912</td>\n",
              "      <td>-1.078439</td>\n",
              "      <td>-1.405706</td>\n",
              "      <td>1.938449</td>\n",
              "      <td>-2.679231</td>\n",
              "      <td>-1.989452</td>\n",
              "      <td>-0.012602</td>\n",
              "      <td>-2.240786</td>\n",
              "      <td>-1.535346</td>\n",
              "      <td>0.294434</td>\n",
              "      <td>1.825396</td>\n",
              "      <td>1.283387</td>\n",
              "      <td>0.122752</td>\n",
              "      <td>0.403363</td>\n",
              "      <td>0.233870</td>\n",
              "      <td>-0.737338</td>\n",
              "      <td>-1.044760</td>\n",
              "      <td>-0.948965</td>\n",
              "      <td>-0.763444</td>\n",
              "      <td>1.036627</td>\n",
              "      <td>2.480093</td>\n",
              "      <td>0.252194</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.155172</td>\n",
              "      <td>1.899592</td>\n",
              "      <td>1.051491</td>\n",
              "      <td>2.833673</td>\n",
              "      <td>-1.802613</td>\n",
              "      <td>-0.095620</td>\n",
              "      <td>-1.839952</td>\n",
              "      <td>-0.321125</td>\n",
              "      <td>0.991234</td>\n",
              "      <td>-0.055728</td>\n",
              "      <td>1.655902</td>\n",
              "      <td>-0.597439</td>\n",
              "      <td>-0.337931</td>\n",
              "      <td>-0.208908</td>\n",
              "      <td>0.111292</td>\n",
              "      <td>1.563351</td>\n",
              "      <td>-2.186515</td>\n",
              "      <td>-1.224082</td>\n",
              "      <td>1.141217</td>\n",
              "      <td>-0.566647</td>\n",
              "      <td>-1.134578</td>\n",
              "      <td>2.934387</td>\n",
              "      <td>2.998872</td>\n",
              "      <td>0.130571</td>\n",
              "      <td>0.524407</td>\n",
              "      <td>2.324645</td>\n",
              "      <td>2.087171</td>\n",
              "      <td>-0.442157</td>\n",
              "      <td>1.521167</td>\n",
              "      <td>0.421690</td>\n",
              "      <td>2.081017</td>\n",
              "      <td>1.108058</td>\n",
              "      <td>0.484758</td>\n",
              "      <td>0.672354</td>\n",
              "      <td>1.290729</td>\n",
              "      <td>2.343422</td>\n",
              "      <td>-0.157449</td>\n",
              "      <td>-1.004076</td>\n",
              "      <td>-1.487925</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 101 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0         1         2         3    ...       97        98        99    100\n",
              "0 -0.074760  2.022230  0.005264  0.392614  ... -1.025529  2.483093  0.761738   7.0\n",
              "1  0.570940  1.355570  0.105026  2.382208  ... -1.182661 -0.782644 -0.187560   3.0\n",
              "2  2.292550  0.072045  0.844364  0.300852  ... -0.272074  1.796188  0.707452   2.0\n",
              "3 -0.366257  0.230313 -0.684654  1.186263  ... -0.848987 -0.328555 -1.058898   3.0\n",
              "4 -0.899964 -1.596224  1.688782  1.025586  ... -0.157449 -1.004076 -1.487925  10.0\n",
              "\n",
              "[5 rows x 101 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5BtVD98sQto",
        "colab_type": "text"
      },
      "source": [
        "Save pandas DataFrame to csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKt3GmousUDG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "outputId": "557e02b0-ecf5-4535-9bf1-50f628bac687"
      },
      "source": [
        "data.to_csv('./latent_dataset.csv', index=False)\n",
        "df = pd.read_csv('./latent_dataset.csv')\n",
        "df.head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>61</th>\n",
              "      <th>62</th>\n",
              "      <th>63</th>\n",
              "      <th>64</th>\n",
              "      <th>65</th>\n",
              "      <th>66</th>\n",
              "      <th>67</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "      <th>86</th>\n",
              "      <th>87</th>\n",
              "      <th>88</th>\n",
              "      <th>89</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.074760</td>\n",
              "      <td>2.022230</td>\n",
              "      <td>0.005264</td>\n",
              "      <td>0.392614</td>\n",
              "      <td>-0.181036</td>\n",
              "      <td>-0.369056</td>\n",
              "      <td>-0.223493</td>\n",
              "      <td>-0.806400</td>\n",
              "      <td>-0.522159</td>\n",
              "      <td>-0.863526</td>\n",
              "      <td>-0.332633</td>\n",
              "      <td>0.775755</td>\n",
              "      <td>-0.695117</td>\n",
              "      <td>0.499550</td>\n",
              "      <td>1.331114</td>\n",
              "      <td>1.010958</td>\n",
              "      <td>-1.217542</td>\n",
              "      <td>-0.891008</td>\n",
              "      <td>1.298618</td>\n",
              "      <td>-0.270849</td>\n",
              "      <td>-1.139377</td>\n",
              "      <td>-0.198567</td>\n",
              "      <td>-0.673687</td>\n",
              "      <td>-0.939522</td>\n",
              "      <td>-0.688575</td>\n",
              "      <td>-0.216446</td>\n",
              "      <td>1.283347</td>\n",
              "      <td>1.394188</td>\n",
              "      <td>0.436754</td>\n",
              "      <td>1.491956</td>\n",
              "      <td>0.647735</td>\n",
              "      <td>-1.907286</td>\n",
              "      <td>0.695409</td>\n",
              "      <td>0.496752</td>\n",
              "      <td>0.252555</td>\n",
              "      <td>0.844662</td>\n",
              "      <td>0.994442</td>\n",
              "      <td>0.527004</td>\n",
              "      <td>-0.069175</td>\n",
              "      <td>2.074639</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.045161</td>\n",
              "      <td>1.134621</td>\n",
              "      <td>0.491393</td>\n",
              "      <td>0.331737</td>\n",
              "      <td>-0.923385</td>\n",
              "      <td>0.200713</td>\n",
              "      <td>-0.168143</td>\n",
              "      <td>-0.295930</td>\n",
              "      <td>1.023374</td>\n",
              "      <td>1.422266</td>\n",
              "      <td>1.467682</td>\n",
              "      <td>-0.442953</td>\n",
              "      <td>1.540047</td>\n",
              "      <td>-0.793314</td>\n",
              "      <td>-0.098048</td>\n",
              "      <td>-0.363689</td>\n",
              "      <td>-1.632762</td>\n",
              "      <td>-0.623801</td>\n",
              "      <td>0.204820</td>\n",
              "      <td>0.268576</td>\n",
              "      <td>-0.057341</td>\n",
              "      <td>-0.880265</td>\n",
              "      <td>0.499716</td>\n",
              "      <td>0.022444</td>\n",
              "      <td>1.150154</td>\n",
              "      <td>0.947700</td>\n",
              "      <td>-0.220021</td>\n",
              "      <td>1.836782</td>\n",
              "      <td>0.818549</td>\n",
              "      <td>0.410302</td>\n",
              "      <td>0.503128</td>\n",
              "      <td>0.823758</td>\n",
              "      <td>-1.162378</td>\n",
              "      <td>0.349801</td>\n",
              "      <td>0.135358</td>\n",
              "      <td>-0.380480</td>\n",
              "      <td>-1.025529</td>\n",
              "      <td>2.483093</td>\n",
              "      <td>0.761738</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.570940</td>\n",
              "      <td>1.355570</td>\n",
              "      <td>0.105026</td>\n",
              "      <td>2.382208</td>\n",
              "      <td>-0.421001</td>\n",
              "      <td>-0.251137</td>\n",
              "      <td>-1.256089</td>\n",
              "      <td>-0.081605</td>\n",
              "      <td>0.575721</td>\n",
              "      <td>-0.611078</td>\n",
              "      <td>1.050410</td>\n",
              "      <td>1.616762</td>\n",
              "      <td>-1.213972</td>\n",
              "      <td>-0.868891</td>\n",
              "      <td>-0.805596</td>\n",
              "      <td>1.750196</td>\n",
              "      <td>-1.986394</td>\n",
              "      <td>-0.687034</td>\n",
              "      <td>-1.014709</td>\n",
              "      <td>0.472611</td>\n",
              "      <td>-1.651651</td>\n",
              "      <td>-0.136497</td>\n",
              "      <td>-0.599357</td>\n",
              "      <td>0.035993</td>\n",
              "      <td>-0.385072</td>\n",
              "      <td>-0.072630</td>\n",
              "      <td>1.758502</td>\n",
              "      <td>-1.442734</td>\n",
              "      <td>-0.488999</td>\n",
              "      <td>1.340759</td>\n",
              "      <td>-0.206022</td>\n",
              "      <td>-2.262341</td>\n",
              "      <td>-0.838148</td>\n",
              "      <td>0.204638</td>\n",
              "      <td>1.830359</td>\n",
              "      <td>-1.756884</td>\n",
              "      <td>1.968087</td>\n",
              "      <td>0.105983</td>\n",
              "      <td>-0.933381</td>\n",
              "      <td>2.854934</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.283615</td>\n",
              "      <td>0.665029</td>\n",
              "      <td>-1.046107</td>\n",
              "      <td>0.905249</td>\n",
              "      <td>0.208101</td>\n",
              "      <td>-0.098505</td>\n",
              "      <td>-0.242531</td>\n",
              "      <td>-1.409439</td>\n",
              "      <td>1.884905</td>\n",
              "      <td>-0.161235</td>\n",
              "      <td>0.377333</td>\n",
              "      <td>0.232317</td>\n",
              "      <td>-0.222511</td>\n",
              "      <td>-0.197332</td>\n",
              "      <td>-2.173722</td>\n",
              "      <td>-2.001394</td>\n",
              "      <td>-1.578223</td>\n",
              "      <td>1.982911</td>\n",
              "      <td>-0.843730</td>\n",
              "      <td>0.328692</td>\n",
              "      <td>2.366330</td>\n",
              "      <td>0.573370</td>\n",
              "      <td>2.370511</td>\n",
              "      <td>0.124766</td>\n",
              "      <td>-0.318144</td>\n",
              "      <td>-0.366861</td>\n",
              "      <td>0.881986</td>\n",
              "      <td>-0.965351</td>\n",
              "      <td>0.707636</td>\n",
              "      <td>-0.615570</td>\n",
              "      <td>-0.830268</td>\n",
              "      <td>0.957833</td>\n",
              "      <td>-0.882062</td>\n",
              "      <td>-0.307394</td>\n",
              "      <td>0.492823</td>\n",
              "      <td>1.017216</td>\n",
              "      <td>-1.182661</td>\n",
              "      <td>-0.782644</td>\n",
              "      <td>-0.187560</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.292550</td>\n",
              "      <td>0.072045</td>\n",
              "      <td>0.844364</td>\n",
              "      <td>0.300852</td>\n",
              "      <td>-0.712505</td>\n",
              "      <td>-0.031150</td>\n",
              "      <td>-1.641721</td>\n",
              "      <td>-1.326200</td>\n",
              "      <td>0.468264</td>\n",
              "      <td>0.405294</td>\n",
              "      <td>0.274585</td>\n",
              "      <td>0.734321</td>\n",
              "      <td>-1.259570</td>\n",
              "      <td>-0.710230</td>\n",
              "      <td>0.620657</td>\n",
              "      <td>-0.604613</td>\n",
              "      <td>-1.502707</td>\n",
              "      <td>-0.846367</td>\n",
              "      <td>-0.289415</td>\n",
              "      <td>0.621050</td>\n",
              "      <td>0.164390</td>\n",
              "      <td>-0.636665</td>\n",
              "      <td>0.123245</td>\n",
              "      <td>-1.642753</td>\n",
              "      <td>0.341759</td>\n",
              "      <td>0.269346</td>\n",
              "      <td>-0.417853</td>\n",
              "      <td>-0.327364</td>\n",
              "      <td>0.346950</td>\n",
              "      <td>-0.343290</td>\n",
              "      <td>-0.870022</td>\n",
              "      <td>-2.237232</td>\n",
              "      <td>-1.001039</td>\n",
              "      <td>0.332311</td>\n",
              "      <td>0.308614</td>\n",
              "      <td>0.303245</td>\n",
              "      <td>1.927465</td>\n",
              "      <td>0.360988</td>\n",
              "      <td>-1.312021</td>\n",
              "      <td>2.855052</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.863498</td>\n",
              "      <td>0.764056</td>\n",
              "      <td>-0.806759</td>\n",
              "      <td>1.470122</td>\n",
              "      <td>0.078139</td>\n",
              "      <td>-0.287304</td>\n",
              "      <td>0.554923</td>\n",
              "      <td>1.620703</td>\n",
              "      <td>1.553455</td>\n",
              "      <td>0.890862</td>\n",
              "      <td>0.328180</td>\n",
              "      <td>0.058832</td>\n",
              "      <td>-0.548805</td>\n",
              "      <td>-1.027731</td>\n",
              "      <td>-0.848426</td>\n",
              "      <td>0.078214</td>\n",
              "      <td>-0.722003</td>\n",
              "      <td>0.630865</td>\n",
              "      <td>-1.226391</td>\n",
              "      <td>0.392899</td>\n",
              "      <td>1.764031</td>\n",
              "      <td>0.025501</td>\n",
              "      <td>1.249633</td>\n",
              "      <td>0.055706</td>\n",
              "      <td>-1.209505</td>\n",
              "      <td>-0.823930</td>\n",
              "      <td>-0.755709</td>\n",
              "      <td>-1.667844</td>\n",
              "      <td>-0.530449</td>\n",
              "      <td>-0.121031</td>\n",
              "      <td>-0.243825</td>\n",
              "      <td>1.972044</td>\n",
              "      <td>0.710414</td>\n",
              "      <td>-0.185604</td>\n",
              "      <td>0.622770</td>\n",
              "      <td>-0.601778</td>\n",
              "      <td>-0.272074</td>\n",
              "      <td>1.796188</td>\n",
              "      <td>0.707452</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.366257</td>\n",
              "      <td>0.230313</td>\n",
              "      <td>-0.684654</td>\n",
              "      <td>1.186263</td>\n",
              "      <td>-0.869948</td>\n",
              "      <td>0.027598</td>\n",
              "      <td>0.216340</td>\n",
              "      <td>-0.912180</td>\n",
              "      <td>0.685560</td>\n",
              "      <td>-0.748203</td>\n",
              "      <td>1.041265</td>\n",
              "      <td>1.858537</td>\n",
              "      <td>0.393133</td>\n",
              "      <td>-0.336696</td>\n",
              "      <td>-1.497047</td>\n",
              "      <td>0.672229</td>\n",
              "      <td>-1.200527</td>\n",
              "      <td>-0.784271</td>\n",
              "      <td>-0.051274</td>\n",
              "      <td>-0.142332</td>\n",
              "      <td>-0.622586</td>\n",
              "      <td>0.820196</td>\n",
              "      <td>-0.728867</td>\n",
              "      <td>-1.261010</td>\n",
              "      <td>0.080103</td>\n",
              "      <td>-0.134554</td>\n",
              "      <td>0.030223</td>\n",
              "      <td>-0.549437</td>\n",
              "      <td>-0.926755</td>\n",
              "      <td>-0.197334</td>\n",
              "      <td>0.596474</td>\n",
              "      <td>-1.475972</td>\n",
              "      <td>-1.531234</td>\n",
              "      <td>-1.742186</td>\n",
              "      <td>-0.263101</td>\n",
              "      <td>-0.330866</td>\n",
              "      <td>1.508977</td>\n",
              "      <td>1.013103</td>\n",
              "      <td>0.262295</td>\n",
              "      <td>2.951676</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.447134</td>\n",
              "      <td>0.939994</td>\n",
              "      <td>-0.528569</td>\n",
              "      <td>0.295357</td>\n",
              "      <td>1.007292</td>\n",
              "      <td>-1.410107</td>\n",
              "      <td>-0.549462</td>\n",
              "      <td>-0.839898</td>\n",
              "      <td>1.580592</td>\n",
              "      <td>0.526468</td>\n",
              "      <td>1.213918</td>\n",
              "      <td>1.710415</td>\n",
              "      <td>0.104702</td>\n",
              "      <td>-0.591928</td>\n",
              "      <td>-2.075770</td>\n",
              "      <td>-0.689329</td>\n",
              "      <td>-1.475914</td>\n",
              "      <td>0.928908</td>\n",
              "      <td>-0.693722</td>\n",
              "      <td>-0.120317</td>\n",
              "      <td>1.701780</td>\n",
              "      <td>-0.189897</td>\n",
              "      <td>0.634573</td>\n",
              "      <td>0.078916</td>\n",
              "      <td>0.625399</td>\n",
              "      <td>-1.398061</td>\n",
              "      <td>1.101900</td>\n",
              "      <td>-0.179323</td>\n",
              "      <td>1.081376</td>\n",
              "      <td>0.486084</td>\n",
              "      <td>-0.229846</td>\n",
              "      <td>0.954376</td>\n",
              "      <td>-0.954479</td>\n",
              "      <td>-0.760801</td>\n",
              "      <td>1.614972</td>\n",
              "      <td>-1.063161</td>\n",
              "      <td>-0.848987</td>\n",
              "      <td>-0.328555</td>\n",
              "      <td>-1.058898</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.899964</td>\n",
              "      <td>-1.596224</td>\n",
              "      <td>1.688782</td>\n",
              "      <td>1.025586</td>\n",
              "      <td>-1.451643</td>\n",
              "      <td>-0.427293</td>\n",
              "      <td>-0.525212</td>\n",
              "      <td>-1.822712</td>\n",
              "      <td>-0.458857</td>\n",
              "      <td>-0.987899</td>\n",
              "      <td>-1.426500</td>\n",
              "      <td>1.793921</td>\n",
              "      <td>0.550701</td>\n",
              "      <td>0.433661</td>\n",
              "      <td>-0.740163</td>\n",
              "      <td>-1.197379</td>\n",
              "      <td>-2.953953</td>\n",
              "      <td>-1.603912</td>\n",
              "      <td>-2.593912</td>\n",
              "      <td>-1.078439</td>\n",
              "      <td>-1.405706</td>\n",
              "      <td>1.938449</td>\n",
              "      <td>-2.679231</td>\n",
              "      <td>-1.989452</td>\n",
              "      <td>-0.012602</td>\n",
              "      <td>-2.240786</td>\n",
              "      <td>-1.535346</td>\n",
              "      <td>0.294434</td>\n",
              "      <td>1.825396</td>\n",
              "      <td>1.283387</td>\n",
              "      <td>0.122752</td>\n",
              "      <td>0.403363</td>\n",
              "      <td>0.233870</td>\n",
              "      <td>-0.737338</td>\n",
              "      <td>-1.044760</td>\n",
              "      <td>-0.948965</td>\n",
              "      <td>-0.763444</td>\n",
              "      <td>1.036627</td>\n",
              "      <td>2.480093</td>\n",
              "      <td>0.252194</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.155172</td>\n",
              "      <td>1.899592</td>\n",
              "      <td>1.051491</td>\n",
              "      <td>2.833673</td>\n",
              "      <td>-1.802613</td>\n",
              "      <td>-0.095620</td>\n",
              "      <td>-1.839952</td>\n",
              "      <td>-0.321125</td>\n",
              "      <td>0.991234</td>\n",
              "      <td>-0.055728</td>\n",
              "      <td>1.655902</td>\n",
              "      <td>-0.597439</td>\n",
              "      <td>-0.337931</td>\n",
              "      <td>-0.208908</td>\n",
              "      <td>0.111292</td>\n",
              "      <td>1.563351</td>\n",
              "      <td>-2.186515</td>\n",
              "      <td>-1.224082</td>\n",
              "      <td>1.141217</td>\n",
              "      <td>-0.566647</td>\n",
              "      <td>-1.134578</td>\n",
              "      <td>2.934387</td>\n",
              "      <td>2.998872</td>\n",
              "      <td>0.130571</td>\n",
              "      <td>0.524407</td>\n",
              "      <td>2.324645</td>\n",
              "      <td>2.087171</td>\n",
              "      <td>-0.442157</td>\n",
              "      <td>1.521167</td>\n",
              "      <td>0.421690</td>\n",
              "      <td>2.081017</td>\n",
              "      <td>1.108058</td>\n",
              "      <td>0.484758</td>\n",
              "      <td>0.672354</td>\n",
              "      <td>1.290729</td>\n",
              "      <td>2.343422</td>\n",
              "      <td>-0.157449</td>\n",
              "      <td>-1.004076</td>\n",
              "      <td>-1.487925</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows √ó 101 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3  ...        97        98        99   100\n",
              "0 -0.074760  2.022230  0.005264  0.392614  ... -1.025529  2.483093  0.761738   7.0\n",
              "1  0.570940  1.355570  0.105026  2.382208  ... -1.182661 -0.782644 -0.187560   3.0\n",
              "2  2.292550  0.072045  0.844364  0.300852  ... -0.272074  1.796188  0.707452   2.0\n",
              "3 -0.366257  0.230313 -0.684654  1.186263  ... -0.848987 -0.328555 -1.058898   3.0\n",
              "4 -0.899964 -1.596224  1.688782  1.025586  ... -0.157449 -1.004076 -1.487925  10.0\n",
              "\n",
              "[5 rows x 101 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t7-CWrJ22I_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e2a076e2-df7d-4f24-9a35-09b1b91beb5c"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9339, 101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDBsWX8p8j8p",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "# Before Preprocessing\n",
        "* -20.07.24.Thur.pm:10:53-\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-5XYldw8oqp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "42e0be2c-5b83-4c95-eb48-1f68fec029e2"
      },
      "source": [
        "# Test-Voting classifier\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# iris = datasets.load_iris()\n",
        "data = latent_vector  # re-change it to numpy\n",
        "X, y = data[:, 0:100], data[:, 100]\n",
        "\n",
        "clf1 = LogisticRegression(random_state=1)\n",
        "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "\n",
        "eclf = VotingClassifier(\n",
        "         estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
        "         voting='hard')\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
        "     scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n",
        "     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.93 (+/- 0.01) [Logistic Regression]\n",
            "Accuracy: 0.94 (+/- 0.00) [Random Forest]\n",
            "Accuracy: 0.93 (+/- 0.00) [naive Bayes]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.94 (+/- 0.00) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gu3-Tg7yQqX3",
        "colab_type": "text"
      },
      "source": [
        "### Data Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWkxK7nr56Ww",
        "colab_type": "text"
      },
      "source": [
        "Divide Data & Label<br>\n",
        "change dataframe to numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZokgRR8Y5-1R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6de2b47d-6ff7-41eb-f1e9-0b1483454788"
      },
      "source": [
        "df = df.to_numpy()\n",
        "df.shape"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9339, 101)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hbQKf4z67Wl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "df8e3ca6-102b-4837-9bbc-da5ca574980c"
      },
      "source": [
        "# make data & label variable\n",
        "data = df[:, :100]\n",
        "label = df[:, 100]\n",
        "\n",
        "print(data.shape, label.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9339, 100) (9339,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZKXpB6LAlji",
        "colab_type": "text"
      },
      "source": [
        "Build Model\n",
        "* data scaling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwTORai-5StA",
        "colab_type": "text"
      },
      "source": [
        "* Reference: Good Resource! - toward D.S\n",
        "    * https://towardsdatascience.com/scale-standardize-or-normalize-with-scikit-learn-6ccc7d176a02\n",
        "<br><br>\n",
        "\n",
        "\n",
        "\n",
        "* Wrap\n",
        "    * Use MinMaxScaler as the default if you are transforming a feature. It‚Äôs non-distorting.\n",
        "    * You could use RobustScaler if you have outliers and want to reduce their influence. However, you might be better off removing the outliers, instead.\n",
        "    * Use StandardScaler if you need a relatively normal distribution.\n",
        "    * Use Normalizer sparingly ‚Äî it normalizes sample rows, not feature columns. It can use l2 or l1 normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PObbIYIy48jf",
        "colab_type": "text"
      },
      "source": [
        "1st. Minmax Scaler\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRbThV__4_eV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "94742f5b-5d31-4fa7-c9ba-7d2b9ebbd3b8"
      },
      "source": [
        "# sklearn.preprocessing.MinMaxSclaer\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html?highlight=minmax%20scaler#sklearn.preprocessing.MinMaxScaler\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "data = data\n",
        "scaler = MinMaxScaler()  # make scaler obj\n",
        "\n",
        "# directly fit_transform?\n",
        "print(scaler.fit_transform(data))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.45336022 0.63622903 0.56358312 ... 0.5694765  0.68342398 0.60632197]\n",
            " [0.53180541 0.54746212 0.57470655 ... 0.55145253 0.26585075 0.49761365]\n",
            " [0.7409615  0.3765586  0.65714246 ... 0.65590229 0.595593   0.60010551]\n",
            " ...\n",
            " [0.70343739 0.55240322 0.60204721 ... 0.56925473 0.40496521 0.68498748]\n",
            " [0.49168533 0.54621097 0.51954767 ... 0.78756417 0.25227082 0.49295863]\n",
            " [0.66771601 0.53583113 0.67377908 ... 0.54747083 0.49395586 0.56545021]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9z2IgJRn8d8-",
        "colab_type": "text"
      },
      "source": [
        "classify it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A8fNyM68fNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test-Voting classifier\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# iris = datasets.load_iris()\n",
        "data = latent_vector  # re-change it to numpy\n",
        "X, y = data[:, 0:100], data[:, 100]\n",
        "\n",
        "clf1 = LogisticRegression(random_state=1)\n",
        "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "\n",
        "eclf = VotingClassifier(\n",
        "         estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
        "         voting='hard')\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
        "     scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n",
        "     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-C1iLXy8cev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtIPC3Hr5CGp",
        "colab_type": "text"
      },
      "source": [
        "2. Standard Scaler\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozTYc6T75Ezf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esy6JOL15Fbq",
        "colab_type": "text"
      },
      "source": [
        "3. Robust Scaler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuthPeeN5AsK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hh7OOoQpt-sm",
        "colab_type": "text"
      },
      "source": [
        "### Modeling\n",
        "* voting classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t5LQjW9uA3D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test-Voting classifier\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# iris = datasets.load_iris()\n",
        "data = latent_vector  # re-change it to numpy\n",
        "X, y = data[:, 0:100], data[:, 100]\n",
        "\n",
        "clf1 = LogisticRegression(random_state=1)\n",
        "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "\n",
        "eclf = VotingClassifier(\n",
        "         estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
        "         voting='hard')\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
        "     scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n",
        "     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GObvQwoehKnk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a780833f-1c5e-4a58-e5a6-58b8d3e5cb5f"
      },
      "source": [
        "! pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Post_InfoSec_Exps/Post_Exp01\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2nxn4T3S9jU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "e28215d5-1656-4cbc-d9f6-7ac0e5f652b3"
      },
      "source": [
        "latent_vector = np.load('./11Epoch_z_vector.npy')\n",
        "print(latent_vector.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-e6e5dad7b509>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlatent_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./11Epoch_z_vector.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_vector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0m_ZIP_SUFFIX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb'PK\\x05\\x06'\u001b[0m \u001b[0;31m# empty zip files start with this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAGIC_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 436\u001b[0;31m         \u001b[0mmagic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    437\u001b[0m         \u001b[0;31m# If the file size is less than N, we need to make sure not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# to seek past the beginning of the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U85u8egIEh1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "outputId": "3eeaeeba-2fc2-487b-9cb6-7c53efc55a16"
      },
      "source": [
        "# numpy to pandas\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "data = pd.DataFrame(data=latent_vector[:, :101])\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-3426210b4fe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_vector\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;36m101\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'latent_vector' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyAIRIZfTCVj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d911e75-30da-4496-8033-ab9e8596f6ca"
      },
      "source": [
        "# Test-Voting classifier\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
        "\n",
        "\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "# iris = datasets.load_iris()\n",
        "data = latent_vector  # re-change it to numpy\n",
        "X, y = data[:, 0:100], data[:, 100]\n",
        "\n",
        "clf1 = LogisticRegression(random_state=1)\n",
        "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
        "clf3 = GaussianNB()\n",
        "\n",
        "eclf = VotingClassifier(\n",
        "         estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)],\n",
        "         voting='hard')\n",
        "\n",
        "for clf, label in zip([clf1, clf2, clf3, eclf], ['Logistic Regression', 'Random Forest', 'naive Bayes', 'Ensemble']):\n",
        "     scores = cross_val_score(clf, X, y, scoring='accuracy', cv=5)\n",
        "     print(\"Accuracy: %0.2f (+/- %0.2f) [%s]\" % (scores.mean(), scores.std(), label))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.93 (+/- 0.00) [Logistic Regression]\n",
            "Accuracy: 0.94 (+/- 0.00) [Random Forest]\n",
            "Accuracy: 0.93 (+/- 0.00) [naive Bayes]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.94 (+/- 0.00) [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}