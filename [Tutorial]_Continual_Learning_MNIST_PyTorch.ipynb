{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Tutorial] Continual Learning MNIST PyTorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN4k/stGs6L32Fi4jlmEvE8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Steve-YJ/Colab_Exercise/blob/master/%5BTutorial%5D_Continual_Learning_MNIST_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8p3XGF4l7xM"
      },
      "source": [
        "# A Gentle Introduction to Continual Learning in PyTorch\r\n",
        "\r\n",
        "* Reference: https://github.com/ContinualAI/colab/blob/master/notebooks/intro_to_continual_learning.ipynb\r\n",
        "\r\n",
        "We will start with learning over the standard MNIST benchmark, then we will move in the actual continual learning setting with the Permuted MNIST benchmark. Let's have some fun! :-)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-8oLj24yQfO",
        "outputId": "2a7125a8-d92d-47fb-ab1b-a019b062df7b"
      },
      "source": [
        "! free -m"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              total        used        free      shared  buff/cache   available\n",
            "Mem:          26124        3512       19009          12        3602       23455\n",
            "Swap:             0           0           0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuQI3Vxoy-qo",
        "outputId": "6c2e5e11-bcfb-4e6d-f616-0b536e9dd6fa"
      },
      "source": [
        "! df -h"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         148G   33G  115G  23% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "tmpfs            13G     0   13G   0% /sys/fs/cgroup\n",
            "shm              13G     0   13G   0% /dev/shm\n",
            "tmpfs            13G   16K   13G   1% /var/colab\n",
            "/dev/sda1       154G   34G  120G  22% /opt/bin\n",
            "tmpfs            13G     0   13G   0% /proc/acpi\n",
            "tmpfs            13G     0   13G   0% /proc/scsi\n",
            "tmpfs            13G     0   13G   0% /sys/firmware\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KoggAr2GzA3v",
        "outputId": "417d9e3c-2be1-4f27-fb17-b1bd61f7291b"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jan  6 07:59:30 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.27.04    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P0    31W / 250W |    859MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yZixFFAzCPD"
      },
      "source": [
        "## Installing PyTorch 0.4.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vriENsqIzlEN",
        "outputId": "5d35fdf5-37de-424a-9db7-b8fa4338c1d2"
      },
      "source": [
        "import torch\r\n",
        "torch.cuda.is_available()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNNZTMSNzlRf"
      },
      "source": [
        "이제는 Colab에서도 기본적으로 torch를 사용할 수 있다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C-5F-ikezx1f"
      },
      "source": [
        "alright!<br>\r\n",
        "let us import a few libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HL2nE_DAz5Xa"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision.datasets as datasets\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmmi8bfl0KL9"
      },
      "source": [
        "## MNIST: Digits recognition with PyTorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3rKEaWM0WZ7"
      },
      "source": [
        "* All right!, let's start it!\r\n",
        "* Let's recognize the ten handwritten digits learning from 60,000, 28x28 grayscale images\r\n",
        "* For simplicity let's import a loading script they have already developed inside the Continual AI Colab repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9MKcZU601UD",
        "outputId": "47bddd0a-a6c4-4c7f-e619-af1d0ef49f9c"
      },
      "source": [
        "!git clone https://github.com/ContinualAI/colab.git continualai/colab"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'continualai/colab' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd6zefh01A68",
        "outputId": "4cd781cc-915b-4a12-f05f-6712bd436c9a"
      },
      "source": [
        "from continualai.colab.scripts import mnist\r\n",
        "mnist.init()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VecddULj1S-V",
        "outputId": "041d2027-7659-40fd-f18e-dfcfb6501c08"
      },
      "source": [
        "x_train, t_train, x_test, t_test = mnist.load()\r\n",
        "\r\n",
        "print(\"x_train dim and type\", x_train.shape, x_train.dtype)\r\n",
        "print(\"t_train dim and type\", t_train.shape, t_train.dtype)\r\n",
        "print(\"x_test dim and type\", x_test.shape, x_test.dtype)\r\n",
        "print(\"t_test dim and type\", t_test.shape, t_test.dtype)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train dim and type (60000, 1, 28, 28) float32\n",
            "t_train dim and type (60000,) uint8\n",
            "x_test dim and type (10000, 1, 28, 28) float32\n",
            "t_test dim and type (10000,) uint8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "IB__T1jE14DN",
        "outputId": "c1d03cc7-5319-4fe0-d89e-efdef96e1468"
      },
      "source": [
        "f, axarr = plt.subplots(2, 2)\r\n",
        "axarr[0, 0].imshow(x_train[1, 0], cmap=\"gray\")\r\n",
        "axarr[0,1].imshow(x_train[2, 0], cmap=\"gray\")\r\n",
        "axarr[1,0].imshow(x_train[3, 0], cmap=\"gray\")\r\n",
        "axarr[1,1].imshow(x_train[4, 0], cmap=\"gray\")\r\n",
        "np.vectorize(lambda ax:ax.axis('off'))(axarr);"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ax5nbwc22NjU"
      },
      "source": [
        "Let's now set up a few general setting before using torch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR4tOxhK2V6A",
        "outputId": "045bfc94-383c-47fd-854f-41b7f3e3b40e"
      },
      "source": [
        "# switch to False to use CPU\r\n",
        "use_cuda = True\r\n",
        "\r\n",
        "use_cuda = use_cuda and torch.cuda.is_available()  # cuda를 사용할 것이고 torch.cuda.is_available()도 True라면\r\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\r\n",
        "torch.manual_seed(1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f7550bbdc78>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XLHw6Lcdpsa"
      },
      "source": [
        "```\r\n",
        "# 이전에는 이런 형식이었던 것 같은데\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcN2oucy2rqO"
      },
      "source": [
        "* and define our first conv-net!<br>\r\n",
        "* We'll use 3 layers of convolutions and two fully connected layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTpTMdtfngQ3"
      },
      "source": [
        "class Net(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Net, self).__init__()\r\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\r\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\r\n",
        "        self.conv2_drop = nn.Dropout2d()\r\n",
        "        self.fc1 = nn.Linear(320, 50)\r\n",
        "        self.fc2 = nn.Linear(50, 10)  # 10개의 클래스로 분류\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\r\n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\r\n",
        "        x = x.view(-1, 320)\r\n",
        "        x = F.relu(self.fc1(x))\r\n",
        "        x = F.dropout(x, training=self.training)\r\n",
        "        x = self.fc2(x)\r\n",
        "        return x"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "hgyPgHIyfZ7x",
        "outputId": "b8768853-17f8-4bfd-8889-1a6f19c744f6"
      },
      "source": [
        "\"\"\"\r\n",
        "# e.g. Conv2d\r\n",
        "# With square kernels and equal stride\r\n",
        "m = nn.Conv2d(16, 33, 3, stride=2)  # input_channel, output_channel, kernel_size, stride\r\n",
        "# non-square kernels and unequal stride and with padding\r\n",
        "# m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\r\n",
        "# non-square kernels and unequal stride and with padding and dilation\r\n",
        "# m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\r\n",
        "input = torch.randn(20, 16, 50, 100)  # num_input, channel, width, height\r\n",
        "output = m(input)\r\n",
        "print(\"output.shape: \", output.shape)  # (20, 33, 24, 49)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "# e.g. dropout\r\n",
        "m = nn.Dropout(p=0.5)\r\n",
        "input = torch.randn(20, 16)\r\n",
        "x = m(input)\r\n",
        "print(\"x.shape: \", x.shape)\r\n",
        "\r\n",
        "\r\n",
        "# maxpool2d\r\n",
        "# pool of square window of size=3, stride=2\r\n",
        "m = nn.MaxPool2d(3, stride=2)\r\n",
        "# pool of non-square window\r\n",
        "input = torch.randn(20, 16, 50, 32)\r\n",
        "output = m(input)\r\n",
        "print(\"maxpool2d: \", output.shape)\r\n",
        "\r\n",
        "\"\"\""
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# e.g. Conv2d\\n# With square kernels and equal stride\\nm = nn.Conv2d(16, 33, 3, stride=2)  # input_channel, output_channel, kernel_size, stride\\n# non-square kernels and unequal stride and with padding\\n# m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2))\\n# non-square kernels and unequal stride and with padding and dilation\\n# m = nn.Conv2d(16, 33, (3, 5), stride=(2, 1), padding=(4, 2), dilation=(3, 1))\\ninput = torch.randn(20, 16, 50, 100)  # num_input, channel, width, height\\noutput = m(input)\\nprint(\"output.shape: \", output.shape)  # (20, 33, 24, 49)\\n\\n\\n\\n# e.g. dropout\\nm = nn.Dropout(p=0.5)\\ninput = torch.randn(20, 16)\\nx = m(input)\\nprint(\"x.shape: \", x.shape)\\n\\n\\n# maxpool2d\\n# pool of square window of size=3, stride=2\\nm = nn.MaxPool2d(3, stride=2)\\n# pool of non-square window\\ninput = torch.randn(20, 16, 50, 32)\\noutput = m(input)\\nprint(\"maxpool2d: \", output.shape)\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3yGrjC46Rph"
      },
      "source": [
        "Next>> we can write the train and test functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7mU6hk18gg_"
      },
      "source": [
        "def train(model, device, x_train, t_train, optimizer, epoch):\r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    for start in range(0, len(t_train)-1, 256):\r\n",
        "      end = start + 256\r\n",
        "      x, y = torch.from_numpy(x_train[start:end]), torch.from_numpy(t_train[start:end]).long()\r\n",
        "      x, y = x.to(device), y.to(device)\r\n",
        "      \r\n",
        "      optimizer.zero_grad()\r\n",
        "\r\n",
        "      output = model(x)\r\n",
        "      loss = F.cross_entropy(output, y)\r\n",
        "      loss.backward()\r\n",
        "      optimizer.step()\r\n",
        "      #print(loss.item())\r\n",
        "    print('Train Epoch: {} \\tLoss: {:.6f}'.format(epoch, loss.item()))\r\n",
        "\r\n",
        "def test(model, device, x_test, t_test):\r\n",
        "    model.eval()\r\n",
        "    test_loss = 0\r\n",
        "    correct = 0\r\n",
        "    for start in range(0, len(t_test)-1, 256):\r\n",
        "      end = start + 256\r\n",
        "      with torch.no_grad():\r\n",
        "        x, y = torch.from_numpy(x_test[start:end]), torch.from_numpy(t_test[start:end]).long()\r\n",
        "        x, y = x.to(device), y.to(device)\r\n",
        "        output = model(x)\r\n",
        "        test_loss += F.cross_entropy(output, y).item() # sum up batch loss\r\n",
        "        pred = output.max(1, keepdim=True)[1] # get the index of the max logit\r\n",
        "        correct += pred.eq(y.view_as(pred)).sum().item()\r\n",
        "\r\n",
        "    test_loss /= len(t_test)\r\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\r\n",
        "        test_loss, correct, len(t_test),\r\n",
        "        100. * correct / len(t_test)))\r\n",
        "    return 100. * correct / len(t_test)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzuEfTMc8jh4"
      },
      "source": [
        "Then we are ready to instantiate our model and start the training!\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwGIFxlW8q3L"
      },
      "source": [
        "model = Net().to(device)\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsDddAWy8rbg",
        "outputId": "b83095e2-f88c-49ea-84c1-50fdebe072c7"
      },
      "source": [
        "for epoch in range(1, 3):\r\n",
        "  train(model, device, x_train, t_train, optimizer, epoch)\r\n",
        "  test(model, device, x_test, t_test)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \tLoss: 0.554169\n",
            "Test set: Average loss: 0.0011, Accuracy: 9117/10000 (91%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.509282\n",
            "Test set: Average loss: 0.0006, Accuracy: 9531/10000 (95%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Nf1uu6V8vlg"
      },
      "source": [
        "Wow! 96% accuracy in such a short time!<br>\r\n",
        "\r\n",
        "**Questions to explore:**\r\n",
        "\r\n",
        "* Can you find a better parametrization to improve the final accuracy?\r\n",
        "* Can you change the network architecture to improve the final accuracy?\r\n",
        "* Can you achive the same performances with a smaller architecture?\r\n",
        "* What's the difference in accuracy if you change convolutions with fully connected layers?\r\n",
        "\r\n",
        "Some tips here: http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "weJOkv25vUV3"
      },
      "source": [
        "> But what if now we want the same model being able to solve a new task we encounter over time like a permuted version of the same MNIST? Let's define our custom function to permute it!\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mfQi5VqvYvS"
      },
      "source": [
        "* we want to same model being able to solve a new task that we encounter overtime\r\n",
        "* like a permuted version of the same MNIST\r\n",
        "* Let's define our custom function to permute it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTAJbcU5vzOb"
      },
      "source": [
        "def permute_mnist(mnist, seed):\r\n",
        "    \"\"\"\r\n",
        "    Given the training set, permute pixels of each img the same way\r\n",
        "    \"\"\"\r\n",
        "    np.random.seed(seed)\r\n",
        "    print(\"starting permutation...\")\r\n",
        "    h = w = 28\r\n",
        "    perm_inds = list(range(h*w))  # <- 순열 인덱스, mnist 이미지를 flatten시킨 각각의 데이터가 하나의 인덱스가 된다\r\n",
        "    np.random.shuffle(perm_inds)  # 슦아\r\n",
        "    # print(perm_inds)\r\n",
        "    perm_mnist = []\r\n",
        "    for set in mnist:\r\n",
        "        num_img = set.shape[0]\r\n",
        "        flat_set = set.reshape(num_img, w * h)  # flatten 시킨 set\r\n",
        "        perm_mnist.append(flat_set[:, perm_inds].reshape(num_img, 1, w, h))  # 같은 shape이지만 완전히 random한 값이 만들어진다\r\n",
        "    print(\"done.\")\r\n",
        "    return perm_mnist"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWE6qbLXw9Jj",
        "outputId": "faaf9bad-1514-496d-8e9d-748666c423a7"
      },
      "source": [
        "x_train2, x_test2 = permute_mnist([x_train, x_test], 0)\r\n",
        "\r\n",
        "print(x_train2.shape, x_test2.shape)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting permutation...\n",
            "done.\n",
            "(60000, 1, 28, 28) (10000, 1, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "XEeyVGJayDr1",
        "outputId": "8c27900b-3d63-411c-dee8-1839c12d233e"
      },
      "source": [
        "f, axarr = plt.subplots(1,2)\r\n",
        "axarr[0].imshow(x_train[1, 0], cmap=\"gray\")\r\n",
        "axarr[1].imshow(x_train2[3, 0], cmap=\"gray\")\r\n",
        "np.vectorize(lambda ax:ax.axis('off'))(axarr);"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWVKaKLFx7zh"
      },
      "source": [
        "Amazing. Now let's see how our pre-trained model is working on both the original and the permuted MNIST dataset:\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-0Z72iix95r",
        "outputId": "38da647a-42bf-473b-edc8-da05d9826fed"
      },
      "source": [
        "print(\"Testing on the first task:\")\r\n",
        "test(model, device, x_test, t_test)\r\n",
        "\r\n",
        "print(\"Testing on the second task:\")\r\n",
        "test(model, device, x_test2, t_test);"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing on the first task:\n",
            "Test set: Average loss: 0.0006, Accuracy: 9531/10000 (95%)\n",
            "\n",
            "Testing on the second task:\n",
            "Test set: Average loss: 0.0115, Accuracy: 1028/10000 (10%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSTO5EipyFlp"
      },
      "source": [
        "Mmmh... that's pretty bad. our model cannot generalize to this apparently very different new task!<br>\r\n",
        "Well, we can just finetune our model using the new permuted training set!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSM0GGFw3DN4"
      },
      "source": [
        "* 데이터가 완전 바뀌니깐 기존의 모델이 제대로된 성능을 보여주지 못햇다\r\n",
        "    * task1으로 학습한 모델로 task2를 평가하면 96%에서 11%로 성능이 매우 안좋아졌다\r\n",
        "\r\n",
        "* 생각\r\n",
        "    * 이렇게 결과가 나오는게 이상하지 않다고 생각한다\r\n",
        "        * 어쩌면 당연한게... 모델이 마주친 데이터가 기존의 데이터와 너무 다르다...! -21.01.06.wed- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSEwA5GP2mf5",
        "outputId": "00bfa5f9-a578-4635-d0b8-51607970927a"
      },
      "source": [
        "for epoch in range(1, 3):\r\n",
        "    train(model, device, x_train2, t_train, optimizer, epoch)\r\n",
        "    test(model, device, x_test2, t_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 \tLoss: 1.040976\n",
            "Test set: Average loss: 0.0027, Accuracy: 7808/10000 (78%)\n",
            "\n",
            "Train Epoch: 2 \tLoss: 0.987049\n",
            "Test set: Average loss: 0.0020, Accuracy: 8425/10000 (84%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d93wJtTK2mSk",
        "outputId": "d42577d1-0453-48a6-c2f7-d6eac75f7c83"
      },
      "source": [
        "print(\"Testing on the first task: \")\r\n",
        "test(model, device, x_test, t_test)\r\n",
        "\r\n",
        "print(\"Testing on the second task: \")\r\n",
        "test(model, device, x_test2, t_test)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing on the first task: \n",
            "Test set: Average loss: 0.0291, Accuracy: 2087/10000 (21%)\n",
            "\n",
            "Testing on the second task: \n",
            "Test set: Average loss: 0.0020, Accuracy: 8425/10000 (84%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYnrua3J2mHX"
      },
      "source": [
        "This is very annoying! Now we are not able to solve the original MNSIT task anymore! :-( This is the phenomenon known in literature as Catastrophic Forgetting! In the following section we well compare three different strategies for learning continually (and trying to not forget!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSIUuOBv3wTv"
      },
      "source": [
        "상당히 흥미롭다...!<br>\r\n",
        "\r\n",
        "> 이녀석...! 새로운 문제를 푸니깐 기존의 문제를 전혀 풀지 못하잖어?!\r\n",
        "\r\n",
        "* task1로 학습한 모델이 task2를 제대로 학습하지 못해서 task2를 잘 학습한 모델을 구축함\r\n",
        "* task2를 잘 학습하게 되니깐 task1에 대해서는 성능이 매우 안좋은 모델로 바뀜...(a.k.a catastrophic forgetting)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REWZ4tEb31-_"
      },
      "source": [
        "**Questions to explore**\r\n",
        "* When the permuted MNIST benchmark has been firstly introduced?\r\n",
        "* Can simple Dropout and Regularization techniques reduce forgetting?\r\n",
        "* In the permuted MNIST task, do convolutions still help increasing the accuracy?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPBtD4Z54QEH"
      },
      "source": [
        "https://papers.nips.cc/paper/2013/hash/8f1d43620bc6bb580df6e80b0dc05c48-Abstract.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOM0yRks4Up4"
      },
      "source": [
        "## CL Strategies\r\n",
        "\r\n",
        "**Questions**<br>\r\n",
        "What is CL Strategies?\r\n",
        "-> `Continual Learning` Strategiy!<br>\r\n",
        "1. Naive\r\n",
        "2. Rehearsal\r\n",
        "3. Elastic Weight Consolidation (EWC)\r\n",
        "<br>\r\n",
        "\r\n",
        "In this section, we'll take a look at three different strategies and run it on a 3-tasks Permuted MNIST<br>\r\n",
        "\r\n",
        "Finally we'll plot our results for comparison.<br>\r\n",
        "\r\n",
        "For a more comprehensive overview on recent CL strategies for deep learning, take a look at the recent paper<br>\r\n",
        "\r\n",
        "<a href=\"https://arxiv.org/abs/1806.08568\">Continuous Learning in Single-Incremental-Task Scenarios</a>\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEZhtFdg5O9-"
      },
      "source": [
        "Let's start by defining our 3 tasks with the function we have already introduced before"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CbdvoRDu5gib",
        "outputId": "a34b475c-8c88-4656-ff38-3cb46267b7e1"
      },
      "source": [
        "# task 1\r\n",
        "task_1 = [(x_train, t_train), (x_test, t_test)]\r\n",
        "\r\n",
        "# task 2\r\n",
        "x_train2, x_test2 = permute_mnist([x_train, x_test], 1)\r\n",
        "task_2 = [(x_train2, t_train), (x_test2, t_test)]\r\n",
        "\r\n",
        "# task3\r\n",
        "x_train3, x_test3 = permute_mnist([x_train, x_test], 2)\r\n",
        "task_3 = [(x_train3, t_train), (x_test3, t_test)]\r\n",
        "\r\n",
        "# task list\r\n",
        "tasks = [task_1, task_2, task_3]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "starting permutation...\n",
            "done.\n",
            "starting permutation...\n",
            "done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQrAYG0QxlOZ"
      },
      "source": [
        "task2와 task3이 각각 variant malware라면 어떨까?<br>\r\n",
        "* 이렇게 될 경우 변종 악성코드라는 새로운 task를 학습했을 때 기존 task에 대한 성능을 평가함으로써 기존 방법의 문제점을 검증할 수 있지 않을까?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr3qCRHP6MXn"
      },
      "source": [
        "## Idea\r\n",
        "* 각각의 task를 VAE를 사용해서 만들어준다면 어떨까?\r\n",
        "* 랜덤하게 값을 만들어주는 것뿐만아니라 입력 데이터의 분포를 띄게 조건도 걸어줄 수 있으니 효과적이지 않을까?\r\n",
        "* 이렇게 Multi-task에 대해서도 학습이 잘 된다면 보다 완강한 분류기가 되지 않을까...!\r\n",
        "\r\n",
        "<br>\r\n",
        "After Search<br>\r\n",
        "\r\n",
        "* 이미 'Variational Continual Learning'라는 논문이 발표되었다\r\n",
        "    * 역시는 역시...!\r\n",
        "    * 사람들이 생각하는 것들은 비슷비슷하다...!\r\n",
        "    * ✅ (적어도) Variational Continual Learning의 핵심 개념과 방법에 대해서는 알고 넘어갈 필요가 있다고 생각한다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vw5DICRA6f3p"
      },
      "source": [
        "### Naive Strategy\r\n",
        "* The Naive Stragegy, is the simple idea of continuing the back-prop process on the new batches/tasks\r\n",
        "* This is very simple, but at the same time very prone to forgetting as we have witnessed before\r\n",
        "* Let's how it works on three tasks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKPTdfOouUIY"
      },
      "source": [
        "model = Net().to(device)\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWu-JXAFuimn",
        "outputId": "cb8785de-15a8-4bc5-fe3a-ff7ba7aa9702"
      },
      "source": [
        "naive_accs = []\r\n",
        "\r\n",
        "for id, task in enumerate(tasks):\r\n",
        "    avg_acc = 0\r\n",
        "    print(\"Training on task: \", id)\r\n",
        "\r\n",
        "    (x_train, t_train), _ = task\r\n",
        "\r\n",
        "    for epoch in range(1, 2):\r\n",
        "        train(model, device, x_train, t_train, optimizer, epoch)\r\n",
        "\r\n",
        "    for id_test, task in enumerate(tasks):\r\n",
        "        print(\"Testing on task: \", id_test)\r\n",
        "        _, (x_test, t_test) = task\r\n",
        "        acc = test(model, device, x_test, t_test)\r\n",
        "        avg_acc = avg_acc + acc\r\n",
        "\r\n",
        "    naive_accs.append(avg_acc / 3)\r\n",
        "    print(\"Avg acc: \", avg_acc/3)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.669325\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0011, Accuracy: 9167/10000 (92%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0114, Accuracy: 703/10000 (7%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0101, Accuracy: 1415/10000 (14%)\n",
            "\n",
            "Avg acc:  37.61666666666667\n",
            "Training on task:  1\n",
            "Train Epoch: 1 \tLoss: 1.827566\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0231, Accuracy: 1459/10000 (15%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0053, Accuracy: 5877/10000 (59%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0105, Accuracy: 1366/10000 (14%)\n",
            "\n",
            "Avg acc:  29.006666666666664\n",
            "Training on task:  2\n",
            "Train Epoch: 1 \tLoss: 1.177152\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0278, Accuracy: 2094/10000 (21%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0086, Accuracy: 2705/10000 (27%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0032, Accuracy: 7595/10000 (76%)\n",
            "\n",
            "Avg acc:  41.31333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pNAIuRVvc11"
      },
      "source": [
        "**Questions to explore**<br>\r\n",
        "* Does the order of the tasks effect the final results?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyq4tTRZv0Sx"
      },
      "source": [
        "### Rehearsal Strategy\r\n",
        "* another simple CL idea is to carry on all or part of the previously encountered examples shuffling them with the data of the current task\r\n",
        "* Using all the past data is near to the optimal performance we can desire at the end of the task sequence\r\n",
        "* but at the expense of much bigger memory usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gMyQuKV0PRW"
      },
      "source": [
        "def shuffle_in_unison(dataset, seed, in_place=False):\r\n",
        "    \"\"\" Shuffle two (or more) list in unison \"\"\"\r\n",
        "\r\n",
        "    np.random.seed(seed)\r\n",
        "    rng_state = np.random.get_state()\r\n",
        "    new_dataset = []\r\n",
        "\r\n",
        "    for x in dataset:\r\n",
        "        if in_place:\r\n",
        "            np.random.shuffle(x)\r\n",
        "        else:\r\n",
        "            new_dataset.append(np.random.permutation(x))\r\n",
        "        np.random.set_state(rng_state)\r\n",
        "\r\n",
        "    if not in_place:\r\n",
        "        return new_dataset"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qlVdeGMv6o0"
      },
      "source": [
        "Now we can reset the model and optimizer and run our training over the tasks sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0yTflf901VW"
      },
      "source": [
        "model = Net().to(device)\r\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDIl9fiF01XT",
        "outputId": "2790e82f-d2f3-4bf4-fd03-eec042e3bd4f"
      },
      "source": [
        "rehe_accs = []\r\n",
        "\r\n",
        "for id, task in enumerate(tasks):\r\n",
        "    avg_acc = 0\r\n",
        "    print(\"Traininig on task: \", id)\r\n",
        "\r\n",
        "    (x_train, t_train), _ = task\r\n",
        "\r\n",
        "    # for previous task\r\n",
        "    for i in range(id):\r\n",
        "        (past_x_train, past_t_train), _ = tasks[i]\r\n",
        "        x_train = np.concatenate((x_train, past_x_train))\r\n",
        "        t_train = np.concatenate((t_train, past_t_train))\r\n",
        "    \r\n",
        "    x_train, t_train = shuffle_in_unison([x_train, t_train], 0)\r\n",
        "\r\n",
        "    for epoch in range(1, 2):\r\n",
        "        train(model, device, x_train, t_train, optimizer, epoch)\r\n",
        "\r\n",
        "    for id_test, task in enumerate(tasks):\r\n",
        "        print(\"Testing on task: \", id_test)\r\n",
        "        _, (x_test, t_test) = task\r\n",
        "        acc = test(model, device, x_test, t_test)\r\n",
        "        avg_acc = avg_acc + acc\r\n",
        "\r\n",
        "    print(\"Avg acc: \", avg_acc /3)\r\n",
        "    rehe_accs.append(avg_acc/3)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traininig on task:  0\n",
            "Train Epoch: 1 \tLoss: 0.175732\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0005, Accuracy: 9592/10000 (96%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0117, Accuracy: 775/10000 (8%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0099, Accuracy: 1181/10000 (12%)\n",
            "\n",
            "Avg acc:  38.49333333333333\n",
            "Traininig on task:  1\n",
            "Train Epoch: 1 \tLoss: 0.507613\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0005, Accuracy: 9631/10000 (96%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0025, Accuracy: 8138/10000 (81%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0116, Accuracy: 955/10000 (10%)\n",
            "\n",
            "Avg acc:  62.413333333333334\n",
            "Traininig on task:  2\n",
            "Train Epoch: 1 \tLoss: 0.382790\n",
            "Testing on task:  0\n",
            "Test set: Average loss: 0.0004, Accuracy: 9660/10000 (97%)\n",
            "\n",
            "Testing on task:  1\n",
            "Test set: Average loss: 0.0018, Accuracy: 8655/10000 (87%)\n",
            "\n",
            "Testing on task:  2\n",
            "Test set: Average loss: 0.0021, Accuracy: 8430/10000 (84%)\n",
            "\n",
            "Avg acc:  89.14999999999999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxJd25WZ0z6u"
      },
      "source": [
        "**Questions to explore:**<br>\r\n",
        "\r\n",
        "* Can you find a way to reduce the number of examples of the previous tasks to maintain in memory?\r\n",
        "* Can you find a good trade-off between memory overhead and final accuracy?\r\n",
        "* Why is shuffling needed here?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7k7aEFf2Nkt"
      },
      "source": [
        ""
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeLxnWVt2TdP"
      },
      "source": [
        ""
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PmlOzq22TgI"
      },
      "source": [
        ""
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WK625DZn2Ti5"
      },
      "source": [
        ""
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_GHzEpy2Tln"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KiJ7so5v6rH"
      },
      "source": [
        "\r\n",
        "Copyright (c) 2018. Continual AI. All rights reserved.\r\n",
        "\r\n",
        "See the accompanying LICENSE file in the GitHub repository for terms.\r\n",
        "\r\n",
        "Date: 29-09-2018\r\n",
        "Author: Vincenzo Lomonaco\r\n",
        "E-mail: contact@continualai.org\r\n",
        "Website: continualai.org"
      ]
    }
  ]
}