{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02.Tutorial-ResNet-VAE-Tunning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPxbho2tn+5jxXOP516Smpw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Steve-YJ/Colab_Exercise/blob/master/02_Tutorial_ResNet_VAE_Tunning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BF2mQr8fdBJE",
        "colab_type": "text"
      },
      "source": [
        "# README.MD\n",
        "\n",
        "* Post-InfoSec-Exp\n",
        "* Continue:\n",
        "    * 01.Tutorial-ResNet-VAE -Epoch5\n",
        "    * Reduce Learning Rate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcIG0ad7a63U",
        "colab_type": "text"
      },
      "source": [
        "* mount drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vbYVvoNa35z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "224b64b3-d261-4608-e9dc-f67801734aae"
      },
      "source": [
        "# drive mount\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2t5puLibOGo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lGGE4xtb59M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "e7206ab4-bd3e-4f4c-c4da-76d805a20a17"
      },
      "source": [
        "%cd drive/My\\ Drive/Post_InfoSec_Exps/ResNet-VAE/ResNetVAE-master.zip (Unzipped Files)/ResNetVAE-master\n",
        "! ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/Post_InfoSec_Exps/ResNet-VAE/ResNetVAE-master.zip (Unzipped Files)/ResNetVAE-master\n",
            "'01.Tutorial-ResNet-VAE.ipynb의 사본'   README.md\n",
            " 01.Tutorial-ResNet-VAE-Recon.ipynb     recon_sampling\n",
            " 02.Tutorial-ResNet-VAE-Tunning.ipynb   reconstruction_Malimg.png\n",
            " fig\t\t\t\t        ResNetVAE_cifar10.py\n",
            " generated_Malimg.png\t\t        ResNetVAE_FACE.py\n",
            " modules.py\t\t\t        ResNetVAE_MNIST.py\n",
            " plot_latent.ipynb\t\t        ResNetVAE_reconstruction.ipynb\n",
            " plot_latent_vector\t\t        results_Malimg\n",
            " plot_train_test_loss\t\t        results_Malimg_Exp2\n",
            " __pycache__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kWi4H8N3Hxp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bc47a354-96e3-4137-a77d-5f3aa8571f1c"
      },
      "source": [
        "import os\n",
        "\n",
        "path = os.getcwd()\n",
        "path"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/Post_InfoSec_Exps/ResNet-VAE/ResNetVAE-master.zip (Unzipped Files)/ResNetVAE-master'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnXFGN4M3Bvx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "outputId": "177d79c9-3448-4139-defa-c771b5634759"
      },
      "source": [
        "'''\n",
        "# make directory\n",
        "# 실험을 한 번 끝낸 이후로는 사용 x\n",
        "\n",
        "def makedir(dirname):\n",
        "    \n",
        "    try:\n",
        "        os.mkdir(path + '/' + dirname)\n",
        "    except OSError:\n",
        "        print(\"Creation of the directory %s failed\" % path)\n",
        "    else:\n",
        "        print(\"Successfully created the directory %s\" % path)\n",
        "    return\n",
        "\n",
        "dir_list = ['recon_sampling', 'plot_train_test_loss', 'plot_latent_vector']\n",
        "\n",
        "for i in range(len(dir_list)):\n",
        "    print(dir_list[i])\n",
        "    print(path + '/' + dir_list[i])\n",
        "    makedir(dir_list[i])\n",
        "\n",
        "\n",
        "! ls\n",
        "'''"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "recon_sampling\n",
            "/content/drive/My Drive/Post_InfoSec_Exps/ResNet-VAE/ResNetVAE-master.zip (Unzipped Files)/ResNetVAE-master/recon_sampling\n",
            "Successfully created the directory /content/drive/My Drive/Post_InfoSec_Exps/ResNet-VAE/ResNetVAE-master.zip (Unzipped Files)/ResNetVAE-master\n",
            "plot_train_test_loss\n",
            "/content/drive/My Drive/Post_InfoSec_Exps/ResNet-VAE/ResNetVAE-master.zip (Unzipped Files)/ResNetVAE-master/plot_train_test_loss\n",
            "Successfully created the directory /content/drive/My Drive/Post_InfoSec_Exps/ResNet-VAE/ResNetVAE-master.zip (Unzipped Files)/ResNetVAE-master\n",
            "plot_latent_vector\n",
            "/content/drive/My Drive/Post_InfoSec_Exps/ResNet-VAE/ResNetVAE-master.zip (Unzipped Files)/ResNetVAE-master/plot_latent_vector\n",
            "Successfully created the directory /content/drive/My Drive/Post_InfoSec_Exps/ResNet-VAE/ResNetVAE-master.zip (Unzipped Files)/ResNetVAE-master\n",
            "'01.Tutorial-ResNet-VAE.ipynb의 사본'   README.md\n",
            " 01.Tutorial-ResNet-VAE-Recon.ipynb     recon_sampling\n",
            " 02.Tutorial-ResNet-VAE-Tunning.ipynb   reconstruction_Malimg.png\n",
            " fig\t\t\t\t        ResNetVAE_cifar10.py\n",
            " generated_Malimg.png\t\t        ResNetVAE_FACE.py\n",
            " modules.py\t\t\t        ResNetVAE_MNIST.py\n",
            " plot_latent.ipynb\t\t        ResNetVAE_reconstruction.ipynb\n",
            " plot_latent_vector\t\t        results_Malimg\n",
            " plot_train_test_loss\t\t        results_Malimg_Exp2\n",
            " __pycache__\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4MQCs0Vdspm",
        "colab_type": "text"
      },
      "source": [
        "## 01. Import Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxJh0s6bbhTS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "e8635d62-cc4a-4f0b-ecbd-b3a33370d2ae"
      },
      "source": [
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        " \n",
        "# https://towardsdatascience.com/visualising-high-dimensional-datasets-using-pca-and-t-sne-in-python-8ef87e7915b\n",
        "import seaborn as sns\n",
        "\n",
        "# save single numpy array\n",
        "# https://numpy.org/doc/stable/reference/generated/numpy.save.html#numpy.save\n",
        "from tempfile import TemporaryFile\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import torch\n",
        "import torch.utils.data\n",
        "\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "# load modules\n",
        "from torchvision import models\n",
        "from modules import *\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zG79j8Wjhjd4",
        "colab_type": "text"
      },
      "source": [
        "## 02. Data Preparation\n",
        "* Make Custom Dataset\n",
        "* Make Custom DataLoader\n",
        "* Train_Test Split\n",
        "\n",
        "### Work Flow\n",
        "* transforms module 사용, Image data compose(전처리, transform)\n",
        "* re-sizing, normalizing, tensor\n",
        "* ImageFolder사용 dataloader\n",
        "* dataset split: train dataset, test dataset\n",
        "* DataLoader: batch단위 dataset loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40wjsfCSgYIY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transforms = transforms.Compose([\n",
        "                                transforms.Resize((224, 224)),                # Change size of Image to (224, 224)\n",
        "                                transforms.Grayscale(num_output_channels=3),  # Makes it 1-dimension channel\n",
        "                                # transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # gray -> GRB 3 channel (lambda function)\n",
        "                                                                                 # Reference: https://github.com/hsinyilin19/ResNetVAE/blob/master/ResNetVAE_MNIST.py\n",
        "\n",
        "\n",
        "                                transforms.ToTensor(),                        # Convert a PIL Image or numpy.ndarray to tensor.\n",
        "                                                                              # Converts a PIL Image or numpy.ndarray (H x W x C) in the range [0, 255] to a torch.FloatTensor of shape (C x H x W) in the range [0.0, 1.0] if the PIL Image belongs to one of the modes (L, LA, P, I, F, RGB, YCbCr, RGBA, CMYK, 1) or if the numpy.ndarray has dtype = np.uint8\n",
        "                                                                              # In the other cases, tensors are returned without scaling.\n",
        "                                # transforms.Normalize(mean=[0.5], std=[0.5]), \n",
        "                                ])\n",
        "\n",
        "# make custom dataset\n",
        "trainset = torchvision.datasets.ImageFolder(root='../../../../InformationSecurity_Summer/malimg',\n",
        "                                            transform=transforms)  # make custom dataset"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYwMgJ5UdvgO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "outputId": "dc3a6fa9-2747-4fec-8218-edc14aa31281"
      },
      "source": [
        "# classes = trainset.classes\n",
        "classes = trainset.classes\n",
        "classes"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Adialer.C',\n",
              " 'Agent.FYI',\n",
              " 'Allaple.A',\n",
              " 'Allaple.L',\n",
              " 'Alueron.gen!J',\n",
              " 'Autorun.K',\n",
              " 'C2LOP.P',\n",
              " 'C2LOP.gen!g',\n",
              " 'Dialplatform.B',\n",
              " 'Dontovo.A',\n",
              " 'Fakerean',\n",
              " 'Instantaccess',\n",
              " 'Lolyda.AA1',\n",
              " 'Lolyda.AA2',\n",
              " 'Lolyda.AA3',\n",
              " 'Lolyda.AT',\n",
              " 'Malex.gen!J',\n",
              " 'Obfuscator.AD',\n",
              " 'Rbot!gen',\n",
              " 'Skintrim.N',\n",
              " 'Swizzor.gen!E',\n",
              " 'Swizzor.gen!I',\n",
              " 'VB.AT',\n",
              " 'Wintrim.BX',\n",
              " 'Yuner.A']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRNtxJgpdy6x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8a2ff767-fe6f-473f-f4de-261c4b1ec3ad"
      },
      "source": [
        "full_dataset = trainset\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "print(train_size, test_size)\n",
        "\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7471 1868\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laqQVjbpkVsq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(train_dataset,\n",
        "                         batch_size=16,\n",
        "                         shuffle=True,\n",
        "                         pin_memory=True) \n",
        "valid_loader = DataLoader(test_dataset,\n",
        "                        batch_size=16,\n",
        "                        shuffle=True,\n",
        "                        pin_memory=True)  # Instead, we recommend using automatic memory pinning (i.e., setting pin_memory=True)\n",
        "                                          #  which enables fast data transfer to CUDA-enabled GPUs\n",
        "\n",
        "# First, insert all test dataset\n",
        "# test_loader_10: testloader for latent vector visualization\n",
        "test_loader_10 = DataLoader(test_dataset,\n",
        "                        batch_size=1868,\n",
        "                        shuffle=True,\n",
        "                        pin_memory=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2tvYihLhDd0",
        "colab_type": "text"
      },
      "source": [
        "## 03. Modeling\n",
        "* save model: <code>save_model_path</code>\n",
        "* save_loss_list\n",
        "* etc...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyiJB8iSiqTT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# EncoderCNN architecture\n",
        "CNN_fc_hidden1, CNN_fc_hidden2 = 1024, 1024\n",
        "CNN_embed_dim = 256     # latent dim extracted by 2D CNN\n",
        "res_size = 224        # ResNet image size\n",
        "dropout_p = 0.2       # dropout probability\n",
        "\n",
        "# training parameters\n",
        "epochs = 50        # training epochs\n",
        "batch_size = 16\n",
        "learning_rate = 1e-5\n",
        "log_interval = 10   # interval for displaying training info"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjFMhGMEiRG8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save model\n",
        "save_model_path = './results_Malimg_Exp2'  # save_model parameter"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK2IkNBgifV6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_mkdir(dir_name):\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.mkdir(dir_name)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLrFg4euigpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_mkdir(dir_name):\n",
        "    if not os.path.exists(dir_name):\n",
        "        os.mkdir(dir_name)\n",
        "\n",
        "def loss_function(recon_x, x, mu, logvar):\n",
        "    # MSE = F.mse_loss(recon_x, x, reduction='sum')\n",
        "    MSE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    # mse, kld의 값도 확인하고 싶은데... 어떻게 하면 좋을까??\n",
        "    mes_loss.append(MSE)\n",
        "    kld_loss.append(KLD)\n",
        "\n",
        "    return MSE + KLD"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHryk-eBitM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(log_interval, model, device, train_loader, optimizer, epoch):\n",
        "    # set model as training mode\n",
        "    model.train()\n",
        "\n",
        "    losses = []\n",
        "    all_y, all_z, all_mu, all_logvar = [], [], [], []\n",
        "    N_count = 0   # counting total trained sample in one epoch\n",
        "    for batch_idx, (X, y) in enumerate(train_loader):\n",
        "        # distribute data to device\n",
        "        X, y = X.to(device), y.to(device).view(-1, )\n",
        "        N_count += X.size(0)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        X_reconst, z, mu, logvar = model(X)  # VAE\n",
        "        loss = loss_function(X_reconst, X, mu, logvar)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        all_y.extend(y.data.cpu().numpy())\n",
        "        all_z.extend(z.data.cpu().numpy())\n",
        "        all_mu.extend(mu.data.cpu().numpy())\n",
        "        all_logvar.extend(logvar.data.cpu().numpy())\n",
        "\n",
        "        # show information\n",
        "        if (batch_idx + 1) % log_interval == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch + 5 +1, N_count, len(train_loader.dataset), 100. * (batch_idx + 1) / len(train_loader), loss.item()))\n",
        "\n",
        "    all_y = np.stack(all_y, axis=0)\n",
        "    all_z = np.stack(all_z, axis=0)\n",
        "    all_mu = np.stack(all_mu, axis=0)\n",
        "    all_logvar = np.stack(all_logvar, axis=0)\n",
        "\n",
        "    # save Pytorch models of best record\n",
        "    torch.save(model.state_dict(), os.path.join(save_model_path, 'model_epoch{}.pth'.format(epoch +5 + 1)))  # save motion_encoder\n",
        "    torch.save(optimizer.state_dict(), os.path.join(save_model_path, 'optimizer_epoch{}.pth'.format(epoch +5 + 1)))      # save optimizer\n",
        "    print(\"Epoch {} model saved!\".format(epoch + 5 +1))  # 5 Epoch부터 이어서 Training하기 때문\n",
        "\n",
        "    return X.data.cpu().numpy(), all_y, all_z, all_mu, all_logvar, losses\n",
        "\n",
        "\n",
        "def validation(model, device, optimizer, test_loader):\n",
        "    # set model as testing mode\n",
        "    model.eval()\n",
        "\n",
        "    test_loss = 0\n",
        "    all_y, all_z, all_mu, all_logvar = [], [], [], []\n",
        "    with torch.no_grad():\n",
        "        for X, y in test_loader:\n",
        "            # distribute data to device\n",
        "            X, y = X.to(device), y.to(device).view(-1, )\n",
        "            X_reconst, z, mu, logvar = model(X)\n",
        "\n",
        "            loss = loss_function(X_reconst, X, mu, logvar)\n",
        "            test_loss += loss.item()  # sum up batch loss\n",
        "\n",
        "            all_y.extend(y.data.cpu().numpy())\n",
        "            all_z.extend(z.data.cpu().numpy())\n",
        "            all_mu.extend(mu.data.cpu().numpy())\n",
        "            all_logvar.extend(logvar.data.cpu().numpy())\n",
        "        \n",
        "\n",
        "    ## Save_Recon_Malimg\n",
        "        for i, (data, _) in enumerate(test_loader):\n",
        "            data = data.to(device)\n",
        "            # recon_batch, mu, logvar, z = model(data)\n",
        "            recon, z, mu, logvar = model(data)\n",
        "\n",
        "            # z vector는 torch type\n",
        "            # latent_vector = z.detach().cpu().clone().numpy()\n",
        "\n",
        "            # test_loss += loss_function(recon, data, mu, logvar).item()  # 중복됨\n",
        "            if i == 0:\n",
        "                n = min(data.size(0), 8)\n",
        "                comparison = torch.cat([data[:n],\n",
        "                                    recon.view(16, 3, 224, 224)[:n]])\n",
        "                save_image(comparison.cpu(),\n",
        "                        './recon_sampling/reconstruction_' + str(epoch+5) + '.png', nrow=n)\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    all_y = np.stack(all_y, axis=0)\n",
        "    all_z = np.stack(all_z, axis=0)\n",
        "    all_mu = np.stack(all_mu, axis=0)\n",
        "    all_logvar = np.stack(all_logvar, axis=0)\n",
        "\n",
        "    # show information\n",
        "    print('\\nTest set ({:d} samples): Average loss: {:.4f}\\n'.format(len(test_loader.dataset), test_loss))\n",
        "    return X.data.cpu().numpy(), all_y, all_z, all_mu, all_logvar, test_loss\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0uohqjsixS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Detect devices\n",
        "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aj1YYgo41S3n",
        "colab_type": "text"
      },
      "source": [
        "### Load_State_Dict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_OOIagV1SQ_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8e0268b6-59d8-4727-8c71-acde42b19a7c"
      },
      "source": [
        "pre_saved_model_path = './results_Malimg'\n",
        "epoch = 5\n",
        "\n",
        "# reload ResNetVAE model\n",
        "resnet_vae = ResNet_VAE(fc_hidden1=CNN_fc_hidden1, fc_hidden2=CNN_fc_hidden2, drop_p=dropout_p, CNN_embed_dim=CNN_embed_dim).to(device)\n",
        "resnet_vae.load_state_dict(torch.load(os.path.join(pre_saved_model_path, 'model_epoch{}.pth'.format(epoch))))\n",
        "print(\"ResNet VAE epoch {} model reloaded!\".format(epoch))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet VAE epoch 5 model reloaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a9FFdiljGPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8b1a0f85-a17c-4cec-e1e5-4cc373a43840"
      },
      "source": [
        "# resnet_vae = ResNet_VAE(fc_hidden1=CNN_fc_hidden1, fc_hidden2=CNN_fc_hidden2, drop_p=dropout_p, CNN_embed_dim=CNN_embed_dim).to(device)\n",
        "\n",
        "print(\"Using\", torch.cuda.device_count(), \"GPU!\")\n",
        "model_params = list(resnet_vae.parameters())\n",
        "optimizer = torch.optim.Adam(model_params, lr=learning_rate)  # After5 lr 1e-3 to 1e-5\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using 1 GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mDezxJUjKSZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# record training process\n",
        "'''\n",
        "list_epoch = []\n",
        "list_train_loss = []\n",
        "list_val_loss = []\n",
        "list_acc = []\n",
        "list_acc_epoch = []\n",
        "'''\n",
        "list_epoch=[]\n",
        "epoch_train_losses = []\n",
        "epoch_test_losses = []\n",
        "mse_loss = []\n",
        "kld_loss = []\n",
        "list_acc = []\n",
        "list_acc_epoch =[]\n",
        "check_mkdir(save_model_path)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcJRmBUEhT5W",
        "colab_type": "text"
      },
      "source": [
        "## 04. Train-it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLFMtJaUhMCN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "adbeee4e-1a43-456c-a253-2e9a224078d7"
      },
      "source": [
        "# start training\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # train, test model\n",
        "    X_train, y_train, z_train, mu_train, logvar_train, train_losses = train(log_interval, resnet_vae, device, train_loader, optimizer, epoch)\n",
        "    X_test, y_test, z_test, mu_test, logvar_test, epoch_test_loss = validation(resnet_vae, device, optimizer, valid_loader)\n",
        "\n",
        "    # save results\n",
        "    list_epoch.append(epoch)\n",
        "    epoch_train_losses.append(train_losses)\n",
        "    epoch_test_losses.append(epoch_test_loss)\n",
        "\n",
        "    \n",
        "    # save all train test results\n",
        "    A = np.array(epoch_train_losses)\n",
        "    C = np.array(epoch_test_losses)\n",
        "    \n",
        "    np.save(os.path.join(save_model_path, 'ResNet_VAE_training_loss.npy'), A)\n",
        "    np.save(os.path.join(save_model_path, 'X_Malimg_train_epoch{}.npy'.format(epoch + 1)), X_train) #save last batch\n",
        "    np.save(os.path.join(save_model_path, 'y_Malimg_train_epoch{}.npy'.format(epoch + 1)), y_train)\n",
        "    np.save(os.path.join(save_model_path, 'z_Malimg_train_epoch{}.npy'.format(epoch + 1)), z_train)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 6 [160/7471 (2%)]\tLoss: 1619163.500000\n",
            "Train Epoch: 6 [320/7471 (4%)]\tLoss: 1578740.000000\n",
            "Train Epoch: 6 [480/7471 (6%)]\tLoss: 1626742.000000\n",
            "Train Epoch: 6 [640/7471 (9%)]\tLoss: 1643403.000000\n",
            "Train Epoch: 6 [800/7471 (11%)]\tLoss: 1595550.250000\n",
            "Train Epoch: 6 [960/7471 (13%)]\tLoss: 1574912.750000\n",
            "Train Epoch: 6 [1120/7471 (15%)]\tLoss: 1619013.625000\n",
            "Train Epoch: 6 [1280/7471 (17%)]\tLoss: 1604289.125000\n",
            "Train Epoch: 6 [1440/7471 (19%)]\tLoss: 1606559.750000\n",
            "Train Epoch: 6 [1600/7471 (21%)]\tLoss: 1572595.000000\n",
            "Train Epoch: 6 [1760/7471 (24%)]\tLoss: 1619650.500000\n",
            "Train Epoch: 6 [1920/7471 (26%)]\tLoss: 1580051.125000\n",
            "Train Epoch: 6 [2080/7471 (28%)]\tLoss: 1591977.375000\n",
            "Train Epoch: 6 [2240/7471 (30%)]\tLoss: 1601548.375000\n",
            "Train Epoch: 6 [2400/7471 (32%)]\tLoss: 1627797.250000\n",
            "Train Epoch: 6 [2560/7471 (34%)]\tLoss: 1575680.625000\n",
            "Train Epoch: 6 [2720/7471 (36%)]\tLoss: 1580439.750000\n",
            "Train Epoch: 6 [2880/7471 (39%)]\tLoss: 1611021.375000\n",
            "Train Epoch: 6 [3040/7471 (41%)]\tLoss: 1569901.375000\n",
            "Train Epoch: 6 [3200/7471 (43%)]\tLoss: 1600609.500000\n",
            "Train Epoch: 6 [3360/7471 (45%)]\tLoss: 1582570.250000\n",
            "Train Epoch: 6 [3520/7471 (47%)]\tLoss: 1605413.500000\n",
            "Train Epoch: 6 [3680/7471 (49%)]\tLoss: 1610097.750000\n",
            "Train Epoch: 6 [3840/7471 (51%)]\tLoss: 1624862.625000\n",
            "Train Epoch: 6 [4000/7471 (54%)]\tLoss: 1619657.375000\n",
            "Train Epoch: 6 [4160/7471 (56%)]\tLoss: 1598790.125000\n",
            "Train Epoch: 6 [4320/7471 (58%)]\tLoss: 1645260.250000\n",
            "Train Epoch: 6 [4480/7471 (60%)]\tLoss: 1535837.500000\n",
            "Train Epoch: 6 [4640/7471 (62%)]\tLoss: 1616739.875000\n",
            "Train Epoch: 6 [4800/7471 (64%)]\tLoss: 1609291.250000\n",
            "Train Epoch: 6 [4960/7471 (66%)]\tLoss: 1545910.125000\n",
            "Train Epoch: 6 [5120/7471 (69%)]\tLoss: 1621331.375000\n",
            "Train Epoch: 6 [5280/7471 (71%)]\tLoss: 1580745.125000\n",
            "Train Epoch: 6 [5440/7471 (73%)]\tLoss: 1606151.500000\n",
            "Train Epoch: 6 [5600/7471 (75%)]\tLoss: 1600020.125000\n",
            "Train Epoch: 6 [5760/7471 (77%)]\tLoss: 1596106.375000\n",
            "Train Epoch: 6 [5920/7471 (79%)]\tLoss: 1574181.375000\n",
            "Train Epoch: 6 [6080/7471 (81%)]\tLoss: 1632477.125000\n",
            "Train Epoch: 6 [6240/7471 (84%)]\tLoss: 1606110.375000\n",
            "Train Epoch: 6 [6400/7471 (86%)]\tLoss: 1595538.500000\n",
            "Train Epoch: 6 [6560/7471 (88%)]\tLoss: 1612456.000000\n",
            "Train Epoch: 6 [6720/7471 (90%)]\tLoss: 1624418.375000\n",
            "Train Epoch: 6 [6880/7471 (92%)]\tLoss: 1541067.375000\n",
            "Train Epoch: 6 [7040/7471 (94%)]\tLoss: 1600879.125000\n",
            "Train Epoch: 6 [7200/7471 (96%)]\tLoss: 1598916.375000\n",
            "Train Epoch: 6 [7360/7471 (99%)]\tLoss: 1584168.750000\n",
            "Epoch 6 model saved!\n",
            "\n",
            "Test set (1868 samples): Average loss: inf\n",
            "\n",
            "Train Epoch: 7 [160/7471 (2%)]\tLoss: 1618997.375000\n",
            "Train Epoch: 7 [320/7471 (4%)]\tLoss: 1613299.625000\n",
            "Train Epoch: 7 [480/7471 (6%)]\tLoss: 1608635.500000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-06ac6efe077f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# train, test model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresnet_vae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_test_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet_vae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-0a9901b84d9b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(log_interval, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mall_y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tmNHFSv20a8",
        "colab_type": "text"
      },
      "source": [
        "### plot_train_val_loss plot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCneJB6XkQ5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(15, 5))\n",
        "\n",
        "# ======= Loss Fluctuation ======= #\n",
        "ax1 = fig.add_subplot(1, 2, 1)\n",
        "ax1.plot(list_epoch, epoch_train_losses, label='train_loss')\n",
        "ax1.plot(list_epoch, epoch_test_losses, '--', label='val_loss')\n",
        "ax1.set_xlabel('epoch')\n",
        "ax1.set_ylabel('loss')\n",
        "ax1.grid()\n",
        "ax1.legend()\n",
        "ax1.set_title('epoch vs loss')\n",
        "\n",
        "plt.savefig('./plot_latent_vector/' + str(epoch+5) + '_t_SNE.png', dpi=300)\n",
        "\n",
        "\n",
        "'''\n",
        "# ======= Metric Fluctuation ======= # \n",
        "ax2 = fig.add_subplot(1, 2, 2)\n",
        "ax2.plot(list_acc_epoch, list_acc, marker='x', label='Accuracy metric')\n",
        "ax2.set_xlabel('epoch')\n",
        "ax2.set_ylabel('Acc')\n",
        "ax2.grid()\n",
        "ax2.legend()\n",
        "ax2.set_title('epoch vs Accuracy')\n",
        "\n",
        "plt.show()\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}